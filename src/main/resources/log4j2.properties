status = error

# Niveau de log principal
rootLogger.level = info
rootLogger.appenderRefs = file
rootLogger.appenderRef.file.ref = logfile

# Définition du fichier de logs
appender.logfile.type = File
appender.logfile.name = logfile
appender.logfile.fileName = logs/spark.log
appender.logfile.layout.type = PatternLayout
appender.logfile.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}: %m%n

# Désactiver la console
appender.console.type = Console
appender.console.name = console
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}: %m%n
appender.console.filter.threshold.type = ThresholdFilter
appender.console.filter.threshold.level = off  #Empêche les logs en console

# Désactiver certains logs inutiles
logger.spark.name = org.apache.spark
logger.spark.level = info
logger.spark.additivity = false
logger.spark.appenderRefs = file
logger.spark.appenderRef.file.ref = logfile

logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = error
logger.hadoop.additivity = false
logger.hadoop.appenderRefs = file
logger.hadoop.appenderRef.file.ref = logfile
