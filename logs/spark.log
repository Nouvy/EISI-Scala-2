2025-02-17 16:23:36 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-17 16:23:36 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-17 16:23:36 INFO  SparkContext: Running Spark version 3.3.2
2025-02-17 16:23:36 INFO  ResourceUtils: ==============================================================
2025-02-17 16:23:36 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-17 16:23:36 INFO  ResourceUtils: ==============================================================
2025-02-17 16:23:36 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-17 16:23:36 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-17 16:23:36 INFO  ResourceProfile: Limiting resource is cpu
2025-02-17 16:23:36 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-17 16:23:36 INFO  SecurityManager: Changing view acls to: fabob
2025-02-17 16:23:36 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-17 16:23:36 INFO  SecurityManager: Changing view acls groups to: 
2025-02-17 16:23:36 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-17 16:23:36 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-17 16:23:36 INFO  Utils: Successfully started service 'sparkDriver' on port 57394.
2025-02-17 16:23:36 INFO  SparkEnv: Registering MapOutputTracker
2025-02-17 16:23:36 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-17 16:23:36 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-17 16:23:36 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-17 16:23:36 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-17 16:23:36 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-303c14c1-0c91-4279-a606-288959658159
2025-02-17 16:23:36 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-17 16:23:37 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-17 16:23:37 INFO  log: Logging initialized @947ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-17 16:23:37 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-17 16:23:37 INFO  Server: Started @1003ms
2025-02-17 16:23:37 INFO  AbstractConnector: Started ServerConnector@684b31de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:23:37 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10fda3d0{/,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-17 16:23:37 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-17 16:23:37 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57395.
2025-02-17 16:23:37 INFO  NettyBlockTransferService: Server created on 172.20.10.2:57395
2025-02-17 16:23:37 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-17 16:23:37 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 57395, None)
2025-02-17 16:23:37 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:57395 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 57395, None)
2025-02-17 16:23:37 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 57395, None)
2025-02-17 16:23:37 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 57395, None)
2025-02-17 16:23:37 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@10fda3d0{/,null,STOPPED,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58015e56{/jobs,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7426a448{/jobs/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6cbe7d4d{/jobs/job,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3679d92e{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/stages,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/stages/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6342ff7f{/stages/stage,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2daf06fc{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/pool,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/storage,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/storage/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/environment,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/environment/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/executors,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/executors/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/static,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68a78f3c{/,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3481ff98{/api,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@67507df{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@692dba54{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d1ff6b1{/metrics/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-17 16:23:37 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@46911148{/SQL,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e351d7{/SQL/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58658f63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60990e5c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4a92c6a9{/static/sql,null,AVAILABLE,@Spark}
2025-02-17 16:23:37 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-17 16:23:37 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-17 16:23:38 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:23:38 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-17 16:23:38 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:23:38 INFO  CodeGenerator: Code generated in 65.273375 ms
2025-02-17 16:23:38 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:57395 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:39 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-17 16:23:39 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:23:39 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:23:39 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-17 16:23:39 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-17 16:23:39 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:23:39 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:23:39 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:57395 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:23:39 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:23:39 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:23:39 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:23:39 INFO  CodeGenerator: Code generated in 5.40675 ms
2025-02-17 16:23:39 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-17 16:23:39 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 95 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:23:39 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-17 16:23:39 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,147 s
2025-02-17 16:23:39 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:23:39 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-17 16:23:39 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,180090 s
2025-02-17 16:23:39 INFO  CodeGenerator: Code generated in 4.307083 ms
2025-02-17 16:23:39 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:57395 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:23:39 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:23:39 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:23:39 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:57395 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:39 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-17 16:23:39 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:23:39 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:23:39 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-17 16:23:39 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-17 16:23:39 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:23:39 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:23:39 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-17 16:23:39 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:57395 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:39 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:23:39 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:23:39 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:23:39 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-17 16:23:39 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-17 16:23:39 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-17 16:23:39 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-17 16:23:39 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-17 16:23:39 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-17 16:23:39 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-17 16:23:39 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:23:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:23:40 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 870 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 948 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 949 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 951 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 957 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 964 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 970 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:23:40 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-17 16:23:40 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 973 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:23:40 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-17 16:23:40 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,989 s
2025-02-17 16:23:40 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:23:40 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-17 16:23:40 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,991577 s
2025-02-17 16:23:55 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:57395 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:55 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:57395 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:55 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:23:55 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:23:55 INFO  FileSourceStrategy: Output Data Schema: struct<montant: double, date_achat: timestamp>
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 66.997708 ms
2025-02-17 16:23:55 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:23:55 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:23:55 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:57395 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:55 INFO  SparkContext: Created broadcast 4 from show at main.scala:76
2025-02-17 16:23:55 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:23:55 INFO  DAGScheduler: Registering RDD 13 (show at main.scala:76) as input to shuffle 0
2025-02-17 16:23:55 INFO  DAGScheduler: Got map stage job 2 (show at main.scala:76) with 8 output partitions
2025-02-17 16:23:55 INFO  DAGScheduler: Final stage: ShuffleMapStage 2 (show at main.scala:76)
2025-02-17 16:23:55 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:23:55 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:23:55 INFO  DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at show at main.scala:76), which has no missing parents
2025-02-17 16:23:55 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.0 KiB, free 2.2 GiB)
2025-02-17 16:23:55 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 2.2 GiB)
2025-02-17 16:23:55 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:57395 (size: 16.5 KiB, free: 2.2 GiB)
2025-02-17 16:23:55 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:23:55 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at show at main.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:23:55 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:23:55 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-17 16:23:55 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-17 16:23:55 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-17 16:23:55 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-17 16:23:55 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-17 16:23:55 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-17 16:23:55 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-17 16:23:55 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 8.685792 ms
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 4.532541 ms
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 4.363417 ms
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 3.367625 ms
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:23:55 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:23:55 INFO  CodeGenerator: Code generated in 3.262333 ms
2025-02-17 16:23:55 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:57395 in memory (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:23:56 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 663 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 672 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 673 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 674 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 675 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 683 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 694 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:23:56 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 2858 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 703 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:23:56 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-17 16:23:56 INFO  DAGScheduler: ShuffleMapStage 2 (show at main.scala:76) finished in 0,712 s
2025-02-17 16:23:56 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:23:56 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:23:56 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:23:56 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:23:56 INFO  ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:23:56 INFO  CodeGenerator: Code generated in 7.567667 ms
2025-02-17 16:23:56 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:23:56 INFO  CodeGenerator: Code generated in 12.142833 ms
2025-02-17 16:23:56 INFO  SparkContext: Starting job: show at main.scala:76
2025-02-17 16:23:56 INFO  DAGScheduler: Got job 3 (show at main.scala:76) with 1 output partitions
2025-02-17 16:23:56 INFO  DAGScheduler: Final stage: ResultStage 4 (show at main.scala:76)
2025-02-17 16:23:56 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
2025-02-17 16:23:56 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:23:56 INFO  DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[17] at show at main.scala:76), which has no missing parents
2025-02-17 16:23:56 INFO  MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.5 KiB, free 2.2 GiB)
2025-02-17 16:23:56 INFO  MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.2 KiB, free 2.2 GiB)
2025-02-17 16:23:56 INFO  BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.10.2:57395 (size: 18.2 KiB, free: 2.2 GiB)
2025-02-17 16:23:56 INFO  SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:23:56 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[17] at show at main.scala:76) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:23:56 INFO  TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
2025-02-17 16:23:56 INFO  TaskSetManager: Starting task 0.0 in stage 4.0 (TID 17) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:23:56 INFO  Executor: Running task 0.0 in stage 4.0 (TID 17)
2025-02-17 16:23:56 INFO  BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.10.2:57395 in memory (size: 16.5 KiB, free: 2.2 GiB)
2025-02-17 16:23:56 INFO  ShuffleBlockFetcherIterator: Getting 8 (6.2 KiB) non-empty blocks including 8 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:23:56 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
2025-02-17 16:23:56 INFO  Executor: Finished task 0.0 in stage 4.0 (TID 17). 7071 bytes result sent to driver
2025-02-17 16:23:56 INFO  TaskSetManager: Finished task 0.0 in stage 4.0 (TID 17) in 48 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:23:56 INFO  TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-02-17 16:23:56 INFO  DAGScheduler: ResultStage 4 (show at main.scala:76) finished in 0,056 s
2025-02-17 16:23:56 INFO  DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:23:56 INFO  TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
2025-02-17 16:23:56 INFO  DAGScheduler: Job 3 finished: show at main.scala:76, took 0,061518 s
2025-02-17 16:23:56 INFO  CodeGenerator: Code generated in 5.347875 ms
2025-02-17 16:23:56 INFO  CodeGenerator: Code generated in 12.592875 ms
2025-02-17 16:23:59 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-17 16:23:59 INFO  AbstractConnector: Stopped Spark@684b31de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:23:59 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-17 16:23:59 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-17 16:23:59 INFO  MemoryStore: MemoryStore cleared
2025-02-17 16:23:59 INFO  BlockManager: BlockManager stopped
2025-02-17 16:23:59 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-17 16:23:59 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-17 16:23:59 INFO  SparkContext: Successfully stopped SparkContext
2025-02-17 16:23:59 INFO  ShutdownHookManager: Shutdown hook called
2025-02-17 16:23:59 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-ceb8341f-234e-426d-8bd6-7534756f6249
2025-02-17 16:26:39 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-17 16:26:39 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-17 16:26:39 INFO  SparkContext: Running Spark version 3.3.2
2025-02-17 16:26:39 INFO  ResourceUtils: ==============================================================
2025-02-17 16:26:39 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-17 16:26:39 INFO  ResourceUtils: ==============================================================
2025-02-17 16:26:39 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-17 16:26:39 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-17 16:26:39 INFO  ResourceProfile: Limiting resource is cpu
2025-02-17 16:26:39 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-17 16:26:39 INFO  SecurityManager: Changing view acls to: fabob
2025-02-17 16:26:39 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-17 16:26:39 INFO  SecurityManager: Changing view acls groups to: 
2025-02-17 16:26:39 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-17 16:26:39 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-17 16:26:39 INFO  Utils: Successfully started service 'sparkDriver' on port 57813.
2025-02-17 16:26:39 INFO  SparkEnv: Registering MapOutputTracker
2025-02-17 16:26:39 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-17 16:26:39 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-17 16:26:39 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-17 16:26:39 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-17 16:26:39 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-88bf0e5e-f2af-407c-b100-cbff993b1840
2025-02-17 16:26:39 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-17 16:26:39 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-17 16:26:39 INFO  log: Logging initialized @1084ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-17 16:26:39 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-17 16:26:39 INFO  Server: Started @1146ms
2025-02-17 16:26:39 INFO  AbstractConnector: Started ServerConnector@782cf31f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:26:39 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-17 16:26:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a6cc2a{/,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-17 16:26:40 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-17 16:26:40 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57815.
2025-02-17 16:26:40 INFO  NettyBlockTransferService: Server created on 172.20.10.2:57815
2025-02-17 16:26:40 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-17 16:26:40 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 57815, None)
2025-02-17 16:26:40 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:57815 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 57815, None)
2025-02-17 16:26:40 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 57815, None)
2025-02-17 16:26:40 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 57815, None)
2025-02-17 16:26:40 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@51a6cc2a{/,null,STOPPED,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575e572f{/jobs,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d3c6593{/jobs/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2dfb885e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1e3e1014{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47b11ec7{/stages,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36aa52d2{/stages/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@633cc6b5{/stages/stage,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@403c3a01{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/stages/pool,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/storage,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/storage/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4462efe1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db4ad1{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/environment,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/environment/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/executors,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/executors/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/static,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d408060{/,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@17ba57f0{/api,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e3ecf5c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@341b13a8{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2d55e826{/metrics/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-17 16:26:40 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70f68288{/SQL,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db1b657{/SQL/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54e12f4c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca30b8a{/static/sql,null,AVAILABLE,@Spark}
2025-02-17 16:26:40 INFO  InMemoryFileIndex: It took 20 ms to list leaf files for 1 paths.
2025-02-17 16:26:40 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-17 16:26:41 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:26:41 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-17 16:26:41 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:26:41 INFO  CodeGenerator: Code generated in 62.5245 ms
2025-02-17 16:26:41 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:57815 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:26:42 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-17 16:26:42 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:26:42 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:26:42 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-17 16:26:42 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-17 16:26:42 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:26:42 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:26:42 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:57815 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:26:42 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:26:42 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:26:42 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:26:42 INFO  CodeGenerator: Code generated in 6.014541 ms
2025-02-17 16:26:42 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-17 16:26:42 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 103 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:26:42 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-17 16:26:42 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,159 s
2025-02-17 16:26:42 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:26:42 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-17 16:26:42 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,190980 s
2025-02-17 16:26:42 INFO  CodeGenerator: Code generated in 4.275 ms
2025-02-17 16:26:42 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:57815 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:26:42 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:26:42 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:26:42 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:57815 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:26:42 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-17 16:26:42 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:26:42 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:26:42 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-17 16:26:42 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-17 16:26:42 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:26:42 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:26:42 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-17 16:26:42 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:57815 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:26:42 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:26:42 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:26:42 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:26:42 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-17 16:26:42 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-17 16:26:42 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-17 16:26:42 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-17 16:26:42 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-17 16:26:42 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-17 16:26:42 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-17 16:26:42 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:26:42 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:26:42 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:57815 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:26:43 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 959 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:26:43 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1101 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:26:43 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1109 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:26:43 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1114 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:26:43 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1116 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1116 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1116 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:26:43 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-17 16:26:43 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1117 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:26:43 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-17 16:26:43 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 1,129 s
2025-02-17 16:26:43 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:26:43 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-17 16:26:43 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 1,130771 s
2025-02-17 16:26:54 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-17 16:26:54 INFO  AbstractConnector: Stopped Spark@782cf31f{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:26:54 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-17 16:26:54 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-17 16:26:54 INFO  MemoryStore: MemoryStore cleared
2025-02-17 16:26:54 INFO  BlockManager: BlockManager stopped
2025-02-17 16:26:54 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-17 16:26:54 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-17 16:26:54 INFO  SparkContext: Successfully stopped SparkContext
2025-02-17 16:26:54 INFO  ShutdownHookManager: Shutdown hook called
2025-02-17 16:26:54 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-448e7f4c-2c8e-47e1-b62a-2d1f09e19232
2025-02-17 16:34:47 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-17 16:34:47 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-17 16:34:47 INFO  SparkContext: Running Spark version 3.3.2
2025-02-17 16:34:48 INFO  ResourceUtils: ==============================================================
2025-02-17 16:34:48 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-17 16:34:48 INFO  ResourceUtils: ==============================================================
2025-02-17 16:34:48 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-17 16:34:48 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-17 16:34:48 INFO  ResourceProfile: Limiting resource is cpu
2025-02-17 16:34:48 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-17 16:34:48 INFO  SecurityManager: Changing view acls to: fabob
2025-02-17 16:34:48 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-17 16:34:48 INFO  SecurityManager: Changing view acls groups to: 
2025-02-17 16:34:48 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-17 16:34:48 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-17 16:34:48 INFO  Utils: Successfully started service 'sparkDriver' on port 58852.
2025-02-17 16:34:48 INFO  SparkEnv: Registering MapOutputTracker
2025-02-17 16:34:48 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-17 16:34:48 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-17 16:34:48 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-17 16:34:48 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-17 16:34:48 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-c2f9628f-7ad7-4faf-a367-cc2adb57ebdd
2025-02-17 16:34:48 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-17 16:34:48 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-17 16:34:48 INFO  log: Logging initialized @1062ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-17 16:34:48 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-17 16:34:48 INFO  Server: Started @1119ms
2025-02-17 16:34:48 INFO  AbstractConnector: Started ServerConnector@684b31de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:34:48 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10fda3d0{/,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-17 16:34:48 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-17 16:34:48 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58854.
2025-02-17 16:34:48 INFO  NettyBlockTransferService: Server created on 172.20.10.2:58854
2025-02-17 16:34:48 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-17 16:34:48 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 58854, None)
2025-02-17 16:34:48 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:58854 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 58854, None)
2025-02-17 16:34:48 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 58854, None)
2025-02-17 16:34:48 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 58854, None)
2025-02-17 16:34:48 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@10fda3d0{/,null,STOPPED,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58015e56{/jobs,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7426a448{/jobs/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6cbe7d4d{/jobs/job,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3679d92e{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/stages,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/stages/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6342ff7f{/stages/stage,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2daf06fc{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/pool,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/storage,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/storage/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/environment,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/environment/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/executors,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/executors/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/static,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68a78f3c{/,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3481ff98{/api,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@67507df{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@692dba54{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d1ff6b1{/metrics/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-17 16:34:48 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@46911148{/SQL,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e351d7{/SQL/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58658f63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60990e5c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-17 16:34:48 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4a92c6a9{/static/sql,null,AVAILABLE,@Spark}
2025-02-17 16:34:49 INFO  InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
2025-02-17 16:34:49 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-17 16:34:50 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:34:50 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-17 16:34:50 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:34:50 INFO  CodeGenerator: Code generated in 53.335584 ms
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:58854 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-17 16:34:50 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:34:50 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:34:50 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-17 16:34:50 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-17 16:34:50 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:34:50 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:34:50 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:58854 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:34:50 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:34:50 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:34:50 INFO  CodeGenerator: Code generated in 5.548125 ms
2025-02-17 16:34:50 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-17 16:34:50 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 99 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:34:50 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-17 16:34:50 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,147 s
2025-02-17 16:34:50 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:34:50 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-17 16:34:50 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,177453 s
2025-02-17 16:34:50 INFO  CodeGenerator: Code generated in 4.314166 ms
2025-02-17 16:34:50 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:34:50 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:34:50 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:58854 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-17 16:34:50 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:34:50 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:34:50 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-17 16:34:50 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-17 16:34:50 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:34:50 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:34:50 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:58854 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:34:50 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:34:50 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:34:50 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-17 16:34:50 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-17 16:34:50 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-17 16:34:50 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-17 16:34:50 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-17 16:34:50 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-17 16:34:50 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-17 16:34:50 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:58854 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:58854 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:34:50 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:34:51 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 749 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 847 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 850 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 854 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 854 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 856 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 857 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:34:51 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-17 16:34:51 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 859 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:34:51 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-17 16:34:51 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,875 s
2025-02-17 16:34:51 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:34:51 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-17 16:34:51 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,877533 s
2025-02-17 16:36:06 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-17 16:36:06 INFO  AbstractConnector: Stopped Spark@684b31de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:36:06 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-17 16:36:06 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-17 16:36:06 INFO  MemoryStore: MemoryStore cleared
2025-02-17 16:36:06 INFO  BlockManager: BlockManager stopped
2025-02-17 16:36:06 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-17 16:36:06 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-17 16:36:06 INFO  SparkContext: Successfully stopped SparkContext
2025-02-17 16:36:06 INFO  ShutdownHookManager: Shutdown hook called
2025-02-17 16:36:06 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-b6f162dd-54ee-45d9-b21c-30ceee246611
2025-02-17 16:40:15 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-17 16:40:15 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-17 16:40:15 INFO  SparkContext: Running Spark version 3.3.2
2025-02-17 16:40:15 INFO  ResourceUtils: ==============================================================
2025-02-17 16:40:15 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-17 16:40:15 INFO  ResourceUtils: ==============================================================
2025-02-17 16:40:15 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-17 16:40:15 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-17 16:40:15 INFO  ResourceProfile: Limiting resource is cpu
2025-02-17 16:40:15 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-17 16:40:15 INFO  SecurityManager: Changing view acls to: fabob
2025-02-17 16:40:15 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-17 16:40:15 INFO  SecurityManager: Changing view acls groups to: 
2025-02-17 16:40:15 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-17 16:40:15 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-17 16:40:15 INFO  Utils: Successfully started service 'sparkDriver' on port 59569.
2025-02-17 16:40:15 INFO  SparkEnv: Registering MapOutputTracker
2025-02-17 16:40:15 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-17 16:40:15 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-17 16:40:15 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-17 16:40:15 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-17 16:40:15 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-f19377b0-2fd3-4f9e-8708-0545a8a3bcc5
2025-02-17 16:40:15 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-17 16:40:15 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-17 16:40:15 INFO  log: Logging initialized @1022ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-17 16:40:16 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-17 16:40:16 INFO  Server: Started @1078ms
2025-02-17 16:40:16 INFO  AbstractConnector: Started ServerConnector@1244d2f0{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:40:16 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a6cc2a{/,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-17 16:40:16 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-17 16:40:16 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59572.
2025-02-17 16:40:16 INFO  NettyBlockTransferService: Server created on 172.20.10.2:59572
2025-02-17 16:40:16 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-17 16:40:16 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 59572, None)
2025-02-17 16:40:16 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:59572 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 59572, None)
2025-02-17 16:40:16 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 59572, None)
2025-02-17 16:40:16 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 59572, None)
2025-02-17 16:40:16 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@51a6cc2a{/,null,STOPPED,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575e572f{/jobs,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d3c6593{/jobs/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2dfb885e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1e3e1014{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47b11ec7{/stages,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36aa52d2{/stages/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@633cc6b5{/stages/stage,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@403c3a01{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/stages/pool,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/storage,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/storage/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4462efe1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db4ad1{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/environment,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/environment/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/executors,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/executors/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/static,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d408060{/,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@17ba57f0{/api,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e3ecf5c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@341b13a8{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2d55e826{/metrics/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-17 16:40:16 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70f68288{/SQL,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db1b657{/SQL/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54e12f4c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca30b8a{/static/sql,null,AVAILABLE,@Spark}
2025-02-17 16:40:16 INFO  InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
2025-02-17 16:40:16 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-17 16:40:17 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:40:17 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-17 16:40:17 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:40:17 INFO  CodeGenerator: Code generated in 60.073666 ms
2025-02-17 16:40:17 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:18 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-17 16:40:18 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:40:18 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:40:18 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-17 16:40:18 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-17 16:40:18 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:40:18 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:18 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:59572 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:40:18 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:18 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:40:18 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:40:18 INFO  CodeGenerator: Code generated in 5.97175 ms
2025-02-17 16:40:18 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-17 16:40:18 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:40:18 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-17 16:40:18 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,154 s
2025-02-17 16:40:18 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:40:18 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-17 16:40:18 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,186698 s
2025-02-17 16:40:18 INFO  CodeGenerator: Code generated in 4.438625 ms
2025-02-17 16:40:18 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:40:18 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:40:18 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:18 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-17 16:40:18 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:40:18 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-17 16:40:18 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-17 16:40:18 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-17 16:40:18 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:40:18 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:18 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-17 16:40:18 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:59572 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:18 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:18 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:40:18 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-17 16:40:18 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-17 16:40:18 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-17 16:40:18 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-17 16:40:18 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-17 16:40:18 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-17 16:40:18 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-17 16:40:18 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-17 16:40:18 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-17 16:40:18 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:59572 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:40:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:40:18 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:19 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 735 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:40:19 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 836 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 837 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 837 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:40:19 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 838 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:40:19 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 840 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 839 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:40:19 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-17 16:40:19 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 842 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:40:19 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-17 16:40:19 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,859 s
2025-02-17 16:40:19 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:40:19 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-17 16:40:19 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,861078 s
2025-02-17 16:40:41 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:40:41 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:40:41 INFO  FileSourceStrategy: Output Data Schema: struct<>
2025-02-17 16:40:41 INFO  CodeGenerator: Code generated in 5.429458 ms
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:40:41 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:41 INFO  SparkContext: Created broadcast 4 from count at main.scala:34
2025-02-17 16:40:41 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:40:41 INFO  DAGScheduler: Registering RDD 13 (count at main.scala:34) as input to shuffle 0
2025-02-17 16:40:41 INFO  DAGScheduler: Got map stage job 2 (count at main.scala:34) with 8 output partitions
2025-02-17 16:40:41 INFO  DAGScheduler: Final stage: ShuffleMapStage 2 (count at main.scala:34)
2025-02-17 16:40:41 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:40:41 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:41 INFO  DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at count at main.scala:34), which has no missing parents
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.0 KiB, free 2.2 GiB)
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 2.2 GiB)
2025-02-17 16:40:41 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:59572 (size: 8.5 KiB, free: 2.2 GiB)
2025-02-17 16:40:41 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:41 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at count at main.scala:34) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:40:41 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-17 16:40:41 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-17 16:40:41 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-17 16:40:41 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-17 16:40:41 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-17 16:40:41 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-17 16:40:41 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-17 16:40:41 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:40:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:40:41 INFO  CodeGenerator: Code generated in 3.38575 ms
2025-02-17 16:40:41 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 2098 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 180 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:40:41 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 201 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 201 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:40:41 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 201 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 201 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:40:41 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 200 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:40:41 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 2055 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 201 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 202 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:40:41 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-17 16:40:41 INFO  DAGScheduler: ShuffleMapStage 2 (count at main.scala:34) finished in 0,211 s
2025-02-17 16:40:41 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:40:41 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:40:41 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:40:41 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:40:41 INFO  CodeGenerator: Code generated in 4.088583 ms
2025-02-17 16:40:41 INFO  SparkContext: Starting job: count at main.scala:34
2025-02-17 16:40:41 INFO  DAGScheduler: Got job 3 (count at main.scala:34) with 1 output partitions
2025-02-17 16:40:41 INFO  DAGScheduler: Final stage: ResultStage 4 (count at main.scala:34)
2025-02-17 16:40:41 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
2025-02-17 16:40:41 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:41 INFO  DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at count at main.scala:34), which has no missing parents
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.6 KiB, free 2.2 GiB)
2025-02-17 16:40:41 INFO  MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 2.2 GiB)
2025-02-17 16:40:41 INFO  BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.10.2:59572 (size: 5.6 KiB, free: 2.2 GiB)
2025-02-17 16:40:41 INFO  SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:41 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at count at main.scala:34) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:40:41 INFO  TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
2025-02-17 16:40:41 INFO  TaskSetManager: Starting task 0.0 in stage 4.0 (TID 17) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:40:41 INFO  Executor: Running task 0.0 in stage 4.0 (TID 17)
2025-02-17 16:40:41 INFO  ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:40:41 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
2025-02-17 16:40:41 INFO  Executor: Finished task 0.0 in stage 4.0 (TID 17). 2745 bytes result sent to driver
2025-02-17 16:40:41 INFO  TaskSetManager: Finished task 0.0 in stage 4.0 (TID 17) in 24 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:40:41 INFO  TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-02-17 16:40:41 INFO  DAGScheduler: ResultStage 4 (count at main.scala:34) finished in 0,043 s
2025-02-17 16:40:41 INFO  DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:40:41 INFO  TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
2025-02-17 16:40:41 INFO  DAGScheduler: Job 3 finished: count at main.scala:34, took 0,051308 s
2025-02-17 16:40:51 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:40:51 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:40:51 INFO  FileSourceStrategy: Output Data Schema: struct<categorie: string, montant: double>
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 89.643625 ms
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_7 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  SparkContext: Created broadcast 7 from show at main.scala:45
2025-02-17 16:40:52 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:40:52 INFO  DAGScheduler: Registering RDD 20 (show at main.scala:45) as input to shuffle 1
2025-02-17 16:40:52 INFO  DAGScheduler: Got map stage job 4 (show at main.scala:45) with 8 output partitions
2025-02-17 16:40:52 INFO  DAGScheduler: Final stage: ShuffleMapStage 5 (show at main.scala:45)
2025-02-17 16:40:52 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:40:52 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:52 INFO  DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at show at main.scala:45), which has no missing parents
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_8 stored as values in memory (estimated size 33.6 KiB, free 2.2 GiB)
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.10.2:59572 (size: 15.3 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:52 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at show at main.scala:45) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:40:52 INFO  TaskSchedulerImpl: Adding task set 5.0 with 8 tasks resource profile 0
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 0.0 in stage 5.0 (TID 18) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 1.0 in stage 5.0 (TID 19) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 2.0 in stage 5.0 (TID 20) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 3.0 in stage 5.0 (TID 21) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 4.0 in stage 5.0 (TID 22) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 5.0 in stage 5.0 (TID 23) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 6.0 in stage 5.0 (TID 24) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 7.0 in stage 5.0 (TID 25) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  Executor: Running task 3.0 in stage 5.0 (TID 21)
2025-02-17 16:40:52 INFO  Executor: Running task 2.0 in stage 5.0 (TID 20)
2025-02-17 16:40:52 INFO  Executor: Running task 5.0 in stage 5.0 (TID 23)
2025-02-17 16:40:52 INFO  Executor: Running task 4.0 in stage 5.0 (TID 22)
2025-02-17 16:40:52 INFO  Executor: Running task 6.0 in stage 5.0 (TID 24)
2025-02-17 16:40:52 INFO  Executor: Running task 1.0 in stage 5.0 (TID 19)
2025-02-17 16:40:52 INFO  Executor: Running task 7.0 in stage 5.0 (TID 25)
2025-02-17 16:40:52 INFO  Executor: Running task 0.0 in stage 5.0 (TID 18)
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 11.600791 ms
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 2.880458 ms
2025-02-17 16:40:52 INFO  BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.10.2:59572 in memory (size: 5.6 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 6.562208 ms
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 3.254959 ms
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:40:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:40:52 INFO  BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.10.2:59572 in memory (size: 8.5 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:59572 in memory (size: 8.8 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  Executor: Finished task 7.0 in stage 5.0 (TID 25). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 7.0 in stage 5.0 (TID 25) in 422 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 4.0 in stage 5.0 (TID 22). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 4.0 in stage 5.0 (TID 22) in 484 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 6.0 in stage 5.0 (TID 24). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 6.0 in stage 5.0 (TID 24) in 487 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 2.0 in stage 5.0 (TID 20). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 2.0 in stage 5.0 (TID 20) in 488 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 3.0 in stage 5.0 (TID 21). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 3.0 in stage 5.0 (TID 21) in 489 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 0.0 in stage 5.0 (TID 18). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 0.0 in stage 5.0 (TID 18) in 491 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 1.0 in stage 5.0 (TID 19). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 1.0 in stage 5.0 (TID 19) in 490 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:40:52 INFO  Executor: Finished task 5.0 in stage 5.0 (TID 23). 2858 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 5.0 in stage 5.0 (TID 23) in 491 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:40:52 INFO  TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-02-17 16:40:52 INFO  DAGScheduler: ShuffleMapStage 5 (show at main.scala:45) finished in 0,503 s
2025-02-17 16:40:52 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:40:52 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:40:52 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:40:52 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:40:52 INFO  ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 7.457125 ms
2025-02-17 16:40:52 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 10.682375 ms
2025-02-17 16:40:52 INFO  SparkContext: Starting job: show at main.scala:45
2025-02-17 16:40:52 INFO  DAGScheduler: Got job 5 (show at main.scala:45) with 1 output partitions
2025-02-17 16:40:52 INFO  DAGScheduler: Final stage: ResultStage 7 (show at main.scala:45)
2025-02-17 16:40:52 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
2025-02-17 16:40:52 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:40:52 INFO  DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[24] at show at main.scala:45), which has no missing parents
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_9 stored as values in memory (estimated size 37.5 KiB, free 2.2 GiB)
2025-02-17 16:40:52 INFO  MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 2.2 GiB)
2025-02-17 16:40:52 INFO  BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.10.2:59572 (size: 17.2 KiB, free: 2.2 GiB)
2025-02-17 16:40:52 INFO  SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:40:52 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at show at main.scala:45) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:40:52 INFO  TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
2025-02-17 16:40:52 INFO  TaskSetManager: Starting task 0.0 in stage 7.0 (TID 26) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:40:52 INFO  Executor: Running task 0.0 in stage 7.0 (TID 26)
2025-02-17 16:40:52 INFO  ShuffleBlockFetcherIterator: Getting 8 (2.1 KiB) non-empty blocks including 8 (2.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:40:52 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:40:52 INFO  Executor: Finished task 0.0 in stage 7.0 (TID 26). 6767 bytes result sent to driver
2025-02-17 16:40:52 INFO  TaskSetManager: Finished task 0.0 in stage 7.0 (TID 26) in 27 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:40:52 INFO  TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-02-17 16:40:52 INFO  DAGScheduler: ResultStage 7 (show at main.scala:45) finished in 0,035 s
2025-02-17 16:40:52 INFO  DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:40:52 INFO  TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
2025-02-17 16:40:52 INFO  DAGScheduler: Job 5 finished: show at main.scala:45, took 0,036856 s
2025-02-17 16:40:52 INFO  CodeGenerator: Code generated in 4.841458 ms
2025-02-17 16:42:14 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:42:14 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:42:14 INFO  FileSourceStrategy: Output Data Schema: struct<prix_unitaire: double>
2025-02-17 16:42:14 INFO  CodeGenerator: Code generated in 12.83175 ms
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_10 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:42:14 INFO  BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:42:14 INFO  SparkContext: Created broadcast 10 from show at main.scala:39
2025-02-17 16:42:14 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:42:14 INFO  DAGScheduler: Registering RDD 28 (show at main.scala:39) as input to shuffle 2
2025-02-17 16:42:14 INFO  DAGScheduler: Got map stage job 6 (show at main.scala:39) with 8 output partitions
2025-02-17 16:42:14 INFO  DAGScheduler: Final stage: ShuffleMapStage 8 (show at main.scala:39)
2025-02-17 16:42:14 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:42:14 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:42:14 INFO  DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[28] at show at main.scala:39), which has no missing parents
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_11 stored as values in memory (estimated size 21.4 KiB, free 2.2 GiB)
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 2.2 GiB)
2025-02-17 16:42:14 INFO  BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.10.2:59572 (size: 9.7 KiB, free: 2.2 GiB)
2025-02-17 16:42:14 INFO  SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:42:14 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[28] at show at main.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:42:14 INFO  TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 0.0 in stage 8.0 (TID 27) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 1.0 in stage 8.0 (TID 28) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 2.0 in stage 8.0 (TID 29) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 3.0 in stage 8.0 (TID 30) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 4.0 in stage 8.0 (TID 31) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 5.0 in stage 8.0 (TID 32) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 6.0 in stage 8.0 (TID 33) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 7.0 in stage 8.0 (TID 34) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  Executor: Running task 0.0 in stage 8.0 (TID 27)
2025-02-17 16:42:14 INFO  Executor: Running task 1.0 in stage 8.0 (TID 28)
2025-02-17 16:42:14 INFO  Executor: Running task 2.0 in stage 8.0 (TID 29)
2025-02-17 16:42:14 INFO  Executor: Running task 3.0 in stage 8.0 (TID 30)
2025-02-17 16:42:14 INFO  Executor: Running task 4.0 in stage 8.0 (TID 31)
2025-02-17 16:42:14 INFO  Executor: Running task 5.0 in stage 8.0 (TID 32)
2025-02-17 16:42:14 INFO  Executor: Running task 7.0 in stage 8.0 (TID 34)
2025-02-17 16:42:14 INFO  Executor: Running task 6.0 in stage 8.0 (TID 33)
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:42:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:42:14 INFO  BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.10.2:59572 in memory (size: 17.2 KiB, free: 2.2 GiB)
2025-02-17 16:42:14 INFO  Executor: Finished task 7.0 in stage 8.0 (TID 34). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 7.0 in stage 8.0 (TID 34) in 231 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 3.0 in stage 8.0 (TID 30). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 3.0 in stage 8.0 (TID 30) in 277 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 6.0 in stage 8.0 (TID 33). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  Executor: Finished task 4.0 in stage 8.0 (TID 31). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 6.0 in stage 8.0 (TID 33) in 285 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 4.0 in stage 8.0 (TID 31) in 286 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 2.0 in stage 8.0 (TID 29). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 2.0 in stage 8.0 (TID 29) in 287 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 0.0 in stage 8.0 (TID 27). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 0.0 in stage 8.0 (TID 27) in 287 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 1.0 in stage 8.0 (TID 28). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 1.0 in stage 8.0 (TID 28) in 289 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:42:14 INFO  Executor: Finished task 5.0 in stage 8.0 (TID 32). 2055 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 5.0 in stage 8.0 (TID 32) in 289 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:42:14 INFO  TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-02-17 16:42:14 INFO  DAGScheduler: ShuffleMapStage 8 (show at main.scala:39) finished in 0,295 s
2025-02-17 16:42:14 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:42:14 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:42:14 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:42:14 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:42:14 INFO  CodeGenerator: Code generated in 15.172291 ms
2025-02-17 16:42:14 INFO  SparkContext: Starting job: show at main.scala:39
2025-02-17 16:42:14 INFO  DAGScheduler: Got job 7 (show at main.scala:39) with 1 output partitions
2025-02-17 16:42:14 INFO  DAGScheduler: Final stage: ResultStage 10 (show at main.scala:39)
2025-02-17 16:42:14 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
2025-02-17 16:42:14 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:42:14 INFO  DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[31] at show at main.scala:39), which has no missing parents
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.8 KiB, free 2.2 GiB)
2025-02-17 16:42:14 INFO  MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2025-02-17 16:42:14 INFO  BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.10.2:59572 (size: 7.5 KiB, free: 2.2 GiB)
2025-02-17 16:42:14 INFO  SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:42:14 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[31] at show at main.scala:39) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:42:14 INFO  TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
2025-02-17 16:42:14 INFO  TaskSetManager: Starting task 0.0 in stage 10.0 (TID 35) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:42:14 INFO  Executor: Running task 0.0 in stage 10.0 (TID 35)
2025-02-17 16:42:14 INFO  ShuffleBlockFetcherIterator: Getting 8 (704.0 B) non-empty blocks including 8 (704.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:42:14 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:42:14 INFO  Executor: Finished task 0.0 in stage 10.0 (TID 35). 2741 bytes result sent to driver
2025-02-17 16:42:14 INFO  TaskSetManager: Finished task 0.0 in stage 10.0 (TID 35) in 5 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:42:14 INFO  TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-02-17 16:42:14 INFO  DAGScheduler: ResultStage 10 (show at main.scala:39) finished in 0,008 s
2025-02-17 16:42:14 INFO  DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:42:14 INFO  TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
2025-02-17 16:42:14 INFO  DAGScheduler: Job 7 finished: show at main.scala:39, took 0,008776 s
2025-02-17 16:42:14 INFO  CodeGenerator: Code generated in 4.607834 ms
2025-02-17 16:42:43 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:42:43 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:42:43 INFO  FileSourceStrategy: Output Data Schema: struct<produit: string, quantite: int>
2025-02-17 16:42:43 INFO  CodeGenerator: Code generated in 17.471584 ms
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_13 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:42:43 INFO  BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  SparkContext: Created broadcast 13 from show at main.scala:52
2025-02-17 16:42:43 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:42:43 INFO  DAGScheduler: Registering RDD 35 (show at main.scala:52) as input to shuffle 3
2025-02-17 16:42:43 INFO  DAGScheduler: Got map stage job 8 (show at main.scala:52) with 8 output partitions
2025-02-17 16:42:43 INFO  DAGScheduler: Final stage: ShuffleMapStage 11 (show at main.scala:52)
2025-02-17 16:42:43 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:42:43 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:42:43 INFO  DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[35] at show at main.scala:52), which has no missing parents
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_14 stored as values in memory (estimated size 34.3 KiB, free 2.2 GiB)
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 2.2 GiB)
2025-02-17 16:42:43 INFO  BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.10.2:59572 (size: 15.7 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:42:43 INFO  BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[35] at show at main.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:42:43 INFO  TaskSchedulerImpl: Adding task set 11.0 with 8 tasks resource profile 0
2025-02-17 16:42:43 INFO  BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.10.2:59572 in memory (size: 9.7 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 0.0 in stage 11.0 (TID 36) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 1.0 in stage 11.0 (TID 37) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 2.0 in stage 11.0 (TID 38) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 3.0 in stage 11.0 (TID 39) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 4.0 in stage 11.0 (TID 40) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 5.0 in stage 11.0 (TID 41) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 6.0 in stage 11.0 (TID 42) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 7.0 in stage 11.0 (TID 43) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  Executor: Running task 3.0 in stage 11.0 (TID 39)
2025-02-17 16:42:43 INFO  Executor: Running task 2.0 in stage 11.0 (TID 38)
2025-02-17 16:42:43 INFO  Executor: Running task 0.0 in stage 11.0 (TID 36)
2025-02-17 16:42:43 INFO  Executor: Running task 1.0 in stage 11.0 (TID 37)
2025-02-17 16:42:43 INFO  Executor: Running task 6.0 in stage 11.0 (TID 42)
2025-02-17 16:42:43 INFO  Executor: Running task 4.0 in stage 11.0 (TID 40)
2025-02-17 16:42:43 INFO  Executor: Running task 7.0 in stage 11.0 (TID 43)
2025-02-17 16:42:43 INFO  Executor: Running task 5.0 in stage 11.0 (TID 41)
2025-02-17 16:42:43 INFO  BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.10.2:59572 in memory (size: 7.5 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  CodeGenerator: Code generated in 2.833875 ms
2025-02-17 16:42:43 INFO  CodeGenerator: Code generated in 2.537959 ms
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:42:43 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:42:43 INFO  CodeGenerator: Code generated in 2.258 ms
2025-02-17 16:42:43 INFO  Executor: Finished task 7.0 in stage 11.0 (TID 43). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 7.0 in stage 11.0 (TID 43) in 272 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 4.0 in stage 11.0 (TID 40). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 4.0 in stage 11.0 (TID 40) in 324 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 6.0 in stage 11.0 (TID 42). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 6.0 in stage 11.0 (TID 42) in 327 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 0.0 in stage 11.0 (TID 36). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  Executor: Finished task 2.0 in stage 11.0 (TID 38). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 0.0 in stage 11.0 (TID 36) in 333 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 2.0 in stage 11.0 (TID 38) in 333 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 5.0 in stage 11.0 (TID 41). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 5.0 in stage 11.0 (TID 41) in 333 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 1.0 in stage 11.0 (TID 37). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 1.0 in stage 11.0 (TID 37) in 337 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:42:43 INFO  Executor: Finished task 3.0 in stage 11.0 (TID 39). 2858 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 3.0 in stage 11.0 (TID 39) in 337 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:42:43 INFO  TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-02-17 16:42:43 INFO  DAGScheduler: ShuffleMapStage 11 (show at main.scala:52) finished in 0,355 s
2025-02-17 16:42:43 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:42:43 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:42:43 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:42:43 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:42:43 INFO  ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:42:43 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:42:43 INFO  CodeGenerator: Code generated in 9.227042 ms
2025-02-17 16:42:43 INFO  SparkContext: Starting job: show at main.scala:52
2025-02-17 16:42:43 INFO  DAGScheduler: Got job 9 (show at main.scala:52) with 1 output partitions
2025-02-17 16:42:43 INFO  DAGScheduler: Final stage: ResultStage 13 (show at main.scala:52)
2025-02-17 16:42:43 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
2025-02-17 16:42:43 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:42:43 INFO  DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[39] at show at main.scala:52), which has no missing parents
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_15 stored as values in memory (estimated size 38.1 KiB, free 2.2 GiB)
2025-02-17 16:42:43 INFO  MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 2.2 GiB)
2025-02-17 16:42:43 INFO  BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.10.2:59572 (size: 17.5 KiB, free: 2.2 GiB)
2025-02-17 16:42:43 INFO  SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:42:43 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[39] at show at main.scala:52) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:42:43 INFO  TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
2025-02-17 16:42:43 INFO  TaskSetManager: Starting task 0.0 in stage 13.0 (TID 44) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:42:43 INFO  Executor: Running task 0.0 in stage 13.0 (TID 44)
2025-02-17 16:42:43 INFO  ShuffleBlockFetcherIterator: Getting 8 (5.1 KiB) non-empty blocks including 8 (5.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:42:43 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:42:43 INFO  Executor: Finished task 0.0 in stage 13.0 (TID 44). 6798 bytes result sent to driver
2025-02-17 16:42:43 INFO  TaskSetManager: Finished task 0.0 in stage 13.0 (TID 44) in 8 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:42:43 INFO  TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-02-17 16:42:43 INFO  DAGScheduler: ResultStage 13 (show at main.scala:52) finished in 0,011 s
2025-02-17 16:42:43 INFO  DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:42:43 INFO  TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
2025-02-17 16:42:43 INFO  DAGScheduler: Job 9 finished: show at main.scala:52, took 0,012739 s
2025-02-17 16:45:44 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:45:44 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:45:44 INFO  FileSourceStrategy: Output Data Schema: struct<quantite: int, date_achat: timestamp>
2025-02-17 16:45:44 INFO  CodeGenerator: Code generated in 15.986417 ms
2025-02-17 16:45:44 INFO  MemoryStore: Block broadcast_16 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:45:44 INFO  BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.10.2:59572 in memory (size: 17.5 KiB, free: 2.2 GiB)
2025-02-17 16:45:44 INFO  BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:45:44 INFO  BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.10.2:59572 in memory (size: 15.7 KiB, free: 2.2 GiB)
2025-02-17 16:45:44 INFO  MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:45:44 INFO  BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:45:44 INFO  SparkContext: Created broadcast 16 from show at main.scala:64
2025-02-17 16:45:44 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:45:44 INFO  DAGScheduler: Registering RDD 43 (show at main.scala:64) as input to shuffle 4
2025-02-17 16:45:44 INFO  DAGScheduler: Got map stage job 10 (show at main.scala:64) with 8 output partitions
2025-02-17 16:45:44 INFO  DAGScheduler: Final stage: ShuffleMapStage 14 (show at main.scala:64)
2025-02-17 16:45:44 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:45:44 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:45:44 INFO  DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[43] at show at main.scala:64), which has no missing parents
2025-02-17 16:45:44 INFO  MemoryStore: Block broadcast_17 stored as values in memory (estimated size 36.2 KiB, free 2.2 GiB)
2025-02-17 16:45:44 INFO  MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 2.2 GiB)
2025-02-17 16:45:44 INFO  BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.10.2:59572 (size: 16.6 KiB, free: 2.2 GiB)
2025-02-17 16:45:44 INFO  SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:45:44 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[43] at show at main.scala:64) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:45:44 INFO  TaskSchedulerImpl: Adding task set 14.0 with 8 tasks resource profile 0
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 0.0 in stage 14.0 (TID 45) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 1.0 in stage 14.0 (TID 46) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 2.0 in stage 14.0 (TID 47) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 3.0 in stage 14.0 (TID 48) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 4.0 in stage 14.0 (TID 49) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 5.0 in stage 14.0 (TID 50) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 6.0 in stage 14.0 (TID 51) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  TaskSetManager: Starting task 7.0 in stage 14.0 (TID 52) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:44 INFO  Executor: Running task 0.0 in stage 14.0 (TID 45)
2025-02-17 16:45:44 INFO  Executor: Running task 1.0 in stage 14.0 (TID 46)
2025-02-17 16:45:44 INFO  Executor: Running task 2.0 in stage 14.0 (TID 47)
2025-02-17 16:45:44 INFO  Executor: Running task 3.0 in stage 14.0 (TID 48)
2025-02-17 16:45:44 INFO  Executor: Running task 4.0 in stage 14.0 (TID 49)
2025-02-17 16:45:44 INFO  Executor: Running task 5.0 in stage 14.0 (TID 50)
2025-02-17 16:45:44 INFO  Executor: Running task 6.0 in stage 14.0 (TID 51)
2025-02-17 16:45:44 INFO  Executor: Running task 7.0 in stage 14.0 (TID 52)
2025-02-17 16:45:44 INFO  CodeGenerator: Code generated in 4.686042 ms
2025-02-17 16:45:44 INFO  CodeGenerator: Code generated in 2.472292 ms
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:45:44 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:45:44 INFO  CodeGenerator: Code generated in 2.366084 ms
2025-02-17 16:45:44 INFO  Executor: Finished task 7.0 in stage 14.0 (TID 52). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 7.0 in stage 14.0 (TID 52) in 404 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 2.0 in stage 14.0 (TID 47). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 2.0 in stage 14.0 (TID 47) in 489 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 6.0 in stage 14.0 (TID 51). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 6.0 in stage 14.0 (TID 51) in 496 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 1.0 in stage 14.0 (TID 46). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 1.0 in stage 14.0 (TID 46) in 501 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 4.0 in stage 14.0 (TID 49). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 4.0 in stage 14.0 (TID 49) in 501 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 5.0 in stage 14.0 (TID 50). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 5.0 in stage 14.0 (TID 50) in 502 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 0.0 in stage 14.0 (TID 45). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 0.0 in stage 14.0 (TID 45) in 504 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 3.0 in stage 14.0 (TID 48). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 3.0 in stage 14.0 (TID 48) in 503 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-02-17 16:45:45 INFO  DAGScheduler: ShuffleMapStage 14 (show at main.scala:64) finished in 0,508 s
2025-02-17 16:45:45 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:45:45 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:45:45 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:45:45 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:45:45 INFO  ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:45:45 INFO  CodeGenerator: Code generated in 3.684333 ms
2025-02-17 16:45:45 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:45:45 INFO  CodeGenerator: Code generated in 6.229 ms
2025-02-17 16:45:45 INFO  SparkContext: Starting job: show at main.scala:64
2025-02-17 16:45:45 INFO  DAGScheduler: Got job 11 (show at main.scala:64) with 1 output partitions
2025-02-17 16:45:45 INFO  DAGScheduler: Final stage: ResultStage 16 (show at main.scala:64)
2025-02-17 16:45:45 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
2025-02-17 16:45:45 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[47] at show at main.scala:64), which has no missing parents
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_18 stored as values in memory (estimated size 39.6 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 18.2 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.10.2:59572 (size: 18.2 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[47] at show at main.scala:64) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 0.0 in stage 16.0 (TID 53) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  Executor: Running task 0.0 in stage 16.0 (TID 53)
2025-02-17 16:45:45 INFO  ShuffleBlockFetcherIterator: Getting 8 (6.2 KiB) non-empty blocks including 8 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:45:45 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:45:45 INFO  Executor: Finished task 0.0 in stage 16.0 (TID 53). 6975 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 0.0 in stage 16.0 (TID 53) in 9 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-02-17 16:45:45 INFO  DAGScheduler: ResultStage 16 (show at main.scala:64) finished in 0,013 s
2025-02-17 16:45:45 INFO  DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
2025-02-17 16:45:45 INFO  DAGScheduler: Job 11 finished: show at main.scala:64, took 0,014346 s
2025-02-17 16:45:45 INFO  CodeGenerator: Code generated in 2.5505 ms
2025-02-17 16:45:45 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:45:45 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:45:45 INFO  FileSourceStrategy: Output Data Schema: struct<quantite: int, date_achat: timestamp>
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_19 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  SparkContext: Created broadcast 19 from show at main.scala:67
2025-02-17 16:45:45 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:45:45 INFO  DAGScheduler: Registering RDD 51 (show at main.scala:67) as input to shuffle 5
2025-02-17 16:45:45 INFO  DAGScheduler: Got map stage job 12 (show at main.scala:67) with 8 output partitions
2025-02-17 16:45:45 INFO  DAGScheduler: Final stage: ShuffleMapStage 17 (show at main.scala:67)
2025-02-17 16:45:45 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:45:45 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[51] at show at main.scala:67), which has no missing parents
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_20 stored as values in memory (estimated size 36.4 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.7 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.10.2:59572 (size: 16.7 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[51] at show at main.scala:67) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Adding task set 17.0 with 8 tasks resource profile 0
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 0.0 in stage 17.0 (TID 54) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 1.0 in stage 17.0 (TID 55) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 2.0 in stage 17.0 (TID 56) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 3.0 in stage 17.0 (TID 57) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 4.0 in stage 17.0 (TID 58) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 5.0 in stage 17.0 (TID 59) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 6.0 in stage 17.0 (TID 60) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 7.0 in stage 17.0 (TID 61) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  Executor: Running task 3.0 in stage 17.0 (TID 57)
2025-02-17 16:45:45 INFO  Executor: Running task 0.0 in stage 17.0 (TID 54)
2025-02-17 16:45:45 INFO  Executor: Running task 1.0 in stage 17.0 (TID 55)
2025-02-17 16:45:45 INFO  Executor: Running task 5.0 in stage 17.0 (TID 59)
2025-02-17 16:45:45 INFO  Executor: Running task 4.0 in stage 17.0 (TID 58)
2025-02-17 16:45:45 INFO  Executor: Running task 6.0 in stage 17.0 (TID 60)
2025-02-17 16:45:45 INFO  Executor: Running task 2.0 in stage 17.0 (TID 56)
2025-02-17 16:45:45 INFO  Executor: Running task 7.0 in stage 17.0 (TID 61)
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:45:45 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:45:45 INFO  BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.10.2:59572 in memory (size: 18.2 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.10.2:59572 in memory (size: 16.6 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  Executor: Finished task 7.0 in stage 17.0 (TID 61). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 7.0 in stage 17.0 (TID 61) in 289 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 2.0 in stage 17.0 (TID 56). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 2.0 in stage 17.0 (TID 56) in 389 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 6.0 in stage 17.0 (TID 60). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 6.0 in stage 17.0 (TID 60) in 394 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 1.0 in stage 17.0 (TID 55). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  Executor: Finished task 5.0 in stage 17.0 (TID 59). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 1.0 in stage 17.0 (TID 55) in 398 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 0.0 in stage 17.0 (TID 54). 2901 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 5.0 in stage 17.0 (TID 59) in 400 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 0.0 in stage 17.0 (TID 54) in 401 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 4.0 in stage 17.0 (TID 58). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 4.0 in stage 17.0 (TID 58) in 404 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:45:45 INFO  Executor: Finished task 3.0 in stage 17.0 (TID 57). 2858 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 3.0 in stage 17.0 (TID 57) in 408 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-02-17 16:45:45 INFO  DAGScheduler: ShuffleMapStage 17 (show at main.scala:67) finished in 0,411 s
2025-02-17 16:45:45 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:45:45 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:45:45 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:45:45 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:45:45 INFO  ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:45:45 INFO  CodeGenerator: Code generated in 2.91025 ms
2025-02-17 16:45:45 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:45:45 INFO  SparkContext: Starting job: show at main.scala:67
2025-02-17 16:45:45 INFO  DAGScheduler: Got job 13 (show at main.scala:67) with 1 output partitions
2025-02-17 16:45:45 INFO  DAGScheduler: Final stage: ResultStage 19 (show at main.scala:67)
2025-02-17 16:45:45 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
2025-02-17 16:45:45 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[56] at show at main.scala:67), which has no missing parents
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_21 stored as values in memory (estimated size 43.0 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 2.2 GiB)
2025-02-17 16:45:45 INFO  BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.10.2:59572 (size: 19.6 KiB, free: 2.2 GiB)
2025-02-17 16:45:45 INFO  SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:45:45 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[56] at show at main.scala:67) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
2025-02-17 16:45:45 INFO  TaskSetManager: Starting task 0.0 in stage 19.0 (TID 62) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:45:45 INFO  Executor: Running task 0.0 in stage 19.0 (TID 62)
2025-02-17 16:45:45 INFO  ShuffleBlockFetcherIterator: Getting 8 (6.2 KiB) non-empty blocks including 8 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:45:45 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:45:45 INFO  Executor: Finished task 0.0 in stage 19.0 (TID 62). 4512 bytes result sent to driver
2025-02-17 16:45:45 INFO  TaskSetManager: Finished task 0.0 in stage 19.0 (TID 62) in 9 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
2025-02-17 16:45:45 INFO  DAGScheduler: ResultStage 19 (show at main.scala:67) finished in 0,011 s
2025-02-17 16:45:45 INFO  DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:45:45 INFO  TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
2025-02-17 16:45:45 INFO  DAGScheduler: Job 13 finished: show at main.scala:67, took 0,012543 s
2025-02-17 16:46:28 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:46:28 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:46:28 INFO  FileSourceStrategy: Output Data Schema: struct<montant: double, date_achat: timestamp>
2025-02-17 16:46:28 INFO  CodeGenerator: Code generated in 25.880709 ms
2025-02-17 16:46:28 INFO  MemoryStore: Block broadcast_22 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:46:28 INFO  MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:46:28 INFO  BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:46:28 INFO  SparkContext: Created broadcast 22 from show at main.scala:76
2025-02-17 16:46:28 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:46:28 INFO  DAGScheduler: Registering RDD 60 (show at main.scala:76) as input to shuffle 6
2025-02-17 16:46:28 INFO  DAGScheduler: Got map stage job 14 (show at main.scala:76) with 8 output partitions
2025-02-17 16:46:28 INFO  DAGScheduler: Final stage: ShuffleMapStage 20 (show at main.scala:76)
2025-02-17 16:46:28 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:46:28 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:46:28 INFO  DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[60] at show at main.scala:76), which has no missing parents
2025-02-17 16:46:28 INFO  MemoryStore: Block broadcast_23 stored as values in memory (estimated size 36.0 KiB, free 2.2 GiB)
2025-02-17 16:46:28 INFO  MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 2.2 GiB)
2025-02-17 16:46:28 INFO  BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.10.2:59572 (size: 16.5 KiB, free: 2.2 GiB)
2025-02-17 16:46:28 INFO  SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:46:28 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[60] at show at main.scala:76) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:46:28 INFO  TaskSchedulerImpl: Adding task set 20.0 with 8 tasks resource profile 0
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 0.0 in stage 20.0 (TID 63) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 1.0 in stage 20.0 (TID 64) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 2.0 in stage 20.0 (TID 65) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 3.0 in stage 20.0 (TID 66) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 4.0 in stage 20.0 (TID 67) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 5.0 in stage 20.0 (TID 68) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 6.0 in stage 20.0 (TID 69) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  TaskSetManager: Starting task 7.0 in stage 20.0 (TID 70) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:28 INFO  Executor: Running task 5.0 in stage 20.0 (TID 68)
2025-02-17 16:46:28 INFO  Executor: Running task 2.0 in stage 20.0 (TID 65)
2025-02-17 16:46:28 INFO  Executor: Running task 0.0 in stage 20.0 (TID 63)
2025-02-17 16:46:28 INFO  Executor: Running task 1.0 in stage 20.0 (TID 64)
2025-02-17 16:46:28 INFO  Executor: Running task 3.0 in stage 20.0 (TID 66)
2025-02-17 16:46:28 INFO  Executor: Running task 4.0 in stage 20.0 (TID 67)
2025-02-17 16:46:28 INFO  Executor: Running task 7.0 in stage 20.0 (TID 70)
2025-02-17 16:46:28 INFO  Executor: Running task 6.0 in stage 20.0 (TID 69)
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:46:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:46:28 INFO  CodeGenerator: Code generated in 3.262625 ms
2025-02-17 16:46:29 INFO  BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.10.2:59572 in memory (size: 19.6 KiB, free: 2.2 GiB)
2025-02-17 16:46:29 INFO  BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:46:29 INFO  BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.10.2:59572 in memory (size: 16.7 KiB, free: 2.2 GiB)
2025-02-17 16:46:29 INFO  Executor: Finished task 7.0 in stage 20.0 (TID 70). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 7.0 in stage 20.0 (TID 70) in 302 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 4.0 in stage 20.0 (TID 67). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 4.0 in stage 20.0 (TID 67) in 444 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 2.0 in stage 20.0 (TID 65). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 2.0 in stage 20.0 (TID 65) in 448 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 0.0 in stage 20.0 (TID 63). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 0.0 in stage 20.0 (TID 63) in 450 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 1.0 in stage 20.0 (TID 64). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 1.0 in stage 20.0 (TID 64) in 455 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 5.0 in stage 20.0 (TID 68). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 5.0 in stage 20.0 (TID 68) in 455 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 3.0 in stage 20.0 (TID 66). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 3.0 in stage 20.0 (TID 66) in 458 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:46:29 INFO  Executor: Finished task 6.0 in stage 20.0 (TID 69). 2858 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 6.0 in stage 20.0 (TID 69) in 459 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:46:29 INFO  TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
2025-02-17 16:46:29 INFO  DAGScheduler: ShuffleMapStage 20 (show at main.scala:76) finished in 0,463 s
2025-02-17 16:46:29 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:46:29 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:46:29 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:46:29 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:46:29 INFO  ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:46:29 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:46:29 INFO  CodeGenerator: Code generated in 8.241042 ms
2025-02-17 16:46:29 INFO  SparkContext: Starting job: show at main.scala:76
2025-02-17 16:46:29 INFO  DAGScheduler: Got job 15 (show at main.scala:76) with 1 output partitions
2025-02-17 16:46:29 INFO  DAGScheduler: Final stage: ResultStage 22 (show at main.scala:76)
2025-02-17 16:46:29 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
2025-02-17 16:46:29 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:46:29 INFO  DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[64] at show at main.scala:76), which has no missing parents
2025-02-17 16:46:29 INFO  MemoryStore: Block broadcast_24 stored as values in memory (estimated size 39.5 KiB, free 2.2 GiB)
2025-02-17 16:46:29 INFO  MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 18.2 KiB, free 2.2 GiB)
2025-02-17 16:46:29 INFO  BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.10.2:59572 (size: 18.2 KiB, free: 2.2 GiB)
2025-02-17 16:46:29 INFO  SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:46:29 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[64] at show at main.scala:76) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:46:29 INFO  TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
2025-02-17 16:46:29 INFO  TaskSetManager: Starting task 0.0 in stage 22.0 (TID 71) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:46:29 INFO  Executor: Running task 0.0 in stage 22.0 (TID 71)
2025-02-17 16:46:29 INFO  ShuffleBlockFetcherIterator: Getting 8 (6.2 KiB) non-empty blocks including 8 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:46:29 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:46:29 INFO  Executor: Finished task 0.0 in stage 22.0 (TID 71). 7071 bytes result sent to driver
2025-02-17 16:46:29 INFO  TaskSetManager: Finished task 0.0 in stage 22.0 (TID 71) in 10 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:46:29 INFO  TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
2025-02-17 16:46:29 INFO  DAGScheduler: ResultStage 22 (show at main.scala:76) finished in 0,013 s
2025-02-17 16:46:29 INFO  DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:46:29 INFO  TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
2025-02-17 16:46:29 INFO  DAGScheduler: Job 15 finished: show at main.scala:76, took 0,014132 s
2025-02-17 16:46:48 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-17 16:46:48 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-17 16:46:48 INFO  FileSourceStrategy: Output Data Schema: struct<montant: double, date_achat: timestamp>
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_25 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-17 16:46:48 INFO  BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.10.2:59572 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  SparkContext: Created broadcast 25 from show at main.scala:88
2025-02-17 16:46:48 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-17 16:46:48 INFO  DAGScheduler: Registering RDD 68 (show at main.scala:88) as input to shuffle 7
2025-02-17 16:46:48 INFO  DAGScheduler: Got map stage job 16 (show at main.scala:88) with 8 output partitions
2025-02-17 16:46:48 INFO  DAGScheduler: Final stage: ShuffleMapStage 23 (show at main.scala:88)
2025-02-17 16:46:48 INFO  DAGScheduler: Parents of final stage: List()
2025-02-17 16:46:48 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:46:48 INFO  DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[68] at show at main.scala:88), which has no missing parents
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_26 stored as values in memory (estimated size 36.0 KiB, free 2.2 GiB)
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 2.2 GiB)
2025-02-17 16:46:48 INFO  BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.10.2:59572 (size: 16.5 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:46:48 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[68] at show at main.scala:88) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-17 16:46:48 INFO  TaskSchedulerImpl: Adding task set 23.0 with 8 tasks resource profile 0
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 0.0 in stage 23.0 (TID 72) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 1.0 in stage 23.0 (TID 73) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 2.0 in stage 23.0 (TID 74) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 3.0 in stage 23.0 (TID 75) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 4.0 in stage 23.0 (TID 76) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 5.0 in stage 23.0 (TID 77) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 6.0 in stage 23.0 (TID 78) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 7.0 in stage 23.0 (TID 79) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7904 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  Executor: Running task 0.0 in stage 23.0 (TID 72)
2025-02-17 16:46:48 INFO  Executor: Running task 2.0 in stage 23.0 (TID 74)
2025-02-17 16:46:48 INFO  Executor: Running task 7.0 in stage 23.0 (TID 79)
2025-02-17 16:46:48 INFO  Executor: Running task 5.0 in stage 23.0 (TID 77)
2025-02-17 16:46:48 INFO  Executor: Running task 3.0 in stage 23.0 (TID 75)
2025-02-17 16:46:48 INFO  Executor: Running task 1.0 in stage 23.0 (TID 73)
2025-02-17 16:46:48 INFO  Executor: Running task 6.0 in stage 23.0 (TID 78)
2025-02-17 16:46:48 INFO  Executor: Running task 4.0 in stage 23.0 (TID 76)
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-17 16:46:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-17 16:46:48 INFO  BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.10.2:59572 in memory (size: 18.2 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.10.2:59572 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  Executor: Finished task 7.0 in stage 23.0 (TID 79). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 7.0 in stage 23.0 (TID 79) in 144 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-17 16:46:48 INFO  BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.10.2:59572 in memory (size: 16.5 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  Executor: Finished task 5.0 in stage 23.0 (TID 77). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 5.0 in stage 23.0 (TID 77) in 193 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 1.0 in stage 23.0 (TID 73). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 1.0 in stage 23.0 (TID 73) in 211 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 2.0 in stage 23.0 (TID 74). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 2.0 in stage 23.0 (TID 74) in 212 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 6.0 in stage 23.0 (TID 78). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 6.0 in stage 23.0 (TID 78) in 214 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 4.0 in stage 23.0 (TID 76). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 4.0 in stage 23.0 (TID 76) in 217 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 0.0 in stage 23.0 (TID 72). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 0.0 in stage 23.0 (TID 72) in 220 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-17 16:46:48 INFO  Executor: Finished task 3.0 in stage 23.0 (TID 75). 2858 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 3.0 in stage 23.0 (TID 75) in 233 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-17 16:46:48 INFO  TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
2025-02-17 16:46:48 INFO  DAGScheduler: ShuffleMapStage 23 (show at main.scala:88) finished in 0,236 s
2025-02-17 16:46:48 INFO  DAGScheduler: looking for newly runnable stages
2025-02-17 16:46:48 INFO  DAGScheduler: running: HashSet()
2025-02-17 16:46:48 INFO  DAGScheduler: waiting: HashSet()
2025-02-17 16:46:48 INFO  DAGScheduler: failed: HashSet()
2025-02-17 16:46:48 INFO  ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-02-17 16:46:48 INFO  HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-02-17 16:46:48 INFO  SparkContext: Starting job: show at main.scala:88
2025-02-17 16:46:48 INFO  DAGScheduler: Got job 17 (show at main.scala:88) with 1 output partitions
2025-02-17 16:46:48 INFO  DAGScheduler: Final stage: ResultStage 25 (show at main.scala:88)
2025-02-17 16:46:48 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
2025-02-17 16:46:48 INFO  DAGScheduler: Missing parents: List()
2025-02-17 16:46:48 INFO  DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[73] at show at main.scala:88), which has no missing parents
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_27 stored as values in memory (estimated size 42.9 KiB, free 2.2 GiB)
2025-02-17 16:46:48 INFO  MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 2.2 GiB)
2025-02-17 16:46:48 INFO  BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.10.2:59572 (size: 19.5 KiB, free: 2.2 GiB)
2025-02-17 16:46:48 INFO  SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
2025-02-17 16:46:48 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[73] at show at main.scala:88) (first 15 tasks are for partitions Vector(0))
2025-02-17 16:46:48 INFO  TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
2025-02-17 16:46:48 INFO  TaskSetManager: Starting task 0.0 in stage 25.0 (TID 80) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7399 bytes) taskResourceAssignments Map()
2025-02-17 16:46:48 INFO  Executor: Running task 0.0 in stage 25.0 (TID 80)
2025-02-17 16:46:48 INFO  ShuffleBlockFetcherIterator: Getting 8 (6.2 KiB) non-empty blocks including 8 (6.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-17 16:46:48 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2025-02-17 16:46:48 INFO  Executor: Finished task 0.0 in stage 25.0 (TID 80). 4640 bytes result sent to driver
2025-02-17 16:46:48 INFO  TaskSetManager: Finished task 0.0 in stage 25.0 (TID 80) in 6 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-17 16:46:48 INFO  TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
2025-02-17 16:46:48 INFO  DAGScheduler: ResultStage 25 (show at main.scala:88) finished in 0,007 s
2025-02-17 16:46:48 INFO  DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-17 16:46:48 INFO  TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
2025-02-17 16:46:48 INFO  DAGScheduler: Job 17 finished: show at main.scala:88, took 0,008947 s
2025-02-17 16:47:46 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-17 16:47:46 INFO  AbstractConnector: Stopped Spark@1244d2f0{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-17 16:47:46 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-17 16:47:46 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-17 16:47:46 INFO  MemoryStore: MemoryStore cleared
2025-02-17 16:47:46 INFO  BlockManager: BlockManager stopped
2025-02-17 16:47:46 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-17 16:47:46 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-17 16:47:46 INFO  SparkContext: Successfully stopped SparkContext
2025-02-17 16:47:46 INFO  ShutdownHookManager: Shutdown hook called
2025-02-17 16:47:46 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-27b9b073-9501-4b8a-8d8e-5a83e7040d91
2025-02-24 10:07:38 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:07:38 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:07:38 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:07:38 INFO  ResourceUtils: ==============================================================
2025-02-24 10:07:38 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:07:38 INFO  ResourceUtils: ==============================================================
2025-02-24 10:07:38 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:07:38 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:07:38 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:07:38 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:07:38 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:07:38 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:07:38 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:07:38 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:07:38 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:07:38 INFO  Utils: Successfully started service 'sparkDriver' on port 55072.
2025-02-24 10:07:38 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:07:38 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:07:38 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:07:38 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:07:38 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:07:38 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-c2073792-8857-4d54-a6c1-7de019007d2c
2025-02-24 10:07:38 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:07:38 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:07:38 INFO  log: Logging initialized @1099ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:07:38 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:07:38 INFO  Server: Started @1156ms
2025-02-24 10:07:38 INFO  AbstractConnector: Started ServerConnector@cde5b18{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:07:38 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a0094c9{/,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:07:38 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:07:38 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55075.
2025-02-24 10:07:38 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55075
2025-02-24 10:07:38 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:07:38 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55075, None)
2025-02-24 10:07:38 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55075 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55075, None)
2025-02-24 10:07:38 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55075, None)
2025-02-24 10:07:38 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55075, None)
2025-02-24 10:07:38 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@6a0094c9{/,null,STOPPED,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@43bf5397{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58015e56{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3456558{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6cbe7d4d{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3679d92e{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@332bcab0{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6342ff7f{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2daf06fc{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/static,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6dc9da2d{/,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68a78f3c{/api,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@290e8cab{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@67507df{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:07:38 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3dc95b8b{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:07:39 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:07:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@65a9ea3c{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@46911148{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db33feb{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58658f63{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21263314{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:07:39 INFO  InMemoryFileIndex: It took 20 ms to list leaf files for 1 paths.
2025-02-24 10:07:39 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 10:07:40 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:07:40 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:07:40 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:07:40 INFO  CodeGenerator: Code generated in 58.877208 ms
2025-02-24 10:07:40 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55075 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:07:41 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:07:41 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:07:41 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:07:41 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:07:41 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:07:41 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:07:41 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:07:41 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55075 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:07:41 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:07:41 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:07:41 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:07:41 INFO  CodeGenerator: Code generated in 5.116125 ms
2025-02-24 10:07:41 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:07:41 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 99 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:07:41 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:07:41 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,152 s
2025-02-24 10:07:41 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:07:41 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:07:41 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,181205 s
2025-02-24 10:07:41 INFO  CodeGenerator: Code generated in 4.085 ms
2025-02-24 10:07:41 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:07:41 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:07:41 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55075 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:07:41 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:07:41 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:07:41 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:07:41 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:07:41 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:07:41 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:07:41 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:07:41 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:07:41 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55075 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:07:41 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:07:41 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:07:41 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:07:41 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:07:41 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:07:41 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:07:41 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:07:41 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:07:41 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:07:41 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:07:41 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:07:41 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:07:41 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55075 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:07:41 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:55075 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:07:42 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 793 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:07:42 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 949 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:07:42 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 951 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 951 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 951 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:07:42 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 952 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:07:42 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 953 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:07:42 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 953 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:07:42 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:07:42 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,965 s
2025-02-24 10:07:42 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:07:42 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:07:42 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,966496 s
2025-02-24 10:07:42 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:07:42 INFO  AbstractConnector: Stopped Spark@cde5b18{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:07:42 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 10:07:42 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:07:42 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:07:42 INFO  BlockManager: BlockManager stopped
2025-02-24 10:07:42 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:07:42 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:07:42 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:07:42 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:07:42 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-49f5b437-469a-4203-ac45-55ec984120f8
2025-02-24 10:08:34 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:08:34 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:08:34 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:08:34 INFO  ResourceUtils: ==============================================================
2025-02-24 10:08:34 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:08:34 INFO  ResourceUtils: ==============================================================
2025-02-24 10:08:34 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:08:34 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:08:34 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:08:34 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:08:34 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:08:34 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:08:34 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:08:34 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:08:34 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:08:35 INFO  Utils: Successfully started service 'sparkDriver' on port 55388.
2025-02-24 10:08:35 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:08:35 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:08:35 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:08:35 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:08:35 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:08:35 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-89516512-9078-4a96-b3f0-d880e94660ec
2025-02-24 10:08:35 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:08:35 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:08:35 INFO  log: Logging initialized @1005ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:08:35 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:08:35 INFO  Server: Started @1063ms
2025-02-24 10:08:35 INFO  AbstractConnector: Started ServerConnector@278667fd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:08:35 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a6cc2a{/,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:08:35 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:08:35 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55391.
2025-02-24 10:08:35 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55391
2025-02-24 10:08:35 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:08:35 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55391, None)
2025-02-24 10:08:35 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55391 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55391, None)
2025-02-24 10:08:35 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55391, None)
2025-02-24 10:08:35 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55391, None)
2025-02-24 10:08:35 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@51a6cc2a{/,null,STOPPED,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575e572f{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d3c6593{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2dfb885e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1e3e1014{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47b11ec7{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36aa52d2{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@633cc6b5{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@403c3a01{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4462efe1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db4ad1{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/static,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d408060{/,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@17ba57f0{/api,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e3ecf5c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@341b13a8{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2d55e826{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:08:35 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70f68288{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db1b657{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54e12f4c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca30b8a{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:08:35 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 10:08:35 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 10:08:36 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:08:36 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:08:36 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:08:37 INFO  CodeGenerator: Code generated in 53.23275 ms
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55391 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:08:37 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:08:37 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:08:37 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:08:37 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:08:37 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:08:37 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:08:37 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:08:37 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55391 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:08:37 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:08:37 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:08:37 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:08:37 INFO  CodeGenerator: Code generated in 5.586375 ms
2025-02-24 10:08:37 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:08:37 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 88 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:08:37 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:08:37 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,140 s
2025-02-24 10:08:37 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:08:37 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:08:37 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,170362 s
2025-02-24 10:08:37 INFO  CodeGenerator: Code generated in 4.082125 ms
2025-02-24 10:08:37 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:08:37 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:08:37 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55391 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:08:37 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:08:37 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:08:37 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:08:37 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:08:37 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:08:37 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:08:37 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:08:37 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:08:37 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55391 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:08:37 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:08:37 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:08:37 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:08:37 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:08:37 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:08:37 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:08:37 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:08:37 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:08:37 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:08:37 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:08:37 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:08:37 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55391 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:08:37 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:08:38 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 700 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 836 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 839 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 839 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 841 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 844 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 846 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:08:38 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:08:38 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 852 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:08:38 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:08:38 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,869 s
2025-02-24 10:08:38 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:08:38 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:08:38 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,871172 s
2025-02-24 10:08:38 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:08:38 INFO  AbstractConnector: Stopped Spark@278667fd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:08:38 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 10:08:38 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:08:38 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:08:38 INFO  BlockManager: BlockManager stopped
2025-02-24 10:08:38 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:08:38 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:08:38 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:08:38 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:08:38 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-d62b24be-c2ab-40ae-9b21-682580252998
2025-02-24 10:09:18 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:09:18 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:09:18 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:09:19 INFO  ResourceUtils: ==============================================================
2025-02-24 10:09:19 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:09:19 INFO  ResourceUtils: ==============================================================
2025-02-24 10:09:19 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:09:19 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:09:19 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:09:19 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:09:19 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:09:19 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:09:19 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:09:19 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:09:19 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:09:19 INFO  Utils: Successfully started service 'sparkDriver' on port 55648.
2025-02-24 10:09:19 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:09:19 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:09:19 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:09:19 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:09:19 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:09:19 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-a13d184f-078a-4630-82c7-0462fa9ae2ea
2025-02-24 10:09:19 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:09:19 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:09:19 INFO  log: Logging initialized @1230ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:09:19 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:09:19 INFO  Server: Started @1307ms
2025-02-24 10:09:19 INFO  AbstractConnector: Started ServerConnector@271591a3{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:09:19 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a6cc2a{/,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:09:19 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:09:19 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55651.
2025-02-24 10:09:19 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55651
2025-02-24 10:09:19 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:09:19 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55651, None)
2025-02-24 10:09:19 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55651 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55651, None)
2025-02-24 10:09:19 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55651, None)
2025-02-24 10:09:19 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55651, None)
2025-02-24 10:09:19 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@51a6cc2a{/,null,STOPPED,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575e572f{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d3c6593{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2dfb885e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1e3e1014{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47b11ec7{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36aa52d2{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@633cc6b5{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@403c3a01{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4462efe1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db4ad1{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/static,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d408060{/,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@17ba57f0{/api,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e3ecf5c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@341b13a8{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2d55e826{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:09:19 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70f68288{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db1b657{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54e12f4c{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:09:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca30b8a{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:09:20 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 10:09:20 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 10:09:21 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:09:21 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:09:21 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:09:21 INFO  CodeGenerator: Code generated in 53.631875 ms
2025-02-24 10:09:21 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55651 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:09:22 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:09:22 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:09:22 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:09:22 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:09:22 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:09:22 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:09:22 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:09:22 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55651 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:09:22 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:09:22 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:09:22 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:09:22 INFO  CodeGenerator: Code generated in 6.250167 ms
2025-02-24 10:09:22 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1722 bytes result sent to driver
2025-02-24 10:09:22 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 96 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:09:22 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:09:22 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,147 s
2025-02-24 10:09:22 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:09:22 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:09:22 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,184816 s
2025-02-24 10:09:22 INFO  CodeGenerator: Code generated in 4.505541 ms
2025-02-24 10:09:22 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:09:22 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:09:22 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55651 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:09:22 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:09:22 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:09:22 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:09:22 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:09:22 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:09:22 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:09:22 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:09:22 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:09:22 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55651 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:09:22 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:09:22 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:09:22 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:09:22 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:09:22 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:09:22 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:09:22 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:09:22 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:09:22 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:09:22 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:09:22 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:09:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:09:22 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55651 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:09:22 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:55651 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:09:23 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 875 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:09:23 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1058 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:09:23 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1078 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:09:23 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1082 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1082 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1084 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:09:23 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1112 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:09:23 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1115 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:09:23 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:09:23 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 1,128 s
2025-02-24 10:09:23 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:09:23 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:09:23 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 1,139452 s
2025-02-24 10:09:23 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:09:23 INFO  AbstractConnector: Stopped Spark@271591a3{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:09:23 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 10:09:23 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:09:23 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:09:23 INFO  BlockManager: BlockManager stopped
2025-02-24 10:09:23 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:09:23 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:09:23 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:09:23 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:09:23 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-7d4d4329-90d6-483b-96ce-e4366741018c
2025-02-24 10:11:13 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:11:13 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:11:13 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:11:13 INFO  ResourceUtils: ==============================================================
2025-02-24 10:11:13 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:11:13 INFO  ResourceUtils: ==============================================================
2025-02-24 10:11:13 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:11:13 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:11:13 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:11:13 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:11:13 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:11:13 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:11:13 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:11:13 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:11:13 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:11:13 INFO  Utils: Successfully started service 'sparkDriver' on port 56305.
2025-02-24 10:11:13 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:11:13 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:11:13 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:11:13 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:11:13 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:11:13 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-30bf31f4-dcc1-4f03-aac5-5c5a9b6bba61
2025-02-24 10:11:13 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:11:13 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:11:13 INFO  log: Logging initialized @946ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:11:13 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:11:13 INFO  Server: Started @1001ms
2025-02-24 10:11:13 INFO  AbstractConnector: Started ServerConnector@11cd9256{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:11:13 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f6b687e{/,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:11:13 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:11:13 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56306.
2025-02-24 10:11:13 INFO  NettyBlockTransferService: Server created on 172.20.10.2:56306
2025-02-24 10:11:13 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:11:13 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 56306, None)
2025-02-24 10:11:13 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:56306 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 56306, None)
2025-02-24 10:11:13 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 56306, None)
2025-02-24 10:11:13 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 56306, None)
2025-02-24 10:11:13 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@4f6b687e{/,null,STOPPED,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7426a448{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3456558{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3679d92e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ba17be6{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2daf06fc{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca8fcf3{/static,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3481ff98{/,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@79518e00{/api,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@692dba54{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5f14761c{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@329548d0{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:11:13 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e351d7{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@d902300{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60990e5c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@39ee94de{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:11:13 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4cb702ce{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:11:14 INFO  InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
2025-02-24 10:11:14 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 10:11:15 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:11:15 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:11:15 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:11:15 INFO  CodeGenerator: Code generated in 61.920375 ms
2025-02-24 10:11:15 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:11:15 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:11:15 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:56306 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:11:15 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:11:15 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:11:15 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:11:15 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:11:15 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:11:15 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:11:15 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:11:15 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:11:15 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:11:15 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:11:15 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:56306 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:11:15 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:11:15 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:11:15 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:11:15 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:15 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:11:15 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:11:15 INFO  CodeGenerator: Code generated in 5.643833 ms
2025-02-24 10:11:15 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:11:15 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 88 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:11:15 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:11:15 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,142 s
2025-02-24 10:11:15 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:11:15 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:11:15 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,173112 s
2025-02-24 10:11:15 INFO  CodeGenerator: Code generated in 4.400333 ms
2025-02-24 10:11:16 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:56306 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:11:16 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:11:16 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:11:16 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:11:16 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:11:16 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:11:16 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:56306 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:11:16 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:11:16 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:11:16 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:11:16 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:11:16 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:11:16 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:11:16 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:11:16 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:11:16 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:11:16 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:11:16 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:56306 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:11:16 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:11:16 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:11:16 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:11:16 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:11:16 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:11:16 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:11:16 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:11:16 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:11:16 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:11:16 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:11:16 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:11:16 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:11:16 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:56306 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:11:16 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 672 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:11:16 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 819 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 820 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:11:16 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 822 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 823 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:11:16 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 826 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:11:16 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 826 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:11:16 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 826 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:11:16 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:11:16 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 0,842 s
2025-02-24 10:11:16 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:11:16 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:11:16 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 0,843978 s
2025-02-24 10:11:17 INFO  CodeGenerator: Code generated in 5.66075 ms
2025-02-24 10:11:17 INFO  SparkContext: Starting job: show at main.scala:26
2025-02-24 10:11:17 INFO  DAGScheduler: Got job 2 (show at main.scala:26) with 1 output partitions
2025-02-24 10:11:17 INFO  DAGScheduler: Final stage: ResultStage 2 (show at main.scala:26)
2025-02-24 10:11:17 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:11:17 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:11:17 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:26), which has no missing parents
2025-02-24 10:11:17 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.7 KiB, free 2.2 GiB)
2025-02-24 10:11:17 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:11:17 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:56306 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:11:17 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:11:17 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:26) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:11:17 INFO  TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2025-02-24 10:11:17 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7245 bytes) taskResourceAssignments Map()
2025-02-24 10:11:17 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 10:11:17 INFO  JDBCRDD: closed connection
2025-02-24 10:11:17 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1566 bytes result sent to driver
2025-02-24 10:11:17 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 26 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:11:17 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 10:11:17 INFO  DAGScheduler: ResultStage 2 (show at main.scala:26) finished in 0,033 s
2025-02-24 10:11:17 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:11:17 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 10:11:17 INFO  DAGScheduler: Job 2 finished: show at main.scala:26, took 0,033931 s
2025-02-24 10:11:17 INFO  CodeGenerator: Code generated in 6.437667 ms
2025-02-24 10:41:13 INFO  BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.10.2:56306 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:41:13 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:56306 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:41:13 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:56306 in memory (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:46:01 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:46:01 INFO  AbstractConnector: Stopped Spark@11cd9256{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:46:01 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 10:46:02 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:46:02 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:46:02 INFO  BlockManager: BlockManager stopped
2025-02-24 10:46:02 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:46:02 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:46:02 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:46:02 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:46:02 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-a9d46e93-21a3-4512-aecc-e0ffd694f218
2025-02-24 10:46:05 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.16.56.1 instead (on interface bridge100)
2025-02-24 10:46:05 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:46:06 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:46:06 INFO  ResourceUtils: ==============================================================
2025-02-24 10:46:06 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:46:06 INFO  ResourceUtils: ==============================================================
2025-02-24 10:46:06 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:46:06 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:46:06 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:46:06 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:46:06 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:46:06 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:46:06 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:46:06 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:46:06 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:46:06 INFO  Utils: Successfully started service 'sparkDriver' on port 50956.
2025-02-24 10:46:06 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:46:06 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:46:06 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:46:06 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:46:06 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:46:06 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-1223de57-042e-47eb-964c-33de050191a5
2025-02-24 10:46:06 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:46:06 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:46:06 INFO  log: Logging initialized @1033ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:46:06 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:46:06 INFO  Server: Started @1091ms
2025-02-24 10:46:06 INFO  AbstractConnector: Started ServerConnector@e042c99{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:46:06 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28cb3a25{/,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  Executor: Starting executor ID driver on host 172.16.56.1
2025-02-24 10:46:06 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:46:06 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50957.
2025-02-24 10:46:06 INFO  NettyBlockTransferService: Server created on 172.16.56.1:50957
2025-02-24 10:46:06 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:46:06 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.16.56.1, 50957, None)
2025-02-24 10:46:06 INFO  BlockManagerMasterEndpoint: Registering block manager 172.16.56.1:50957 with 2.2 GiB RAM, BlockManagerId(driver, 172.16.56.1, 50957, None)
2025-02-24 10:46:06 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.16.56.1, 50957, None)
2025-02-24 10:46:06 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.16.56.1, 50957, None)
2025-02-24 10:46:06 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@28cb3a25{/,null,STOPPED,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@516462cc{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2dfb885e{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47b11ec7{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36aa52d2{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16a35bd{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6f798482{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4462efe1{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db4ad1{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2b5c4f17{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@69f0b0f4{/static,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2ddb3ae8{/,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c91530d{/api,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@71f1cc02{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@33feb805{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3003827c{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:46:06 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@43c57161{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2db33feb{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d84049a{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@642857e0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:46:06 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@383caf89{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:46:07 INFO  InMemoryFileIndex: It took 21 ms to list leaf files for 1 paths.
2025-02-24 10:46:07 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 10:46:08 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:46:08 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:46:08 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:46:08 INFO  CodeGenerator: Code generated in 51.135667 ms
2025-02-24 10:46:08 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:46:08 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:46:08 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.56.1:50957 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:46:08 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:46:08 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:46:08 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:46:08 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:46:08 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:46:08 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:46:08 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:46:08 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:46:08 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:46:08 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:46:08 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.56.1:50957 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:46:08 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:46:08 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:46:08 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:46:08 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.16.56.1, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:08 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:46:09 INFO  CodeGenerator: Code generated in 5.875708 ms
2025-02-24 10:46:09 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:46:09 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 101 ms on 172.16.56.1 (executor driver) (1/1)
2025-02-24 10:46:09 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:46:09 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,152 s
2025-02-24 10:46:09 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:46:09 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:46:09 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,182200 s
2025-02-24 10:46:09 INFO  CodeGenerator: Code generated in 3.985125 ms
2025-02-24 10:46:09 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.16.56.1:50957 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:46:09 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:46:09 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:46:09 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:46:09 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:46:09 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:46:09 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.56.1:50957 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:46:09 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:46:09 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:46:09 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:46:09 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:46:09 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:46:09 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:46:09 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:46:09 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:46:09 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:46:09 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:46:09 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.16.56.1:50957 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:46:09 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:46:09 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:46:09 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.16.56.1, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.16.56.1, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.16.56.1, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.16.56.1, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.16.56.1, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.16.56.1, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.16.56.1, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.16.56.1, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:46:09 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:46:09 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:46:09 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:46:09 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:46:09 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:46:09 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:46:09 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:46:09 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:46:09 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.16.56.1:50957 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:46:09 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:46:10 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 923 ms on 172.16.56.1 (executor driver) (1/8)
2025-02-24 10:46:10 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1023 ms on 172.16.56.1 (executor driver) (2/8)
2025-02-24 10:46:10 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1026 ms on 172.16.56.1 (executor driver) (3/8)
2025-02-24 10:46:10 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1030 ms on 172.16.56.1 (executor driver) (4/8)
2025-02-24 10:46:10 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1034 ms on 172.16.56.1 (executor driver) (5/8)
2025-02-24 10:46:10 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1033 ms on 172.16.56.1 (executor driver) (6/8)
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1033 ms on 172.16.56.1 (executor driver) (7/8)
2025-02-24 10:46:10 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1034 ms on 172.16.56.1 (executor driver) (8/8)
2025-02-24 10:46:10 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:46:10 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 1,049 s
2025-02-24 10:46:10 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:46:10 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:46:10 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 1,051032 s
2025-02-24 10:46:10 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:46:10 INFO  AbstractConnector: Stopped Spark@e042c99{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:46:10 INFO  SparkUI: Stopped Spark web UI at http://172.16.56.1:4040
2025-02-24 10:46:10 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:46:10 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:46:10 INFO  BlockManager: BlockManager stopped
2025-02-24 10:46:10 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:46:10 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:46:10 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:46:10 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:46:10 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-27b3aeca-cad7-40ef-8eed-b45931b23812
2025-02-24 10:48:23 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:48:23 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:48:23 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:48:23 INFO  ResourceUtils: ==============================================================
2025-02-24 10:48:23 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:48:23 INFO  ResourceUtils: ==============================================================
2025-02-24 10:48:23 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:48:23 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:48:23 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:48:23 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:48:23 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:48:23 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:48:23 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:48:23 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:48:23 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:48:23 INFO  Utils: Successfully started service 'sparkDriver' on port 51796.
2025-02-24 10:48:23 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:48:23 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:48:23 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:48:23 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:48:23 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:48:23 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-24d8a738-c870-4f6d-bc28-34b516fc4027
2025-02-24 10:48:23 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:48:23 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:48:23 INFO  log: Logging initialized @1052ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:48:23 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:48:23 INFO  Server: Started @1110ms
2025-02-24 10:48:23 INFO  AbstractConnector: Started ServerConnector@ac10cbb{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:48:23 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5555ffcf{/,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:48:23 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:48:23 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51797.
2025-02-24 10:48:23 INFO  NettyBlockTransferService: Server created on 172.20.10.2:51797
2025-02-24 10:48:23 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:48:23 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 51797, None)
2025-02-24 10:48:23 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:51797 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 51797, None)
2025-02-24 10:48:23 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 51797, None)
2025-02-24 10:48:23 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 51797, None)
2025-02-24 10:48:23 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@5555ffcf{/,null,STOPPED,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3456558{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6cbe7d4d{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ba17be6{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@332bcab0{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca8fcf3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66933239{/static,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@79518e00{/,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7d70638{/api,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5f14761c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@37854b34{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@29b40b3{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:48:23 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@d902300{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@39ee94de{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4c6b4ed7{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:48:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@64c781a9{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:48:24 INFO  InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
2025-02-24 10:48:24 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 10:48:25 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:48:25 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:48:25 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:48:25 INFO  CodeGenerator: Code generated in 59.976708 ms
2025-02-24 10:48:25 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:51797 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:48:26 INFO  SparkContext: Created broadcast 0 from csv at main.scala:15
2025-02-24 10:48:26 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:48:26 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:48:26 INFO  DAGScheduler: Got job 0 (csv at main.scala:15) with 1 output partitions
2025-02-24 10:48:26 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:15)
2025-02-24 10:48:26 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:48:26 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:48:26 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15), which has no missing parents
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:51797 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:48:26 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:48:26 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:48:26 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:48:26 INFO  CodeGenerator: Code generated in 5.658958 ms
2025-02-24 10:48:26 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:48:26 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 93 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:48:26 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:48:26 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:15) finished in 0,149 s
2025-02-24 10:48:26 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:48:26 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:48:26 INFO  DAGScheduler: Job 0 finished: csv at main.scala:15, took 0,181195 s
2025-02-24 10:48:26 INFO  CodeGenerator: Code generated in 4.727375 ms
2025-02-24 10:48:26 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:48:26 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:48:26 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:51797 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:48:26 INFO  SparkContext: Created broadcast 2 from csv at main.scala:15
2025-02-24 10:48:26 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:48:26 INFO  SparkContext: Starting job: csv at main.scala:15
2025-02-24 10:48:26 INFO  DAGScheduler: Got job 1 (csv at main.scala:15) with 8 output partitions
2025-02-24 10:48:26 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:15)
2025-02-24 10:48:26 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:48:26 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:48:26 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15), which has no missing parents
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:48:26 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:51797 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:48:26 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:48:26 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:15) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:48:26 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:48:26 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:48:26 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:48:26 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:48:26 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:48:26 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:48:26 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:48:26 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:48:26 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:48:26 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:48:26 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:51797 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:48:26 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:51797 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:48:27 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1064 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1177 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1184 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1185 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1187 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1190 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1192 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:48:27 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:48:27 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1194 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:48:27 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:48:27 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:15) finished in 1,205 s
2025-02-24 10:48:27 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:48:27 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:48:27 INFO  DAGScheduler: Job 1 finished: csv at main.scala:15, took 1,206922 s
2025-02-24 10:48:27 INFO  CodeGenerator: Code generated in 5.091041 ms
2025-02-24 10:48:27 INFO  SparkContext: Starting job: show at main.scala:28
2025-02-24 10:48:27 INFO  DAGScheduler: Got job 2 (show at main.scala:28) with 1 output partitions
2025-02-24 10:48:27 INFO  DAGScheduler: Final stage: ResultStage 2 (show at main.scala:28)
2025-02-24 10:48:27 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:48:27 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:48:27 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:28), which has no missing parents
2025-02-24 10:48:27 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.5 KiB, free 2.2 GiB)
2025-02-24 10:48:27 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 2.2 GiB)
2025-02-24 10:48:27 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:51797 (size: 5.5 KiB, free: 2.2 GiB)
2025-02-24 10:48:27 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:48:27 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:28) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:48:27 INFO  TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2025-02-24 10:48:27 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7245 bytes) taskResourceAssignments Map()
2025-02-24 10:48:27 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 10:48:28 INFO  JDBCRDD: closed connection
2025-02-24 10:48:28 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1517 bytes result sent to driver
2025-02-24 10:48:28 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 27 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:48:28 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 10:48:28 INFO  DAGScheduler: ResultStage 2 (show at main.scala:28) finished in 0,035 s
2025-02-24 10:48:28 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:48:28 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 10:48:28 INFO  DAGScheduler: Job 2 finished: show at main.scala:28, took 0,036768 s
2025-02-24 10:48:28 INFO  CodeGenerator: Code generated in 4.481417 ms
2025-02-24 10:56:36 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 10:56:36 INFO  AbstractConnector: Stopped Spark@ac10cbb{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:56:36 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 10:56:36 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 10:56:36 INFO  MemoryStore: MemoryStore cleared
2025-02-24 10:56:36 INFO  BlockManager: BlockManager stopped
2025-02-24 10:56:36 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 10:56:36 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 10:56:36 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 10:56:36 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 10:56:36 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-1715a7f7-e4e2-4e6e-a46c-62a970ed416b
2025-02-24 10:59:15 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 10:59:15 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 10:59:15 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 10:59:15 INFO  ResourceUtils: ==============================================================
2025-02-24 10:59:15 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 10:59:15 INFO  ResourceUtils: ==============================================================
2025-02-24 10:59:15 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 10:59:15 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 10:59:15 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 10:59:15 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 10:59:15 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 10:59:15 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 10:59:15 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 10:59:15 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 10:59:15 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 10:59:15 INFO  Utils: Successfully started service 'sparkDriver' on port 55487.
2025-02-24 10:59:15 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 10:59:15 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 10:59:15 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 10:59:15 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 10:59:15 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 10:59:15 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-4c465042-2daa-4782-9fa9-5bfb16694d1c
2025-02-24 10:59:15 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 10:59:15 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 10:59:15 INFO  log: Logging initialized @1033ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 10:59:15 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 10:59:15 INFO  Server: Started @1091ms
2025-02-24 10:59:15 INFO  AbstractConnector: Started ServerConnector@3f702946{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 10:59:15 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 10:59:15 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5555ffcf{/,null,AVAILABLE,@Spark}
2025-02-24 10:59:15 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 10:59:15 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 10:59:15 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55489.
2025-02-24 10:59:15 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55489
2025-02-24 10:59:15 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 10:59:15 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55489, None)
2025-02-24 10:59:15 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55489 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55489, None)
2025-02-24 10:59:15 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55489, None)
2025-02-24 10:59:15 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55489, None)
2025-02-24 10:59:16 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@5555ffcf{/,null,STOPPED,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3456558{/jobs,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6cbe7d4d{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ba17be6{/stages,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@332bcab0{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/environment,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca8fcf3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66933239{/static,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@79518e00{/,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7d70638{/api,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5f14761c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@37854b34{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@29b40b3{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 10:59:16 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@d902300{/SQL,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30c3ae63{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@39ee94de{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4c6b4ed7{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@64c781a9{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 10:59:16 INFO  InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
2025-02-24 10:59:16 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 10:59:17 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:59:17 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 10:59:17 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:59:17 INFO  CodeGenerator: Code generated in 59.937541 ms
2025-02-24 10:59:17 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55489 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:18 INFO  SparkContext: Created broadcast 0 from csv at main.scala:14
2025-02-24 10:59:18 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:59:18 INFO  SparkContext: Starting job: csv at main.scala:14
2025-02-24 10:59:18 INFO  DAGScheduler: Got job 0 (csv at main.scala:14) with 1 output partitions
2025-02-24 10:59:18 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:14)
2025-02-24 10:59:18 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:59:18 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:59:18 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:14), which has no missing parents
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55489 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:59:18 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:59:18 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:14) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:59:18 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:59:18 INFO  CodeGenerator: Code generated in 5.405458 ms
2025-02-24 10:59:18 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 10:59:18 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 98 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:59:18 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 10:59:18 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:14) finished in 0,154 s
2025-02-24 10:59:18 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:59:18 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 10:59:18 INFO  DAGScheduler: Job 0 finished: csv at main.scala:14, took 0,190492 s
2025-02-24 10:59:18 INFO  CodeGenerator: Code generated in 4.451459 ms
2025-02-24 10:59:18 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 10:59:18 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 10:59:18 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55489 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:18 INFO  SparkContext: Created broadcast 2 from csv at main.scala:14
2025-02-24 10:59:18 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 10:59:18 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55489 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 10:59:18 INFO  SparkContext: Starting job: csv at main.scala:14
2025-02-24 10:59:18 INFO  DAGScheduler: Got job 1 (csv at main.scala:14) with 8 output partitions
2025-02-24 10:59:18 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:14)
2025-02-24 10:59:18 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:59:18 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:59:18 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:14), which has no missing parents
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 10:59:18 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55489 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:18 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:59:18 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:14) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 10:59:18 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 10:59:18 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 10:59:18 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 10:59:18 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 10:59:18 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 10:59:18 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 10:59:18 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 10:59:18 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 10:59:18 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 10:59:18 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 10:59:19 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 896 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1014 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1016 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1022 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1024 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1034 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1037 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 10:59:19 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1045 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 10:59:19 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 10:59:19 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:14) finished in 1,060 s
2025-02-24 10:59:19 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:59:19 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 10:59:19 INFO  DAGScheduler: Job 1 finished: csv at main.scala:14, took 1,062662 s
2025-02-24 10:59:19 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:55489 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:19 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:55489 in memory (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:19 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:55489 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 10:59:19 INFO  CodeGenerator: Code generated in 4.817167 ms
2025-02-24 10:59:19 INFO  SparkContext: Starting job: show at main.scala:26
2025-02-24 10:59:19 INFO  DAGScheduler: Got job 2 (show at main.scala:26) with 1 output partitions
2025-02-24 10:59:19 INFO  DAGScheduler: Final stage: ResultStage 2 (show at main.scala:26)
2025-02-24 10:59:19 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 10:59:19 INFO  DAGScheduler: Missing parents: List()
2025-02-24 10:59:19 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:26), which has no missing parents
2025-02-24 10:59:19 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.5 KiB, free 2.2 GiB)
2025-02-24 10:59:19 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 2.2 GiB)
2025-02-24 10:59:19 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:55489 (size: 5.5 KiB, free: 2.2 GiB)
2025-02-24 10:59:19 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
2025-02-24 10:59:19 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:26) (first 15 tasks are for partitions Vector(0))
2025-02-24 10:59:19 INFO  TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2025-02-24 10:59:19 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7245 bytes) taskResourceAssignments Map()
2025-02-24 10:59:19 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 10:59:19 INFO  JDBCRDD: closed connection
2025-02-24 10:59:19 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1517 bytes result sent to driver
2025-02-24 10:59:19 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 32 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 10:59:19 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 10:59:19 INFO  DAGScheduler: ResultStage 2 (show at main.scala:26) finished in 0,042 s
2025-02-24 10:59:19 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 10:59:19 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 10:59:19 INFO  DAGScheduler: Job 2 finished: show at main.scala:26, took 0,044749 s
2025-02-24 10:59:19 INFO  CodeGenerator: Code generated in 4.258541 ms
2025-02-24 11:02:08 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 11:02:08 INFO  AbstractConnector: Stopped Spark@3f702946{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:02:08 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 11:02:08 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 11:02:08 INFO  MemoryStore: MemoryStore cleared
2025-02-24 11:02:08 INFO  BlockManager: BlockManager stopped
2025-02-24 11:02:08 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 11:02:08 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 11:02:08 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 11:02:08 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 11:02:08 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-279562d6-c725-41fa-b437-e0e303aae772
2025-02-24 11:02:11 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 11:02:11 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 11:02:11 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 11:02:11 INFO  ResourceUtils: ==============================================================
2025-02-24 11:02:11 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 11:02:11 INFO  ResourceUtils: ==============================================================
2025-02-24 11:02:11 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 11:02:11 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 11:02:11 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 11:02:11 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 11:02:11 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 11:02:11 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 11:02:11 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 11:02:11 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 11:02:11 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 11:02:11 INFO  Utils: Successfully started service 'sparkDriver' on port 56494.
2025-02-24 11:02:11 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 11:02:11 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 11:02:11 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 11:02:11 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 11:02:11 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 11:02:11 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-ecd3fea0-5887-4494-8727-1899f8f28b37
2025-02-24 11:02:11 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 11:02:11 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 11:02:12 INFO  log: Logging initialized @1067ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 11:02:12 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 11:02:12 INFO  Server: Started @1120ms
2025-02-24 11:02:12 INFO  AbstractConnector: Started ServerConnector@2b63b9b3{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:02:12 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f6b687e{/,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 11:02:12 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 11:02:12 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56495.
2025-02-24 11:02:12 INFO  NettyBlockTransferService: Server created on 172.20.10.2:56495
2025-02-24 11:02:12 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 11:02:12 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 56495, None)
2025-02-24 11:02:12 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:56495 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 56495, None)
2025-02-24 11:02:12 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 56495, None)
2025-02-24 11:02:12 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 56495, None)
2025-02-24 11:02:12 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@4f6b687e{/,null,STOPPED,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7426a448{/jobs,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3456558{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3679d92e{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@58fa5769{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ee25d80{/stages,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ba17be6{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2daf06fc{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5ceecfee{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28ee7bee{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@31e130bf{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@f1f7db2{/storage,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c3e4b1a{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@765d55d5{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2bfb583b{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6fc1020a{/environment,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2629d5dc{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@42a0501e{/executors,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e4599c0{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d1f558a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28f4f300{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca8fcf3{/static,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3481ff98{/,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@79518e00{/api,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@692dba54{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5f14761c{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@329548d0{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 11:02:12 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e351d7{/SQL,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@d902300{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60990e5c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@39ee94de{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4cb702ce{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 11:02:12 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 11:02:12 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 11:02:13 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:02:13 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 11:02:13 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 11:02:13 INFO  CodeGenerator: Code generated in 60.728792 ms
2025-02-24 11:02:13 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:56495 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:02:14 INFO  SparkContext: Created broadcast 0 from csv at main.scala:14
2025-02-24 11:02:14 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:02:14 INFO  SparkContext: Starting job: csv at main.scala:14
2025-02-24 11:02:14 INFO  DAGScheduler: Got job 0 (csv at main.scala:14) with 1 output partitions
2025-02-24 11:02:14 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:14)
2025-02-24 11:02:14 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:02:14 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:02:14 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:14), which has no missing parents
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:56495 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 11:02:14 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:02:14 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:14) (first 15 tasks are for partitions Vector(0))
2025-02-24 11:02:14 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:02:14 INFO  CodeGenerator: Code generated in 5.318084 ms
2025-02-24 11:02:14 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 11:02:14 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 89 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 11:02:14 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 11:02:14 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:14) finished in 0,140 s
2025-02-24 11:02:14 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:02:14 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 11:02:14 INFO  DAGScheduler: Job 0 finished: csv at main.scala:14, took 0,168093 s
2025-02-24 11:02:14 INFO  CodeGenerator: Code generated in 3.547875 ms
2025-02-24 11:02:14 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:56495 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 11:02:14 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:02:14 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 11:02:14 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:56495 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:02:14 INFO  SparkContext: Created broadcast 2 from csv at main.scala:14
2025-02-24 11:02:14 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:02:14 INFO  SparkContext: Starting job: csv at main.scala:14
2025-02-24 11:02:14 INFO  DAGScheduler: Got job 1 (csv at main.scala:14) with 8 output partitions
2025-02-24 11:02:14 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:14)
2025-02-24 11:02:14 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:02:14 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:02:14 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:14), which has no missing parents
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 11:02:14 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:56495 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 11:02:14 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:02:14 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:14) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:02:14 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:02:14 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 11:02:14 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 11:02:14 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 11:02:14 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 11:02:14 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 11:02:14 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 11:02:14 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 11:02:14 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 11:02:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 11:02:15 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1059 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:02:15 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1326 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:02:15 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1334 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1335 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:02:15 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1337 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:02:15 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1344 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1344 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:02:15 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 11:02:15 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1353 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:02:15 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 11:02:15 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:14) finished in 1,368 s
2025-02-24 11:02:15 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:02:15 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 11:02:15 INFO  DAGScheduler: Job 1 finished: csv at main.scala:14, took 1,369911 s
2025-02-24 11:02:15 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:56495 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:02:15 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:56495 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:02:18 INFO  CodeGenerator: Code generated in 8.504 ms
2025-02-24 11:02:18 INFO  SparkContext: Starting job: show at main.scala:106
2025-02-24 11:02:18 INFO  DAGScheduler: Got job 2 (show at main.scala:106) with 1 output partitions
2025-02-24 11:02:18 INFO  DAGScheduler: Final stage: ResultStage 2 (show at main.scala:106)
2025-02-24 11:02:18 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:02:18 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:02:18 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:106), which has no missing parents
2025-02-24 11:02:18 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.7 KiB, free 2.2 GiB)
2025-02-24 11:02:18 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 11:02:18 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:56495 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 11:02:18 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:02:18 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at main.scala:106) (first 15 tasks are for partitions Vector(0))
2025-02-24 11:02:18 INFO  TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2025-02-24 11:02:18 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7245 bytes) taskResourceAssignments Map()
2025-02-24 11:02:18 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 11:02:18 INFO  JDBCRDD: closed connection
2025-02-24 11:02:18 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1566 bytes result sent to driver
2025-02-24 11:02:18 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 49 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 11:02:18 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 11:02:18 INFO  DAGScheduler: ResultStage 2 (show at main.scala:106) finished in 0,062 s
2025-02-24 11:02:18 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:02:18 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 11:02:18 INFO  DAGScheduler: Job 2 finished: show at main.scala:106, took 0,065715 s
2025-02-24 11:02:18 INFO  CodeGenerator: Code generated in 8.63275 ms
2025-02-24 11:09:50 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 11:09:50 INFO  AbstractConnector: Stopped Spark@2b63b9b3{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:09:50 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 11:09:50 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 11:09:50 INFO  MemoryStore: MemoryStore cleared
2025-02-24 11:09:50 INFO  BlockManager: BlockManager stopped
2025-02-24 11:09:50 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 11:09:50 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 11:09:51 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 11:09:51 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 11:09:51 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-90414858-f77b-4689-9e3b-7a2b4e413192
2025-02-24 11:36:59 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 11:36:59 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 11:36:59 INFO  SparkContext: Running Spark version 3.3.2
2025-02-24 11:37:00 INFO  ResourceUtils: ==============================================================
2025-02-24 11:37:00 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 11:37:00 INFO  ResourceUtils: ==============================================================
2025-02-24 11:37:00 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 11:37:00 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 11:37:00 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 11:37:00 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 11:37:00 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 11:37:00 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 11:37:00 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 11:37:00 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 11:37:00 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fabob); groups with view permissions: Set(); users  with modify permissions: Set(fabob); groups with modify permissions: Set()
2025-02-24 11:37:00 INFO  Utils: Successfully started service 'sparkDriver' on port 51771.
2025-02-24 11:37:00 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 11:37:00 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 11:37:00 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 11:37:00 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 11:37:00 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 11:37:00 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-b3e09dff-f368-4d51-9179-4e245335d49d
2025-02-24 11:37:00 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 11:37:00 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 11:37:00 INFO  log: Logging initialized @1037ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 11:37:00 INFO  Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.9+0
2025-02-24 11:37:00 INFO  Server: Started @1081ms
2025-02-24 11:37:00 INFO  AbstractConnector: Started ServerConnector@269dd5ae{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:37:00 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ecdbab8{/,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 11:37:00 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 11:37:00 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51772.
2025-02-24 11:37:00 INFO  NettyBlockTransferService: Server created on 172.20.10.2:51772
2025-02-24 11:37:00 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 11:37:00 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 51772, None)
2025-02-24 11:37:00 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:51772 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 51772, None)
2025-02-24 11:37:00 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 51772, None)
2025-02-24 11:37:00 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 51772, None)
2025-02-24 11:37:00 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@6ecdbab8{/,null,STOPPED,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6f798482{/jobs,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@633cc6b5{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28237492{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7da31a40{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1b5a1d85{/stages,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54755dd9{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2513a118{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73ae0257{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5762658b{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2596d7f4{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6aa3bfc{/storage,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7dffda8b{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6abdec0e{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2b5c4f17{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@69f0b0f4{/environment,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2f7efd0b{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6801b414{/executors,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f327096{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@78a515e4{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51c8f62c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@11f9535b{/static,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6e3ecf5c{/,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@341b13a8{/api,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@35c9a231{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5626d18c{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4ed4a7e4{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 11:37:00 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@54e12f4c{/SQL,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4d84049a{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ca30b8a{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5c9934da{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 11:37:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@b73433{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 11:37:01 INFO  InMemoryFileIndex: It took 22 ms to list leaf files for 1 paths.
2025-02-24 11:37:01 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 11:37:02 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:37:02 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 11:37:02 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 11:37:02 INFO  CodeGenerator: Code generated in 61.758334 ms
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:51772 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:37:02 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 11:37:02 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:37:02 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:37:02 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 11:37:02 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 11:37:02 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:37:02 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:37:02 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.0 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:51772 (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 11:37:02 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:37:02 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 11:37:02 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:37:02 INFO  CodeGenerator: Code generated in 5.567958 ms
2025-02-24 11:37:02 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2025-02-24 11:37:02 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 91 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 11:37:02 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 11:37:02 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,141 s
2025-02-24 11:37:02 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:37:02 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 11:37:02 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,171067 s
2025-02-24 11:37:02 INFO  CodeGenerator: Code generated in 3.858042 ms
2025-02-24 11:37:02 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:51772 in memory (size: 5.9 KiB, free: 2.2 GiB)
2025-02-24 11:37:02 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:37:02 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 11:37:02 INFO  FileSourceStrategy: Output Data Schema: struct<value: string>
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:51772 (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:37:02 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 11:37:02 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:37:02 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:37:02 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 11:37:02 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 11:37:02 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:37:02 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:37:02 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 2.2 GiB)
2025-02-24 11:37:02 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:51772 (size: 8.8 KiB, free: 2.2 GiB)
2025-02-24 11:37:02 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:37:02 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:37:02 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7915 bytes) taskResourceAssignments Map()
2025-02-24 11:37:02 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 11:37:02 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 11:37:02 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 11:37:02 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 11:37:02 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 11:37:02 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 11:37:02 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 11:37:02 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 11:37:02 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 11:37:03 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1977 bytes result sent to driver
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 843 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:37:03 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1006 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:37:03 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1026 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1026 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1027 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1027 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:37:03 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1934 bytes result sent to driver
2025-02-24 11:37:03 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1029 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:37:03 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1934 bytes result sent to driver
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1032 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:37:04 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 11:37:04 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,048 s
2025-02-24 11:37:04 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:37:04 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 11:37:04 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,049571 s
2025-02-24 11:37:04 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:51772 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:37:04 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:51772 in memory (size: 33.8 KiB, free: 2.2 GiB)
2025-02-24 11:37:04 INFO  CodeGenerator: Code generated in 3.937417 ms
2025-02-24 11:37:04 INFO  SparkContext: Starting job: jdbc at main.scala:39
2025-02-24 11:37:04 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:39) with 8 output partitions
2025-02-24 11:37:04 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:39)
2025-02-24 11:37:04 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:37:04 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:37:04 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:39), which has no missing parents
2025-02-24 11:37:04 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 20.5 KiB, free 2.2 GiB)
2025-02-24 11:37:04 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 2.2 GiB)
2025-02-24 11:37:04 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:51772 (size: 9.2 KiB, free: 2.2 GiB)
2025-02-24 11:37:04 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
2025-02-24 11:37:04 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:37:04 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7455 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7568 bytes) taskResourceAssignments Map()
2025-02-24 11:37:04 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 11:37:04 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 11:37:04 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 11:37:04 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 11:37:04 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 11:37:04 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 11:37:04 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 11:37:04 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 11:37:04 INFO  CodeGenerator: Code generated in 5.733625 ms
2025-02-24 11:37:04 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1272 bytes result sent to driver
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 28 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 28 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 28 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 28 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 28 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 29 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 30 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:37:04 INFO  CodeGenerator: Code generated in 24.566708 ms
2025-02-24 11:37:04 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1315 bytes result sent to driver
2025-02-24 11:37:04 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 84 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:37:04 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 11:37:04 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:39) finished in 0,096 s
2025-02-24 11:37:04 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:37:04 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 11:37:04 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:39, took 0,098191 s
2025-02-24 11:39:05 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 11:39:05 INFO  AbstractConnector: Stopped Spark@269dd5ae{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:39:05 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 11:39:05 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 11:39:05 INFO  MemoryStore: MemoryStore cleared
2025-02-24 11:39:05 INFO  BlockManager: BlockManager stopped
2025-02-24 11:39:05 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 11:39:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 11:39:05 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 11:39:05 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 11:39:05 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-d09d2519-e555-43b1-a0b3-d4a5517fb738
2025-02-24 11:48:16 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 11:48:16 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 11:48:16 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 11:48:16 INFO  ResourceUtils: ==============================================================
2025-02-24 11:48:16 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 11:48:16 INFO  ResourceUtils: ==============================================================
2025-02-24 11:48:16 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 11:48:16 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 11:48:16 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 11:48:16 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 11:48:16 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 11:48:16 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 11:48:16 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 11:48:16 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 11:48:16 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 11:48:16 INFO  Utils: Successfully started service 'sparkDriver' on port 55584.
2025-02-24 11:48:16 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 11:48:16 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 11:48:16 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 11:48:16 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 11:48:16 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 11:48:16 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-fb965ca2-60b4-40bc-a06c-24246a7d3688
2025-02-24 11:48:16 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 11:48:16 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 11:48:16 INFO  log: Logging initialized @1030ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 11:48:16 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 11:48:16 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 11:48:16 INFO  Server: Started @1084ms
2025-02-24 11:48:16 INFO  AbstractConnector: Started ServerConnector@3c69362a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:48:16 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 11:48:16 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70c53dbe{/,null,AVAILABLE,@Spark}
2025-02-24 11:48:16 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 11:48:16 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 11:48:16 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55586.
2025-02-24 11:48:16 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55586
2025-02-24 11:48:16 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 11:48:16 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55586, None)
2025-02-24 11:48:16 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55586 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55586, None)
2025-02-24 11:48:16 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55586, None)
2025-02-24 11:48:16 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55586, None)
2025-02-24 11:48:17 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@70c53dbe{/,null,STOPPED,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c854752{/jobs,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1a500561{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3bec5821{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66236a0a{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@77c10a5f{/stages,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c781c42{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@157ec23b{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3166f664{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60d6fdd4{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/storage,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2152ab30{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7d32e714{/environment,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34d45ec0{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/executors,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/static,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7219ac49{/,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@551e4c6d{/api,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40f35e52{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@561953e3{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 11:48:17 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@fa5f81c{/SQL,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f2f0109{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1faf386c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a5e167a{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e4579c7{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 11:48:17 INFO  InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
2025-02-24 11:48:17 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 11:48:18 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:48:18 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 11:48:18 INFO  CodeGenerator: Code generated in 102.566042 ms
2025-02-24 11:48:18 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55586 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 11:48:19 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:48:19 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:48:19 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 11:48:19 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 11:48:19 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:48:19 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:48:19 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55586 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:48:19 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 11:48:19 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:48:19 INFO  CodeGenerator: Code generated in 5.601917 ms
2025-02-24 11:48:19 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-02-24 11:48:19 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 103 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 11:48:19 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 11:48:19 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,155 s
2025-02-24 11:48:19 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:48:19 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 11:48:19 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,189450 s
2025-02-24 11:48:19 INFO  CodeGenerator: Code generated in 4.051583 ms
2025-02-24 11:48:19 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:48:19 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55586 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 11:48:19 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:48:19 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:48:19 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 11:48:19 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 11:48:19 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:48:19 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:48:19 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55586 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:48:19 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:48:19 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:48:19 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 11:48:19 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 11:48:19 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 11:48:19 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 11:48:19 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 11:48:19 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 11:48:19 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 11:48:19 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:55586 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55586 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 11:48:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 11:48:20 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1029 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:48:20 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1166 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:48:20 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1168 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:48:20 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1171 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1171 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1171 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:48:20 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1174 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:48:20 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1173 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:48:20 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 11:48:20 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,191 s
2025-02-24 11:48:20 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:48:20 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 11:48:20 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,193281 s
2025-02-24 11:48:20 INFO  CodeGenerator: Code generated in 5.062125 ms
2025-02-24 11:48:20 INFO  SparkContext: Starting job: jdbc at main.scala:39
2025-02-24 11:48:20 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:39) with 8 output partitions
2025-02-24 11:48:20 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:39)
2025-02-24 11:48:20 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:48:20 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:48:20 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:39), which has no missing parents
2025-02-24 11:48:20 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.7 KiB, free 2.2 GiB)
2025-02-24 11:48:20 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2.2 GiB)
2025-02-24 11:48:20 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:55586 (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 11:48:20 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:48:20 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:48:20 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:48:20 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7606 bytes) 
2025-02-24 11:48:20 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 11:48:20 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 11:48:20 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 11:48:20 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 11:48:20 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 11:48:20 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 11:48:20 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 11:48:20 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 11:48:21 INFO  CodeGenerator: Code generated in 4.658333 ms
2025-02-24 11:48:21 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 31 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 31 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:48:21 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1276 bytes result sent to driver
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 30 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 31 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 32 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 32 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 33 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:48:21 INFO  CodeGenerator: Code generated in 28.313459 ms
2025-02-24 11:48:21 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1319 bytes result sent to driver
2025-02-24 11:48:21 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 98 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:48:21 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 11:48:21 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:39) finished in 0,110 s
2025-02-24 11:48:21 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:48:21 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 11:48:21 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:39, took 0,111976 s
2025-02-24 11:49:34 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 11:49:34 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 11:49:34 INFO  AbstractConnector: Stopped Spark@3c69362a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:49:34 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 11:49:34 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 11:49:34 INFO  MemoryStore: MemoryStore cleared
2025-02-24 11:49:34 INFO  BlockManager: BlockManager stopped
2025-02-24 11:49:34 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 11:49:34 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 11:49:34 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 11:49:34 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 11:49:34 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-5411b88a-c92e-4dd9-90c2-d163ed935f7e
2025-02-24 11:52:45 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 11:52:45 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 11:52:45 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 11:52:45 INFO  ResourceUtils: ==============================================================
2025-02-24 11:52:45 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 11:52:45 INFO  ResourceUtils: ==============================================================
2025-02-24 11:52:45 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 11:52:45 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 11:52:45 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 11:52:45 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 11:52:45 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 11:52:45 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 11:52:45 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 11:52:45 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 11:52:45 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 11:52:46 INFO  Utils: Successfully started service 'sparkDriver' on port 57107.
2025-02-24 11:52:46 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 11:52:46 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 11:52:46 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 11:52:46 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 11:52:46 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 11:52:46 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-91622721-0361-4cda-9bc8-e48a6b7c7bfa
2025-02-24 11:52:46 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 11:52:46 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 11:52:46 INFO  log: Logging initialized @1077ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 11:52:46 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 11:52:46 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 11:52:46 INFO  Server: Started @1142ms
2025-02-24 11:52:46 INFO  AbstractConnector: Started ServerConnector@3c69362a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:52:46 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@70c53dbe{/,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 11:52:46 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 11:52:46 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57114.
2025-02-24 11:52:46 INFO  NettyBlockTransferService: Server created on 172.20.10.2:57114
2025-02-24 11:52:46 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 11:52:46 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 57114, None)
2025-02-24 11:52:46 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:57114 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 57114, None)
2025-02-24 11:52:46 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 57114, None)
2025-02-24 11:52:46 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 57114, None)
2025-02-24 11:52:46 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@70c53dbe{/,null,STOPPED,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c854752{/jobs,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1a500561{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3bec5821{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66236a0a{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@77c10a5f{/stages,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c781c42{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@157ec23b{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3166f664{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60d6fdd4{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/storage,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2152ab30{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7d32e714{/environment,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34d45ec0{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/executors,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/static,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7219ac49{/,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@551e4c6d{/api,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40f35e52{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@561953e3{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 11:52:46 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@fa5f81c{/SQL,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f2f0109{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1faf386c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a5e167a{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 11:52:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7e4579c7{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 11:52:47 INFO  InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
2025-02-24 11:52:47 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 11:52:48 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:52:48 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 11:52:48 INFO  CodeGenerator: Code generated in 99.933208 ms
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 11:52:48 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:57114 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:52:48 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 11:52:48 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:52:48 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:52:48 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 11:52:48 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 11:52:48 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:52:48 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:52:48 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 11:52:48 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:57114 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 11:52:48 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:52:48 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 11:52:48 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 11:52:48 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:48 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 11:52:48 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:52:48 INFO  CodeGenerator: Code generated in 6.310375 ms
2025-02-24 11:52:48 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 11:52:48 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 101 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 11:52:48 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 11:52:48 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,150 s
2025-02-24 11:52:48 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:52:48 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 11:52:48 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,180947 s
2025-02-24 11:52:48 INFO  CodeGenerator: Code generated in 4.093625 ms
2025-02-24 11:52:48 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:57114 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 11:52:48 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 11:52:48 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 11:52:48 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 11:52:48 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:57114 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:52:48 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 11:52:48 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 11:52:48 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:57114 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 11:52:49 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 11:52:49 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 11:52:49 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 11:52:49 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:52:49 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:52:49 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 11:52:49 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 11:52:49 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 11:52:49 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:57114 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 11:52:49 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:52:49 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:52:49 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 11:52:49 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 11:52:49 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 11:52:49 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 11:52:49 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 11:52:49 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 11:52:49 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 11:52:49 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 11:52:49 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 11:52:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 11:52:49 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 847 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:52:49 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 956 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:52:49 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 958 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:52:49 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 958 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 958 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 959 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:52:49 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 963 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:52:49 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 11:52:49 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 965 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:52:49 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 11:52:49 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 0,978 s
2025-02-24 11:52:49 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:52:49 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 11:52:49 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 0,980298 s
2025-02-24 11:53:13 INFO  CodeGenerator: Code generated in 5.797583 ms
2025-02-24 11:53:13 INFO  SparkContext: Starting job: jdbc at main.scala:119
2025-02-24 11:53:13 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:119) with 8 output partitions
2025-02-24 11:53:13 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:119)
2025-02-24 11:53:13 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:53:13 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:53:13 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:119), which has no missing parents
2025-02-24 11:53:13 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.7 KiB, free 2.2 GiB)
2025-02-24 11:53:13 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2.2 GiB)
2025-02-24 11:53:13 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:57114 (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 11:53:13 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:53:13 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:119) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:53:13 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:13 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7606 bytes) 
2025-02-24 11:53:13 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 11:53:13 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 11:53:13 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 11:53:13 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 11:53:13 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 11:53:13 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 11:53:13 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 11:53:13 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 11:53:13 INFO  CodeGenerator: Code generated in 4.878041 ms
2025-02-24 11:53:13 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 46 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:53:13 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 46 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:53:13 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 49 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:53:13 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 48 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:53:13 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 49 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 50 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 50 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:53:13 INFO  CodeGenerator: Code generated in 27.969417 ms
2025-02-24 11:53:13 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1319 bytes result sent to driver
2025-02-24 11:53:13 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 113 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:53:13 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 11:53:13 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:119) finished in 0,152 s
2025-02-24 11:53:13 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:53:13 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 11:53:13 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:119, took 0,153785 s
2025-02-24 11:53:20 INFO  SparkContext: Starting job: jdbc at main.scala:119
2025-02-24 11:53:20 INFO  DAGScheduler: Got job 3 (jdbc at main.scala:119) with 8 output partitions
2025-02-24 11:53:20 INFO  DAGScheduler: Final stage: ResultStage 3 (jdbc at main.scala:119)
2025-02-24 11:53:20 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 11:53:20 INFO  DAGScheduler: Missing parents: List()
2025-02-24 11:53:20 INFO  DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at jdbc at main.scala:119), which has no missing parents
2025-02-24 11:53:20 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 21.7 KiB, free 2.2 GiB)
2025-02-24 11:53:20 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2.2 GiB)
2025-02-24 11:53:20 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:57114 (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 11:53:20 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 11:53:20 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at jdbc at main.scala:119) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 11:53:20 INFO  TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 0.0 in stage 3.0 (TID 17) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 1.0 in stage 3.0 (TID 18) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 2.0 in stage 3.0 (TID 19) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 3.0 in stage 3.0 (TID 20) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 4.0 in stage 3.0 (TID 21) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 5.0 in stage 3.0 (TID 22) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 6.0 in stage 3.0 (TID 23) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 11:53:20 INFO  TaskSetManager: Starting task 7.0 in stage 3.0 (TID 24) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7606 bytes) 
2025-02-24 11:53:20 INFO  Executor: Running task 0.0 in stage 3.0 (TID 17)
2025-02-24 11:53:20 INFO  Executor: Running task 4.0 in stage 3.0 (TID 21)
2025-02-24 11:53:20 INFO  Executor: Running task 5.0 in stage 3.0 (TID 22)
2025-02-24 11:53:20 INFO  Executor: Running task 2.0 in stage 3.0 (TID 19)
2025-02-24 11:53:20 INFO  Executor: Running task 6.0 in stage 3.0 (TID 23)
2025-02-24 11:53:20 INFO  Executor: Running task 3.0 in stage 3.0 (TID 20)
2025-02-24 11:53:20 INFO  Executor: Running task 7.0 in stage 3.0 (TID 24)
2025-02-24 11:53:20 INFO  Executor: Running task 1.0 in stage 3.0 (TID 18)
2025-02-24 11:53:20 INFO  Executor: Finished task 3.0 in stage 3.0 (TID 20). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  Executor: Finished task 2.0 in stage 3.0 (TID 19). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  Executor: Finished task 6.0 in stage 3.0 (TID 23). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 3.0 in stage 3.0 (TID 20) in 8 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 2.0 in stage 3.0 (TID 19) in 9 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 11:53:20 INFO  Executor: Finished task 4.0 in stage 3.0 (TID 21). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 6.0 in stage 3.0 (TID 23) in 9 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 4.0 in stage 3.0 (TID 21) in 11 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 11:53:20 INFO  Executor: Finished task 1.0 in stage 3.0 (TID 18). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 1.0 in stage 3.0 (TID 18) in 12 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 11:53:20 INFO  Executor: Finished task 0.0 in stage 3.0 (TID 17). 1276 bytes result sent to driver
2025-02-24 11:53:20 INFO  Executor: Finished task 5.0 in stage 3.0 (TID 22). 1362 bytes result sent to driver
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 0.0 in stage 3.0 (TID 17) in 21 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 5.0 in stage 3.0 (TID 22) in 21 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 11:53:20 INFO  BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.10.2:57114 in memory (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 11:53:20 INFO  Executor: Finished task 7.0 in stage 3.0 (TID 24). 1362 bytes result sent to driver
2025-02-24 11:53:20 INFO  TaskSetManager: Finished task 7.0 in stage 3.0 (TID 24) in 37 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 11:53:20 INFO  TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-02-24 11:53:20 INFO  DAGScheduler: ResultStage 3 (jdbc at main.scala:119) finished in 0,044 s
2025-02-24 11:53:20 INFO  DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 11:53:20 INFO  TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2025-02-24 11:53:20 INFO  DAGScheduler: Job 3 finished: jdbc at main.scala:119, took 0,045760 s
2025-02-24 11:53:27 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 11:53:27 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 11:53:27 INFO  AbstractConnector: Stopped Spark@3c69362a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 11:53:27 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 11:53:27 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 11:53:27 INFO  MemoryStore: MemoryStore cleared
2025-02-24 11:53:27 INFO  BlockManager: BlockManager stopped
2025-02-24 11:53:27 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 11:53:27 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 11:53:27 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 11:53:27 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 11:53:27 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-13efb8b3-674b-4e81-8c6e-1d82879ce8ec
2025-02-24 14:30:17 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 14:30:17 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 14:30:17 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 14:30:17 INFO  ResourceUtils: ==============================================================
2025-02-24 14:30:17 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 14:30:17 INFO  ResourceUtils: ==============================================================
2025-02-24 14:30:17 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 14:30:17 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 14:30:17 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 14:30:17 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 14:30:17 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 14:30:17 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 14:30:17 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 14:30:17 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 14:30:17 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 14:30:17 INFO  Utils: Successfully started service 'sparkDriver' on port 55360.
2025-02-24 14:30:17 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 14:30:17 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 14:30:17 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 14:30:17 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 14:30:17 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 14:30:17 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-c983b222-f075-4dbf-b2dc-893fb43f53bb
2025-02-24 14:30:17 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 14:30:17 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 14:30:17 INFO  log: Logging initialized @1123ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 14:30:17 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 14:30:17 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 14:30:17 INFO  Server: Started @1188ms
2025-02-24 14:30:17 INFO  AbstractConnector: Started ServerConnector@3f725306{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 14:30:17 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d51e129{/,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 14:30:17 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 14:30:17 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55361.
2025-02-24 14:30:17 INFO  NettyBlockTransferService: Server created on 172.20.10.2:55361
2025-02-24 14:30:17 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 14:30:17 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 55361, None)
2025-02-24 14:30:17 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:55361 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 55361, None)
2025-02-24 14:30:17 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 55361, None)
2025-02-24 14:30:17 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 55361, None)
2025-02-24 14:30:17 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@5d51e129{/,null,STOPPED,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3e7b65d7{/jobs,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ddeaa5f{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@210d2a6c{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4086d8fb{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e3572e8{/stages,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@176555c{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@c386958{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47ac613b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/storage,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3902bd2c{/environment,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@eb6ec6{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/executors,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/static,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44be69aa{/,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21da4b5f{/api,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@480b57e2{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@340d6d89{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 14:30:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 14:30:18 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 14:30:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73a0f2b{/SQL,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a1d526c{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@fb0a08c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4debbf0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5a917723{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 14:30:18 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 14:30:18 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 14:30:19 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:30:19 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 14:30:19 INFO  CodeGenerator: Code generated in 97.31525 ms
2025-02-24 14:30:19 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:55361 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:30:20 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 14:30:20 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:30:20 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:30:20 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 14:30:20 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 14:30:20 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:30:20 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:30:20 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:55361 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:30:20 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:30:20 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 14:30:20 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:30:20 INFO  CodeGenerator: Code generated in 5.647083 ms
2025-02-24 14:30:20 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-02-24 14:30:20 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 102 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 14:30:20 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 14:30:20 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,152 s
2025-02-24 14:30:20 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:30:20 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 14:30:20 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,183118 s
2025-02-24 14:30:20 INFO  CodeGenerator: Code generated in 4.204208 ms
2025-02-24 14:30:20 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:30:20 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:55361 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:30:20 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 14:30:20 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:30:20 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:55361 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:30:20 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:30:20 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 14:30:20 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 14:30:20 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:30:20 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:30:20 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 14:30:20 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:55361 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 14:30:20 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:30:20 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 14:30:20 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:30:20 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 14:30:20 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 14:30:20 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 14:30:20 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 14:30:20 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 14:30:20 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 14:30:20 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 14:30:20 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 14:30:20 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:30:21 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:55361 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:30:21 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 989 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1186 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1205 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1206 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1211 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1216 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1219 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 14:30:21 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 14:30:21 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1223 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 14:30:21 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 14:30:21 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,237 s
2025-02-24 14:30:21 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:30:21 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 14:30:21 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,239227 s
2025-02-24 14:31:36 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 14:31:36 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 14:31:36 INFO  AbstractConnector: Stopped Spark@3f725306{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 14:31:36 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 14:31:36 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 14:31:36 INFO  MemoryStore: MemoryStore cleared
2025-02-24 14:31:36 INFO  BlockManager: BlockManager stopped
2025-02-24 14:31:36 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 14:31:36 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 14:31:36 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 14:31:36 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 14:31:36 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-5f41a090-cece-4ddd-8517-0016dc7e6eec
2025-02-24 14:33:36 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 14:33:36 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 14:33:36 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 14:33:36 INFO  ResourceUtils: ==============================================================
2025-02-24 14:33:36 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 14:33:36 INFO  ResourceUtils: ==============================================================
2025-02-24 14:33:36 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 14:33:36 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 14:33:36 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 14:33:36 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 14:33:36 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 14:33:36 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 14:33:36 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 14:33:36 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 14:33:36 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 14:33:36 INFO  Utils: Successfully started service 'sparkDriver' on port 56758.
2025-02-24 14:33:37 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 14:33:37 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 14:33:37 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 14:33:37 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 14:33:37 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 14:33:37 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-629273cb-fee9-415b-8e2a-6c88d43a88c9
2025-02-24 14:33:37 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 14:33:37 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 14:33:37 INFO  log: Logging initialized @1109ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 14:33:37 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 14:33:37 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 14:33:37 INFO  Server: Started @1173ms
2025-02-24 14:33:37 INFO  AbstractConnector: Started ServerConnector@6f8b3c20{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 14:33:37 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d51e129{/,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 14:33:37 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 14:33:37 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56763.
2025-02-24 14:33:37 INFO  NettyBlockTransferService: Server created on 172.20.10.2:56763
2025-02-24 14:33:37 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 14:33:37 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 56763, None)
2025-02-24 14:33:37 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:56763 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 56763, None)
2025-02-24 14:33:37 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 56763, None)
2025-02-24 14:33:37 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 56763, None)
2025-02-24 14:33:37 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@5d51e129{/,null,STOPPED,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3e7b65d7{/jobs,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ddeaa5f{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@210d2a6c{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4086d8fb{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e3572e8{/stages,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@176555c{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@c386958{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@47ac613b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/storage,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3902bd2c{/environment,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@eb6ec6{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/executors,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/static,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44be69aa{/,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21da4b5f{/api,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@480b57e2{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@340d6d89{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 14:33:37 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73a0f2b{/SQL,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a1d526c{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@fb0a08c{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4debbf0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5a917723{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 14:33:37 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 14:33:37 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 14:33:38 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:33:38 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 14:33:39 INFO  CodeGenerator: Code generated in 99.137625 ms
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:56763 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:33:39 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 14:33:39 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:33:39 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:33:39 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 14:33:39 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 14:33:39 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:33:39 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:33:39 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:56763 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:33:39 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:33:39 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 14:33:39 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:33:39 INFO  CodeGenerator: Code generated in 6.961167 ms
2025-02-24 14:33:39 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 14:33:39 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 124 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 14:33:39 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 14:33:39 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,187 s
2025-02-24 14:33:39 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:33:39 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 14:33:39 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,221994 s
2025-02-24 14:33:39 INFO  CodeGenerator: Code generated in 4.753708 ms
2025-02-24 14:33:39 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:33:39 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:56763 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:33:39 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 14:33:39 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:33:39 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:56763 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:33:39 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:33:39 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 14:33:39 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 14:33:39 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:33:39 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:33:39 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 14:33:39 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:56763 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 14:33:39 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:33:39 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 14:33:39 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:33:39 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 14:33:39 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 14:33:39 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 14:33:39 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 14:33:39 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 14:33:39 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 14:33:39 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 14:33:39 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 14:33:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 14:33:40 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:56763 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:33:40 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 14:33:40 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 860 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1167 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1173 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1173 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1177 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1179 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1180 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 14:33:41 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 14:33:41 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1182 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 14:33:41 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 14:33:41 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,197 s
2025-02-24 14:33:41 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:33:41 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 14:33:41 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,199783 s
2025-02-24 14:34:05 INFO  CodeGenerator: Code generated in 6.232625 ms
2025-02-24 14:34:05 INFO  SparkContext: Starting job: jdbc at main.scala:127
2025-02-24 14:34:05 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:127) with 8 output partitions
2025-02-24 14:34:05 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:127)
2025-02-24 14:34:05 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:34:05 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:34:05 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:127), which has no missing parents
2025-02-24 14:34:05 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.7 KiB, free 2.2 GiB)
2025-02-24 14:34:05 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 2.2 GiB)
2025-02-24 14:34:05 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:56763 (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 14:34:05 INFO  SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:34:05 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at jdbc at main.scala:127) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 14:34:05 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 7493 bytes) 
2025-02-24 14:34:05 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 7583 bytes) 
2025-02-24 14:34:05 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 14:34:05 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 14:34:05 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 14:34:05 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 14:34:05 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 14:34:05 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 14:34:05 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 14:34:05 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 14:34:05 INFO  CodeGenerator: Code generated in 5.577834 ms
2025-02-24 14:34:05 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 51 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 52 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 54 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 51 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 51 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 53 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 52 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 14:34:05 INFO  CodeGenerator: Code generated in 41.365959 ms
2025-02-24 14:34:05 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1319 bytes result sent to driver
2025-02-24 14:34:05 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 132 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 14:34:05 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 14:34:05 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:127) finished in 0,153 s
2025-02-24 14:34:05 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:34:05 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 14:34:05 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:127, took 0,157124 s
2025-02-24 14:34:50 INFO  BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.10.2:56763 in memory (size: 9.4 KiB, free: 2.2 GiB)
2025-02-24 14:34:50 INFO  CodeGenerator: Code generated in 23.713417 ms
2025-02-24 14:34:50 INFO  SparkContext: Starting job: show at main.scala:105
2025-02-24 14:34:50 INFO  DAGScheduler: Got job 3 (show at main.scala:105) with 1 output partitions
2025-02-24 14:34:50 INFO  DAGScheduler: Final stage: ResultStage 3 (show at main.scala:105)
2025-02-24 14:34:50 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:34:50 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:34:50 INFO  DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at show at main.scala:105), which has no missing parents
2025-02-24 14:34:50 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.8 KiB, free 2.2 GiB)
2025-02-24 14:34:50 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 2.2 GiB)
2025-02-24 14:34:50 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:56763 (size: 6.0 KiB, free: 2.2 GiB)
2025-02-24 14:34:50 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:34:50 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at show at main.scala:105) (first 15 tasks are for partitions Vector(0))
2025-02-24 14:34:50 INFO  TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
2025-02-24 14:34:50 INFO  TaskSetManager: Starting task 0.0 in stage 3.0 (TID 17) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 7283 bytes) 
2025-02-24 14:34:50 INFO  Executor: Running task 0.0 in stage 3.0 (TID 17)
2025-02-24 14:34:50 INFO  JDBCRDD: closed connection
2025-02-24 14:34:50 INFO  Executor: Finished task 0.0 in stage 3.0 (TID 17). 1775 bytes result sent to driver
2025-02-24 14:34:50 INFO  TaskSetManager: Finished task 0.0 in stage 3.0 (TID 17) in 39 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 14:34:50 INFO  TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-02-24 14:34:50 INFO  DAGScheduler: ResultStage 3 (show at main.scala:105) finished in 0,046 s
2025-02-24 14:34:50 INFO  DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:34:50 INFO  TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2025-02-24 14:34:50 INFO  DAGScheduler: Job 3 finished: show at main.scala:105, took 0,048448 s
2025-02-24 14:34:50 INFO  CodeGenerator: Code generated in 4.841334 ms
2025-02-24 14:36:28 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:36:28 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 14:36:28 INFO  CodeGenerator: Code generated in 7.787292 ms
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_6 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:36:28 INFO  BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.10.2:56763 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:36:28 INFO  SparkContext: Created broadcast 6 from count at main.scala:47
2025-02-24 14:36:28 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:36:28 INFO  DAGScheduler: Registering RDD 23 (count at main.scala:47) as input to shuffle 0
2025-02-24 14:36:28 INFO  DAGScheduler: Got map stage job 4 (count at main.scala:47) with 8 output partitions
2025-02-24 14:36:28 INFO  DAGScheduler: Final stage: ShuffleMapStage 4 (count at main.scala:47)
2025-02-24 14:36:28 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:36:28 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:36:28 INFO  DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at count at main.scala:47), which has no missing parents
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_7 stored as values in memory (estimated size 17.4 KiB, free 2.2 GiB)
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 2.2 GiB)
2025-02-24 14:36:28 INFO  BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.10.2:56763 (size: 8.7 KiB, free: 2.2 GiB)
2025-02-24 14:36:28 INFO  SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:36:28 INFO  DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at count at main.scala:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 14:36:28 INFO  TaskSchedulerImpl: Adding task set 4.0 with 8 tasks resource profile 0
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 0.0 in stage 4.0 (TID 18) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 1.0 in stage 4.0 (TID 19) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 2.0 in stage 4.0 (TID 20) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 3.0 in stage 4.0 (TID 21) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 4.0 in stage 4.0 (TID 22) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 5.0 in stage 4.0 (TID 23) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 6.0 in stage 4.0 (TID 24) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 7.0 in stage 4.0 (TID 25) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8041 bytes) 
2025-02-24 14:36:28 INFO  Executor: Running task 1.0 in stage 4.0 (TID 19)
2025-02-24 14:36:28 INFO  Executor: Running task 0.0 in stage 4.0 (TID 18)
2025-02-24 14:36:28 INFO  Executor: Running task 3.0 in stage 4.0 (TID 21)
2025-02-24 14:36:28 INFO  Executor: Running task 2.0 in stage 4.0 (TID 20)
2025-02-24 14:36:28 INFO  Executor: Running task 4.0 in stage 4.0 (TID 22)
2025-02-24 14:36:28 INFO  Executor: Running task 5.0 in stage 4.0 (TID 23)
2025-02-24 14:36:28 INFO  Executor: Running task 6.0 in stage 4.0 (TID 24)
2025-02-24 14:36:28 INFO  Executor: Running task 7.0 in stage 4.0 (TID 25)
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 14:36:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 14:36:28 INFO  CodeGenerator: Code generated in 2.947334 ms
2025-02-24 14:36:28 INFO  Executor: Finished task 7.0 in stage 4.0 (TID 25). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 7.0 in stage 4.0 (TID 25) in 336 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 14:36:28 INFO  BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.10.2:56763 in memory (size: 6.0 KiB, free: 2.2 GiB)
2025-02-24 14:36:28 INFO  Executor: Finished task 3.0 in stage 4.0 (TID 21). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 3.0 in stage 4.0 (TID 21) in 370 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 6.0 in stage 4.0 (TID 24). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 6.0 in stage 4.0 (TID 24) in 370 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 4.0 in stage 4.0 (TID 22). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 4.0 in stage 4.0 (TID 22) in 371 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 5.0 in stage 4.0 (TID 23). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 5.0 in stage 4.0 (TID 23) in 372 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 2.0 in stage 4.0 (TID 20). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 2.0 in stage 4.0 (TID 20) in 373 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 1.0 in stage 4.0 (TID 19). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 1.0 in stage 4.0 (TID 19) in 374 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 14:36:28 INFO  Executor: Finished task 0.0 in stage 4.0 (TID 18). 2059 bytes result sent to driver
2025-02-24 14:36:28 INFO  TaskSetManager: Finished task 0.0 in stage 4.0 (TID 18) in 374 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 14:36:28 INFO  TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-02-24 14:36:28 INFO  DAGScheduler: ShuffleMapStage 4 (count at main.scala:47) finished in 0,387 s
2025-02-24 14:36:28 INFO  DAGScheduler: looking for newly runnable stages
2025-02-24 14:36:28 INFO  DAGScheduler: running: HashSet()
2025-02-24 14:36:28 INFO  DAGScheduler: waiting: HashSet()
2025-02-24 14:36:28 INFO  DAGScheduler: failed: HashSet()
2025-02-24 14:36:28 INFO  CodeGenerator: Code generated in 4.078584 ms
2025-02-24 14:36:28 INFO  SparkContext: Starting job: count at main.scala:47
2025-02-24 14:36:28 INFO  DAGScheduler: Got job 5 (count at main.scala:47) with 1 output partitions
2025-02-24 14:36:28 INFO  DAGScheduler: Final stage: ResultStage 6 (count at main.scala:47)
2025-02-24 14:36:28 INFO  DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
2025-02-24 14:36:28 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:36:28 INFO  DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at main.scala:47), which has no missing parents
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.7 KiB, free 2.2 GiB)
2025-02-24 14:36:28 INFO  MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 2.2 GiB)
2025-02-24 14:36:28 INFO  BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.10.2:56763 (size: 6.0 KiB, free: 2.2 GiB)
2025-02-24 14:36:28 INFO  SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:36:28 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at main.scala:47) (first 15 tasks are for partitions Vector(0))
2025-02-24 14:36:28 INFO  TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
2025-02-24 14:36:28 INFO  TaskSetManager: Starting task 0.0 in stage 6.0 (TID 26) (172.20.10.2, executor driver, partition 0, NODE_LOCAL, 7437 bytes) 
2025-02-24 14:36:28 INFO  Executor: Running task 0.0 in stage 6.0 (TID 26)
2025-02-24 14:36:29 INFO  ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-02-24 14:36:29 INFO  ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
2025-02-24 14:36:29 INFO  Executor: Finished task 0.0 in stage 6.0 (TID 26). 4084 bytes result sent to driver
2025-02-24 14:36:29 INFO  TaskSetManager: Finished task 0.0 in stage 6.0 (TID 26) in 24 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 14:36:29 INFO  TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-02-24 14:36:29 INFO  DAGScheduler: ResultStage 6 (count at main.scala:47) finished in 0,028 s
2025-02-24 14:36:29 INFO  DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:36:29 INFO  TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
2025-02-24 14:36:29 INFO  DAGScheduler: Job 5 finished: count at main.scala:47, took 0,032577 s
2025-02-24 14:37:14 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 14:37:14 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 14:37:14 INFO  AbstractConnector: Stopped Spark@6f8b3c20{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 14:37:14 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 14:37:14 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 14:37:14 INFO  MemoryStore: MemoryStore cleared
2025-02-24 14:37:14 INFO  BlockManager: BlockManager stopped
2025-02-24 14:37:14 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 14:37:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 14:37:14 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 14:37:14 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 14:37:14 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-520b2af8-b125-4954-a911-78bf6f8c0f02
2025-02-24 14:57:25 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 14:57:25 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 14:57:25 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 14:57:25 INFO  ResourceUtils: ==============================================================
2025-02-24 14:57:25 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 14:57:25 INFO  ResourceUtils: ==============================================================
2025-02-24 14:57:25 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 14:57:25 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 14:57:25 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 14:57:25 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 14:57:25 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 14:57:25 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 14:57:25 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 14:57:25 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 14:57:25 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 14:57:26 INFO  Utils: Successfully started service 'sparkDriver' on port 50246.
2025-02-24 14:57:26 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 14:57:26 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 14:57:26 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 14:57:26 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 14:57:26 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 14:57:26 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-407ab0c2-84b6-4ea6-86c4-fdc227abbbbd
2025-02-24 14:57:26 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 14:57:26 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 14:57:26 INFO  log: Logging initialized @1182ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 14:57:26 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 14:57:26 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 14:57:26 INFO  Server: Started @1257ms
2025-02-24 14:57:26 INFO  AbstractConnector: Started ServerConnector@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 14:57:26 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68d651f2{/,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 14:57:26 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 14:57:26 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50250.
2025-02-24 14:57:26 INFO  NettyBlockTransferService: Server created on 172.20.10.2:50250
2025-02-24 14:57:26 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 14:57:26 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 50250, None)
2025-02-24 14:57:26 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:50250 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 50250, None)
2025-02-24 14:57:26 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 50250, None)
2025-02-24 14:57:26 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 50250, None)
2025-02-24 14:57:26 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@68d651f2{/,null,STOPPED,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/jobs,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/stages,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/storage,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/environment,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/executors,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/static,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@443faa85{/,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41da3aee{/api,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c8a7e38{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41184371{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 14:57:26 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cedee22{/SQL,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5b47731f{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e13f304{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d24420b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16ac5d35{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 14:57:26 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 14:57:27 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 14:57:27 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:57:27 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 14:57:28 INFO  CodeGenerator: Code generated in 85.381334 ms
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:50250 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:57:28 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 14:57:28 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:57:28 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:57:28 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 14:57:28 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 14:57:28 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:57:28 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:57:28 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:50250 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:57:28 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:57:28 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 14:57:28 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:57:28 INFO  CodeGenerator: Code generated in 6.012583 ms
2025-02-24 14:57:28 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 14:57:28 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 96 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 14:57:28 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 14:57:28 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,149 s
2025-02-24 14:57:28 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:57:28 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 14:57:28 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,179840 s
2025-02-24 14:57:28 INFO  CodeGenerator: Code generated in 4.397416 ms
2025-02-24 14:57:28 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 14:57:28 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:50250 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:57:28 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 14:57:28 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 14:57:28 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:50250 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 14:57:28 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 14:57:28 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 14:57:28 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 14:57:28 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 14:57:28 INFO  DAGScheduler: Missing parents: List()
2025-02-24 14:57:28 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 14:57:28 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:50250 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 14:57:28 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 14:57:28 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 14:57:28 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 14:57:28 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 14:57:28 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 14:57:28 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 14:57:28 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 14:57:28 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 14:57:28 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 14:57:28 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 14:57:28 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 14:57:28 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 14:57:29 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:50250 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 14:57:29 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 703 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 14:57:29 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 814 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 14:57:29 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 825 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 827 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 14:57:29 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 832 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 833 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 14:57:29 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 833 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 14:57:29 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 14:57:29 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 834 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 14:57:29 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 14:57:29 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 0,850 s
2025-02-24 14:57:29 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 14:57:29 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 14:57:29 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 0,852075 s
2025-02-24 14:57:34 INFO  CodeGenerator: Code generated in 6.848375 ms
2025-02-24 14:57:34 INFO  SparkContext: Starting job: jdbc at main.scala:147
2025-02-24 14:57:34 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:147, took 0,000157 s
2025-02-24 15:00:26 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:00:26 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:00:26 INFO  AbstractConnector: Stopped Spark@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:00:26 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:00:26 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:00:26 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:00:26 INFO  BlockManager: BlockManager stopped
2025-02-24 15:00:26 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:00:26 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:00:26 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:00:26 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:00:26 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-f5177fbc-0ffd-402d-bd90-61a46f01dbc5
2025-02-24 15:00:29 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:00:29 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:00:29 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:00:29 INFO  ResourceUtils: ==============================================================
2025-02-24 15:00:29 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:00:29 INFO  ResourceUtils: ==============================================================
2025-02-24 15:00:29 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:00:29 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:00:29 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:00:29 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:00:29 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:00:29 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:00:29 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:00:29 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:00:29 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:00:30 INFO  Utils: Successfully started service 'sparkDriver' on port 51562.
2025-02-24 15:00:30 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:00:30 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:00:30 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:00:30 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:00:30 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:00:30 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-66a4cdb3-3986-4e7a-b553-5dc846f0c1ff
2025-02-24 15:00:30 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:00:30 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:00:30 INFO  log: Logging initialized @973ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:00:30 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:00:30 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:00:30 INFO  Server: Started @1031ms
2025-02-24 15:00:30 INFO  AbstractConnector: Started ServerConnector@75ddedd7{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:00:30 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68d651f2{/,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:00:30 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:00:30 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51567.
2025-02-24 15:00:30 INFO  NettyBlockTransferService: Server created on 172.20.10.2:51567
2025-02-24 15:00:30 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:00:30 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 51567, None)
2025-02-24 15:00:30 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:51567 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 51567, None)
2025-02-24 15:00:30 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 51567, None)
2025-02-24 15:00:30 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 51567, None)
2025-02-24 15:00:30 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@68d651f2{/,null,STOPPED,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/static,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@443faa85{/,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41da3aee{/api,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c8a7e38{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41184371{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:00:30 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cedee22{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5b47731f{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e13f304{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d24420b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16ac5d35{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:00:30 INFO  InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
2025-02-24 15:00:30 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:00:31 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:00:31 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:00:32 INFO  CodeGenerator: Code generated in 87.600584 ms
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:51567 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:00:32 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 15:00:32 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:00:32 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:00:32 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 15:00:32 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 15:00:32 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:00:32 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:00:32 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:51567 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:00:32 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:00:32 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:00:32 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:00:32 INFO  CodeGenerator: Code generated in 6.316292 ms
2025-02-24 15:00:32 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:00:32 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 97 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:00:32 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:00:32 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,154 s
2025-02-24 15:00:32 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:00:32 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:00:32 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,184176 s
2025-02-24 15:00:32 INFO  CodeGenerator: Code generated in 4.568666 ms
2025-02-24 15:00:32 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:00:32 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:51567 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:00:32 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 15:00:32 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:00:32 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:51567 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:00:32 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:00:32 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 15:00:32 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 15:00:32 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:00:32 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:00:32 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:00:32 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:51567 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:00:32 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:00:32 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:00:32 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:32 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:00:32 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:00:32 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:00:32 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:00:32 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:00:32 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:00:32 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:00:32 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:00:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:00:33 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:51567 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:00:33 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 725 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 844 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 847 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 851 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 851 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 856 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 857 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:00:33 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:00:33 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 859 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:00:33 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:00:33 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 0,873 s
2025-02-24 15:00:33 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:00:33 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:00:33 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 0,874921 s
2025-02-24 15:00:38 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:00:38 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:00:38 INFO  CodeGenerator: Code generated in 11.660917 ms
2025-02-24 15:00:38 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:00:38 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:00:38 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:51567 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:00:38 INFO  SparkContext: Created broadcast 4 from show at main.scala:144
2025-02-24 15:00:38 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:00:38 INFO  SparkContext: Starting job: show at main.scala:144
2025-02-24 15:00:38 INFO  DAGScheduler: Got job 2 (show at main.scala:144) with 1 output partitions
2025-02-24 15:00:38 INFO  DAGScheduler: Final stage: ResultStage 2 (show at main.scala:144)
2025-02-24 15:00:38 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:00:38 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:00:38 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at show at main.scala:144), which has no missing parents
2025-02-24 15:00:38 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 17.7 KiB, free 2.2 GiB)
2025-02-24 15:00:38 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 2.2 GiB)
2025-02-24 15:00:38 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:51567 (size: 8.3 KiB, free: 2.2 GiB)
2025-02-24 15:00:38 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:00:38 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at show at main.scala:144) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:00:38 INFO  TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
2025-02-24 15:00:38 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:00:38 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:00:38 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:00:38 INFO  CodeGenerator: Code generated in 6.800042 ms
2025-02-24 15:00:38 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 2770 bytes result sent to driver
2025-02-24 15:00:38 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 43 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:00:38 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 15:00:38 INFO  DAGScheduler: ResultStage 2 (show at main.scala:144) finished in 0,048 s
2025-02-24 15:00:38 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:00:38 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 15:00:38 INFO  DAGScheduler: Job 2 finished: show at main.scala:144, took 0,049466 s
2025-02-24 15:00:38 INFO  CodeGenerator: Code generated in 12.288458 ms
2025-02-24 15:00:38 INFO  CodeGenerator: Code generated in 7.388334 ms
2025-02-24 15:00:38 INFO  SparkContext: Starting job: jdbc at main.scala:150
2025-02-24 15:00:38 INFO  DAGScheduler: Job 3 finished: jdbc at main.scala:150, took 0,000113 s
2025-02-24 15:03:14 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:03:14 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:03:14 INFO  AbstractConnector: Stopped Spark@75ddedd7{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:03:14 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:03:14 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:03:14 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:03:14 INFO  BlockManager: BlockManager stopped
2025-02-24 15:03:14 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:03:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:03:14 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:03:14 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:03:14 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-e556b980-c553-4c89-bcb8-c735b26a88ee
2025-02-24 15:03:16 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:03:16 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:03:16 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:03:17 INFO  ResourceUtils: ==============================================================
2025-02-24 15:03:17 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:03:17 INFO  ResourceUtils: ==============================================================
2025-02-24 15:03:17 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:03:17 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:03:17 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:03:17 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:03:17 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:03:17 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:03:17 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:03:17 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:03:17 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:03:17 INFO  Utils: Successfully started service 'sparkDriver' on port 52740.
2025-02-24 15:03:17 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:03:17 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:03:17 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:03:17 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:03:17 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:03:17 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-bdf0955a-fe50-4a84-8c61-0c879116227c
2025-02-24 15:03:17 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:03:17 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:03:17 INFO  log: Logging initialized @986ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:03:17 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:03:17 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:03:17 INFO  Server: Started @1048ms
2025-02-24 15:03:17 INFO  AbstractConnector: Started ServerConnector@6daf7d37{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:03:17 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ad4a7d6{/,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:03:17 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:03:17 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52741.
2025-02-24 15:03:17 INFO  NettyBlockTransferService: Server created on 172.20.10.2:52741
2025-02-24 15:03:17 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:03:17 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 52741, None)
2025-02-24 15:03:17 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:52741 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 52741, None)
2025-02-24 15:03:17 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 52741, None)
2025-02-24 15:03:17 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 52741, None)
2025-02-24 15:03:17 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@3ad4a7d6{/,null,STOPPED,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3166f664{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2152ab30{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@766a49c7{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@75e27856{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f4c88f9{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cb39552{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2a53f215{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7beae796{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@52bf7bf6{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ae73c80{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@bbd4791{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73971965{/static,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1ee47d9e{/,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5dc0ff7d{/api,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30839e44{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34585ac9{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:03:17 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59b32539{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@233db8e9{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@787508ca{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6274670b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:03:17 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3965bdf9{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:03:18 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 15:03:18 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:03:19 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:03:19 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:03:19 INFO  CodeGenerator: Code generated in 90.451125 ms
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:52741 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:03:19 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 15:03:19 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:03:19 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:03:19 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 15:03:19 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 15:03:19 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:03:19 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:03:19 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:52741 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:03:19 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:03:19 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:03:19 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:03:19 INFO  CodeGenerator: Code generated in 6.405916 ms
2025-02-24 15:03:19 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-02-24 15:03:19 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 103 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:03:19 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:03:19 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,154 s
2025-02-24 15:03:19 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:03:19 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:03:19 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,182992 s
2025-02-24 15:03:19 INFO  CodeGenerator: Code generated in 4.104667 ms
2025-02-24 15:03:19 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:03:19 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:52741 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:03:19 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 15:03:19 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:03:19 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:03:19 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 15:03:19 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 15:03:19 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:03:19 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:03:19 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:03:19 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:52741 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:03:19 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:03:19 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:03:19 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:03:19 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:03:19 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:03:19 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:03:19 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:03:19 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:03:19 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:03:19 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:03:19 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:03:19 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:03:19 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:52741 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:03:19 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:52741 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:03:20 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:03:20 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 875 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:03:20 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:03:20 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1052 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1600 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1616 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1645 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1657 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1665 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:03:21 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:03:21 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1676 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:03:21 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:03:21 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,689 s
2025-02-24 15:03:21 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:03:21 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:03:21 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,691187 s
2025-02-24 15:03:52 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:03:52 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:03:52 INFO  AbstractConnector: Stopped Spark@6daf7d37{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:03:52 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:03:52 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:03:52 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:03:52 INFO  BlockManager: BlockManager stopped
2025-02-24 15:03:52 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:03:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:03:52 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:03:52 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:03:52 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-ebb95fe7-8734-4e79-be12-32d9bf6683a9
2025-02-24 15:04:22 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:04:22 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:04:22 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:04:22 INFO  ResourceUtils: ==============================================================
2025-02-24 15:04:22 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:04:22 INFO  ResourceUtils: ==============================================================
2025-02-24 15:04:22 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:04:22 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:04:22 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:04:22 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:04:22 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:04:22 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:04:22 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:04:22 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:04:22 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:04:22 INFO  Utils: Successfully started service 'sparkDriver' on port 53212.
2025-02-24 15:04:22 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:04:22 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:04:22 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:04:22 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:04:22 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:04:22 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-8641de21-c59e-4e2c-873c-e747fccedcc8
2025-02-24 15:04:22 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:04:22 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:04:22 INFO  log: Logging initialized @1129ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:04:23 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:04:23 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:04:23 INFO  Server: Started @1192ms
2025-02-24 15:04:23 INFO  AbstractConnector: Started ServerConnector@d7f4a2e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:04:23 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7915bca3{/,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:04:23 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:04:23 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53219.
2025-02-24 15:04:23 INFO  NettyBlockTransferService: Server created on 172.20.10.2:53219
2025-02-24 15:04:23 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:04:23 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 53219, None)
2025-02-24 15:04:23 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:53219 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 53219, None)
2025-02-24 15:04:23 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 53219, None)
2025-02-24 15:04:23 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 53219, None)
2025-02-24 15:04:23 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@7915bca3{/,null,STOPPED,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@157ec23b{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60d6fdd4{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34d45ec0{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@766a49c7{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@75e27856{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f4c88f9{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cb39552{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2a53f215{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7beae796{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@52bf7bf6{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ae73c80{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@bbd4791{/static,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@561953e3{/,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1ee47d9e{/api,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21a02556{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36baa049{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:04:23 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d94a2dc{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59b32539{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a7e509{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@787508ca{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7f7b6639{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:04:23 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 15:04:23 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:04:24 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:04:24 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:04:25 INFO  CodeGenerator: Code generated in 113.63875 ms
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:53219 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:04:25 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 15:04:25 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:04:25 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:04:25 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 15:04:25 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 15:04:25 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:04:25 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:04:25 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:53219 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:04:25 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:04:25 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:04:25 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:04:25 INFO  CodeGenerator: Code generated in 6.390208 ms
2025-02-24 15:04:25 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:04:25 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 106 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:04:25 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:04:25 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,164 s
2025-02-24 15:04:25 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:04:25 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:04:25 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,200024 s
2025-02-24 15:04:25 INFO  CodeGenerator: Code generated in 5.652042 ms
2025-02-24 15:04:25 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:04:25 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:53219 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:04:25 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 15:04:25 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:04:25 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:04:25 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 15:04:25 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 15:04:25 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:04:25 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:04:25 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:04:25 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:53219 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:04:25 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:04:25 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:53219 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:04:25 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:04:25 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:04:25 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:04:25 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:04:25 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:04:25 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:04:25 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:04:25 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:04:25 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:04:25 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:04:25 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:04:25 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:53219 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:04:27 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1255 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1412 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1419 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1431 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1437 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1442 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:04:27 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1447 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:04:27 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1448 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:04:27 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:04:27 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,471 s
2025-02-24 15:04:27 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:04:27 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:04:27 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,472730 s
2025-02-24 15:04:27 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:04:27 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:04:27 INFO  AbstractConnector: Stopped Spark@d7f4a2e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:04:27 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:04:27 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:04:27 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:04:27 INFO  BlockManager: BlockManager stopped
2025-02-24 15:04:27 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:04:27 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:04:27 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:04:27 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:04:27 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-9be753b8-730b-4874-a082-52838c1d8919
2025-02-24 15:05:49 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:05:49 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:05:49 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:05:49 INFO  ResourceUtils: ==============================================================
2025-02-24 15:05:49 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:05:49 INFO  ResourceUtils: ==============================================================
2025-02-24 15:05:49 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:05:49 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:05:49 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:05:49 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:05:49 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:05:49 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:05:49 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:05:49 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:05:49 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:05:49 INFO  Utils: Successfully started service 'sparkDriver' on port 53834.
2025-02-24 15:05:49 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:05:49 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:05:49 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:05:49 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:05:49 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:05:49 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-a6690bf3-f641-4456-b158-320bd30e6bdf
2025-02-24 15:05:50 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:05:50 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:05:50 INFO  log: Logging initialized @1129ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:05:50 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:05:50 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:05:50 INFO  Server: Started @1192ms
2025-02-24 15:05:50 INFO  AbstractConnector: Started ServerConnector@23b0bbf6{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:05:50 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7915bca3{/,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:05:50 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:05:50 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53835.
2025-02-24 15:05:50 INFO  NettyBlockTransferService: Server created on 172.20.10.2:53835
2025-02-24 15:05:50 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:05:50 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 53835, None)
2025-02-24 15:05:50 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:53835 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 53835, None)
2025-02-24 15:05:50 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 53835, None)
2025-02-24 15:05:50 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 53835, None)
2025-02-24 15:05:50 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@7915bca3{/,null,STOPPED,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@157ec23b{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60d6fdd4{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34d45ec0{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@766a49c7{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@75e27856{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f4c88f9{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cb39552{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2a53f215{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7beae796{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@52bf7bf6{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ae73c80{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@bbd4791{/static,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@561953e3{/,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1ee47d9e{/api,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21a02556{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36baa049{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:05:50 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d94a2dc{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59b32539{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a7e509{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@787508ca{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7f7b6639{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:05:50 INFO  InMemoryFileIndex: It took 20 ms to list leaf files for 1 paths.
2025-02-24 15:05:50 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:05:51 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:05:51 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:05:52 INFO  CodeGenerator: Code generated in 101.149791 ms
2025-02-24 15:05:52 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:05:52 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:05:52 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:53835 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:05:52 INFO  SparkContext: Created broadcast 0 from csv at main.scala:16
2025-02-24 15:05:52 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:05:52 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:05:52 INFO  DAGScheduler: Got job 0 (csv at main.scala:16) with 1 output partitions
2025-02-24 15:05:52 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:16)
2025-02-24 15:05:52 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:05:52 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:05:52 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16), which has no missing parents
2025-02-24 15:05:52 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:05:52 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:05:52 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:53835 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:05:52 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:05:52 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:05:52 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:05:52 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:52 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:05:52 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:05:52 INFO  CodeGenerator: Code generated in 8.76225 ms
2025-02-24 15:05:52 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:05:52 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 142 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:05:52 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:05:52 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:16) finished in 0,201 s
2025-02-24 15:05:52 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:05:52 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:05:52 INFO  DAGScheduler: Job 0 finished: csv at main.scala:16, took 0,261835 s
2025-02-24 15:05:52 INFO  CodeGenerator: Code generated in 5.89475 ms
2025-02-24 15:05:52 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:05:52 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:05:52 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:05:53 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:05:53 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:53835 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:05:53 INFO  SparkContext: Created broadcast 2 from csv at main.scala:16
2025-02-24 15:05:53 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:05:53 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:53835 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:05:53 INFO  SparkContext: Starting job: csv at main.scala:16
2025-02-24 15:05:53 INFO  DAGScheduler: Got job 1 (csv at main.scala:16) with 8 output partitions
2025-02-24 15:05:53 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:16)
2025-02-24 15:05:53 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:05:53 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:05:53 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16), which has no missing parents
2025-02-24 15:05:53 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:05:53 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:05:53 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:53835 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:05:53 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:05:53 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:16) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:05:53 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:53 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:05:53 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:05:53 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:05:53 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:05:53 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:05:53 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:05:53 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:05:53 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:05:53 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:05:53 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:53835 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:05:54 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1151 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1292 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1296 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1305 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1307 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1308 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1310 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:05:54 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:05:54 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1313 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:05:54 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:05:54 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:16) finished in 1,328 s
2025-02-24 15:05:54 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:05:54 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:05:54 INFO  DAGScheduler: Job 1 finished: csv at main.scala:16, took 1,330099 s
2025-02-24 15:05:58 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:05:58 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:05:58 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:05:58 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:05:58 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:53835 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:05:58 INFO  SparkContext: Created broadcast 4 from jdbc at main.scala:153
2025-02-24 15:05:58 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:05:58 INFO  SparkContext: Starting job: jdbc at main.scala:153
2025-02-24 15:05:58 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:153) with 8 output partitions
2025-02-24 15:05:58 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:153)
2025-02-24 15:05:58 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:05:58 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:05:58 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at jdbc at main.scala:153), which has no missing parents
2025-02-24 15:05:58 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.2 KiB, free 2.2 GiB)
2025-02-24 15:05:58 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 2.2 GiB)
2025-02-24 15:05:58 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:53835 (size: 10.5 KiB, free: 2.2 GiB)
2025-02-24 15:05:58 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:05:58 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at jdbc at main.scala:153) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:05:58 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:05:58 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 15:05:58 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 15:05:58 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 15:05:58 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:05:58 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 15:05:58 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 15:05:58 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 15:05:58 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 15:05:58 INFO  CodeGenerator: Code generated in 15.137458 ms
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:05:58 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:05:58 INFO  CodeGenerator: Code generated in 6.82475 ms
2025-02-24 15:06:34 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1656 bytes result sent to driver
2025-02-24 15:06:34 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 36561 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:07:01 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1613 bytes result sent to driver
2025-02-24 15:07:01 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 63450 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:07:01 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1613 bytes result sent to driver
2025-02-24 15:07:01 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 63622 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:07:02 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1656 bytes result sent to driver
2025-02-24 15:07:02 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1656 bytes result sent to driver
2025-02-24 15:07:02 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 63846 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:07:02 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 63847 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:07:02 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1613 bytes result sent to driver
2025-02-24 15:07:02 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 63967 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:07:02 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1613 bytes result sent to driver
2025-02-24 15:07:02 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 64052 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:07:02 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1613 bytes result sent to driver
2025-02-24 15:07:02 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 64427 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:07:02 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 15:07:02 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:153) finished in 64,437 s
2025-02-24 15:07:02 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:07:02 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 15:07:02 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:153, took 64,440207 s
2025-02-24 15:35:50 INFO  BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.10.2:53835 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:35:50 INFO  BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.10.2:53835 in memory (size: 10.5 KiB, free: 2.2 GiB)
2025-02-24 15:35:50 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:53835 in memory (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:35:50 INFO  BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.10.2:53835 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:50:33 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:50:33 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:50:33 INFO  AbstractConnector: Stopped Spark@23b0bbf6{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:50:33 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:50:33 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:50:33 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:50:33 INFO  BlockManager: BlockManager stopped
2025-02-24 15:50:33 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:50:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:50:33 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:50:33 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:50:33 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-e357e520-6329-4a82-9242-acd3a30d4113
2025-02-24 15:50:36 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:50:36 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:50:36 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:50:36 INFO  ResourceUtils: ==============================================================
2025-02-24 15:50:36 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:50:36 INFO  ResourceUtils: ==============================================================
2025-02-24 15:50:36 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:50:36 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:50:36 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:50:36 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:50:36 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:50:36 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:50:36 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:50:36 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:50:36 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:50:37 INFO  Utils: Successfully started service 'sparkDriver' on port 52159.
2025-02-24 15:50:37 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:50:37 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:50:37 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:50:37 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:50:37 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:50:37 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-44ea097e-13d2-4c1d-a556-be99b289ee20
2025-02-24 15:50:37 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:50:37 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:50:37 INFO  log: Logging initialized @1098ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:50:37 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:50:37 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:50:37 INFO  Server: Started @1166ms
2025-02-24 15:50:37 INFO  AbstractConnector: Started ServerConnector@1aec613d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:50:37 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68d651f2{/,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:50:37 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:50:37 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52160.
2025-02-24 15:50:37 INFO  NettyBlockTransferService: Server created on 172.20.10.2:52160
2025-02-24 15:50:37 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:50:37 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 52160, None)
2025-02-24 15:50:37 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:52160 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 52160, None)
2025-02-24 15:50:37 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 52160, None)
2025-02-24 15:50:37 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 52160, None)
2025-02-24 15:50:37 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@68d651f2{/,null,STOPPED,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/static,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@443faa85{/,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41da3aee{/api,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c8a7e38{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41184371{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:50:37 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cedee22{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5b47731f{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e13f304{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d24420b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16ac5d35{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:50:37 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-02-24 15:50:38 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:50:38 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:50:39 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:50:39 INFO  CodeGenerator: Code generated in 111.5365 ms
2025-02-24 15:50:39 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:50:39 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:50:39 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:52160 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:50:39 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-02-24 15:50:39 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:50:39 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:50:39 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-02-24 15:50:39 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-02-24 15:50:39 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:50:39 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:50:39 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-02-24 15:50:39 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:50:39 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:50:39 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:52160 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:50:39 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:50:39 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:50:39 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:50:39 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:39 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:50:39 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:50:39 INFO  CodeGenerator: Code generated in 6.156791 ms
2025-02-24 15:50:39 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-02-24 15:50:39 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 114 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:50:39 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:50:39 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,168 s
2025-02-24 15:50:39 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:50:39 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:50:39 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,199686 s
2025-02-24 15:50:39 INFO  CodeGenerator: Code generated in 4.444375 ms
2025-02-24 15:50:40 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:50:40 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:50:40 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:50:40 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:50:40 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:52160 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:50:40 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-02-24 15:50:40 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:50:40 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:52160 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:50:40 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:52160 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:50:40 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:50:40 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-02-24 15:50:40 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-02-24 15:50:40 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:50:40 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:50:40 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-02-24 15:50:40 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:50:40 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:50:40 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:52160 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:50:40 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:50:40 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:50:40 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:50:40 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:50:40 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:50:40 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:50:40 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:50:40 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:50:40 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:50:40 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:50:40 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:50:40 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:50:41 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 947 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1161 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1163 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1178 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1574 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1597 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1604 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:50:41 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:50:41 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1621 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:50:41 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:50:41 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 1,633 s
2025-02-24 15:50:41 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:50:41 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:50:41 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,634849 s
2025-02-24 15:51:48 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:51:48 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:51:48 INFO  AbstractConnector: Stopped Spark@1aec613d{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:51:48 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:51:48 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:51:48 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:51:48 INFO  BlockManager: BlockManager stopped
2025-02-24 15:51:48 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:51:48 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:51:48 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:51:48 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:51:48 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-332b9d9c-b91b-4df1-9f73-2c3aabbbdbd5
2025-02-24 15:52:03 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:52:03 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:52:03 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:52:03 INFO  ResourceUtils: ==============================================================
2025-02-24 15:52:03 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:52:03 INFO  ResourceUtils: ==============================================================
2025-02-24 15:52:03 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:52:03 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:52:03 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:52:03 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:52:03 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:52:03 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:52:03 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:52:03 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:52:03 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:52:03 INFO  Utils: Successfully started service 'sparkDriver' on port 52659.
2025-02-24 15:52:03 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:52:03 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:52:03 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:52:03 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:52:03 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:52:03 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-91c08de8-cd0d-4a05-9421-95d196239103
2025-02-24 15:52:03 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:52:03 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:52:03 INFO  log: Logging initialized @1204ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:52:03 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:52:03 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:52:03 INFO  Server: Started @1268ms
2025-02-24 15:52:03 INFO  AbstractConnector: Started ServerConnector@5890763{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:52:03 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7915bca3{/,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:52:03 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:52:03 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52660.
2025-02-24 15:52:03 INFO  NettyBlockTransferService: Server created on 172.20.10.2:52660
2025-02-24 15:52:03 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:52:03 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 52660, None)
2025-02-24 15:52:03 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:52660 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 52660, None)
2025-02-24 15:52:03 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 52660, None)
2025-02-24 15:52:03 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 52660, None)
2025-02-24 15:52:03 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@7915bca3{/,null,STOPPED,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@157ec23b{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60d6fdd4{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34d45ec0{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@766a49c7{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@75e27856{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f4c88f9{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cb39552{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2a53f215{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7beae796{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@52bf7bf6{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ae73c80{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@bbd4791{/static,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@561953e3{/,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1ee47d9e{/api,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@21a02556{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@36baa049{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:52:03 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d94a2dc{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59b32539{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a7e509{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@787508ca{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:52:03 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7f7b6639{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:52:04 INFO  InMemoryFileIndex: It took 22 ms to list leaf files for 1 paths.
2025-02-24 15:52:04 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 15:52:05 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:52:05 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:52:05 INFO  CodeGenerator: Code generated in 93.121791 ms
2025-02-24 15:52:05 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:52:05 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:52:05 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:52660 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:52:05 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-02-24 15:52:05 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:52:06 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:52:06 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-02-24 15:52:06 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-02-24 15:52:06 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:52:06 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:52:06 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:52:06 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:52660 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:52:06 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:52:06 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:52:06 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:52:06 INFO  CodeGenerator: Code generated in 5.884333 ms
2025-02-24 15:52:06 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:52:06 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 89 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:52:06 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:52:06 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,165 s
2025-02-24 15:52:06 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:52:06 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:52:06 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,198882 s
2025-02-24 15:52:06 INFO  CodeGenerator: Code generated in 4.085625 ms
2025-02-24 15:52:06 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:52:06 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:52:06 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:52660 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:52:06 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-02-24 15:52:06 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:52:06 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:52660 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:52:06 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:52:06 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-02-24 15:52:06 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-02-24 15:52:06 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:52:06 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:52:06 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:52:06 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:52:06 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:52660 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:52:06 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:52:06 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:52:06 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:52:06 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:52:06 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:52:06 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:52:06 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:52:06 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:52:06 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:52:06 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:52:06 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:52:06 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:52:06 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:52660 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:52:07 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 820 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 903 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 911 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 919 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 921 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 926 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 932 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:52:07 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:52:07 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 934 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:52:07 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:52:07 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 0,946 s
2025-02-24 15:52:07 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:52:07 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:52:07 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 0,948269 s
2025-02-24 15:52:13 INFO  CodeGenerator: Code generated in 6.551792 ms
2025-02-24 15:52:13 INFO  SparkContext: Starting job: jdbc at main.scala:149
2025-02-24 15:52:13 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:149, took 0,000136 s
2025-02-24 15:53:06 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:53:06 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:53:06 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:53:06 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:53:06 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:52660 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:53:06 INFO  SparkContext: Created broadcast 4 from jdbc at main.scala:155
2025-02-24 15:53:06 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:53:06 INFO  SparkContext: Starting job: jdbc at main.scala:155
2025-02-24 15:53:07 INFO  DAGScheduler: Got job 3 (jdbc at main.scala:155) with 8 output partitions
2025-02-24 15:53:07 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:155)
2025-02-24 15:53:07 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:53:07 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:53:07 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:155), which has no missing parents
2025-02-24 15:53:07 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.2 KiB, free 2.2 GiB)
2025-02-24 15:53:07 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 2.2 GiB)
2025-02-24 15:53:07 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:52660 (size: 10.4 KiB, free: 2.2 GiB)
2025-02-24 15:53:07 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:53:07 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:53:07 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:53:07 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 15:53:07 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 15:53:07 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:53:07 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 15:53:07 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 15:53:07 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 15:53:07 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 15:53:07 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 15:53:07 INFO  CodeGenerator: Code generated in 15.904667 ms
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:53:07 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:53:07 INFO  CodeGenerator: Code generated in 14.738 ms
2025-02-24 15:53:43 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1656 bytes result sent to driver
2025-02-24 15:53:43 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 36444 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:53:53 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:53:53 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:53:53 INFO  AbstractConnector: Stopped Spark@5890763{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:53:53 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:53:53 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:155) failed in 46,336 s due to Stage cancelled because SparkContext was shut down
2025-02-24 15:53:53 INFO  DAGScheduler: Job 3 failed: jdbc at main.scala:155, took 46,338776 s
2025-02-24 15:53:53 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:53:53 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:53:53 INFO  BlockManager: BlockManager stopped
2025-02-24 15:53:53 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:53:53 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:53:53 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:53:53 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:53:53 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-67e179b3-8a06-4c8a-9ef2-a4f3e5b7db55
2025-02-24 15:53:59 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:53:59 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:53:59 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:53:59 INFO  ResourceUtils: ==============================================================
2025-02-24 15:53:59 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:53:59 INFO  ResourceUtils: ==============================================================
2025-02-24 15:53:59 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:53:59 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:53:59 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:53:59 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:53:59 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:53:59 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:53:59 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:53:59 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:53:59 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:53:59 INFO  Utils: Successfully started service 'sparkDriver' on port 53347.
2025-02-24 15:53:59 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:54:00 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:54:00 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:54:00 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:54:00 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:54:00 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-b2c9f2fa-0324-4a9f-b9af-61a0a2062a04
2025-02-24 15:54:00 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:54:00 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:54:00 INFO  log: Logging initialized @1414ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:54:00 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:54:00 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:54:00 INFO  Server: Started @1485ms
2025-02-24 15:54:00 INFO  AbstractConnector: Started ServerConnector@6daf7d37{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:54:00 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ad4a7d6{/,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:54:00 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:54:00 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53348.
2025-02-24 15:54:00 INFO  NettyBlockTransferService: Server created on 172.20.10.2:53348
2025-02-24 15:54:00 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:54:00 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 53348, None)
2025-02-24 15:54:00 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:53348 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 53348, None)
2025-02-24 15:54:00 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 53348, None)
2025-02-24 15:54:00 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 53348, None)
2025-02-24 15:54:00 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@3ad4a7d6{/,null,STOPPED,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1dd74143{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3166f664{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@60a19573{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@134ff8f8{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@df921b1{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2152ab30{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@727320fa{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3f018494{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@57fbc06f{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@62b790a5{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7523a3dc{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@766a49c7{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@75e27856{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4f4c88f9{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cb39552{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2a53f215{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7beae796{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@52bf7bf6{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@ae73c80{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@bbd4791{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@73971965{/static,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1ee47d9e{/,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5dc0ff7d{/api,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@138aa3cc{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@30839e44{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@34585ac9{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:54:00 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59b32539{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@233db8e9{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@787508ca{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6274670b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:54:00 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3965bdf9{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:54:01 INFO  InMemoryFileIndex: It took 19 ms to list leaf files for 1 paths.
2025-02-24 15:54:01 INFO  InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
2025-02-24 15:54:02 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:54:02 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:54:02 INFO  CodeGenerator: Code generated in 109.168291 ms
2025-02-24 15:54:02 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:54:02 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:54:02 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:53348 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:54:02 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-02-24 15:54:02 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:54:03 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:54:03 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-02-24 15:54:03 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-02-24 15:54:03 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:54:03 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:54:03 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:54:03 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:53348 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:54:03 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:54:03 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:54:03 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:54:03 INFO  CodeGenerator: Code generated in 6.794167 ms
2025-02-24 15:54:03 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:54:03 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 99 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:54:03 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:54:03 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,156 s
2025-02-24 15:54:03 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:54:03 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:54:03 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,187665 s
2025-02-24 15:54:03 INFO  CodeGenerator: Code generated in 4.520666 ms
2025-02-24 15:54:03 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:54:03 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:54:03 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:53348 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:54:03 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:53348 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:54:03 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-02-24 15:54:03 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:54:03 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:54:03 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-02-24 15:54:03 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-02-24 15:54:03 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:54:03 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:54:03 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:54:03 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:54:03 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:53348 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:54:03 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:54:03 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:54:03 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:54:03 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:54:03 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:54:03 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:54:03 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:54:03 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:54:03 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:54:03 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:54:03 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:54:03 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:54:04 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 818 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:54:04 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1004 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:54:04 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1006 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1007 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:54:04 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1010 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:54:04 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1012 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1013 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:54:04 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:54:04 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1013 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:54:04 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:54:04 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 1,028 s
2025-02-24 15:54:04 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:54:04 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:54:04 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,030501 s
2025-02-24 15:54:07 INFO  CodeGenerator: Code generated in 6.54125 ms
2025-02-24 15:54:07 INFO  SparkContext: Starting job: jdbc at main.scala:150
2025-02-24 15:54:07 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:150, took 0,000124 s
2025-02-24 15:55:32 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:55:32 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:55:32 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:55:32 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:55:32 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:53348 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:55:32 INFO  SparkContext: Created broadcast 4 from jdbc at main.scala:156
2025-02-24 15:55:32 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:55:32 INFO  SparkContext: Starting job: jdbc at main.scala:156
2025-02-24 15:55:32 INFO  DAGScheduler: Got job 3 (jdbc at main.scala:156) with 8 output partitions
2025-02-24 15:55:32 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:156)
2025-02-24 15:55:32 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:55:32 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:55:32 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:156), which has no missing parents
2025-02-24 15:55:32 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.2 KiB, free 2.2 GiB)
2025-02-24 15:55:32 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 2.2 GiB)
2025-02-24 15:55:32 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:53348 (size: 10.5 KiB, free: 2.2 GiB)
2025-02-24 15:55:32 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:55:32 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:156) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:55:32 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:55:32 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 15:55:32 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:55:32 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 15:55:32 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 15:55:32 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 15:55:32 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 15:55:32 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 15:55:32 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 15:55:32 INFO  CodeGenerator: Code generated in 32.907208 ms
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:55:32 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:55:32 INFO  CodeGenerator: Code generated in 9.4715 ms
2025-02-24 15:55:34 INFO  BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.10.2:53348 in memory (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:10 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1656 bytes result sent to driver
2025-02-24 15:56:10 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 37443 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:56:17 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:56:17 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:56:17 INFO  AbstractConnector: Stopped Spark@6daf7d37{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:56:17 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:56:17 INFO  DAGScheduler: Job 3 failed: jdbc at main.scala:156, took 44,449985 s
2025-02-24 15:56:17 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:156) failed in 44,448 s due to Stage cancelled because SparkContext was shut down
2025-02-24 15:56:17 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:56:17 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:56:17 INFO  BlockManager: BlockManager stopped
2025-02-24 15:56:17 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:56:17 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:56:17 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:56:17 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:56:17 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-3cc010e1-a1e3-4d43-a8d6-f7af762d7c7e
2025-02-24 15:56:21 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:56:21 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:56:21 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:56:21 INFO  ResourceUtils: ==============================================================
2025-02-24 15:56:21 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:56:21 INFO  ResourceUtils: ==============================================================
2025-02-24 15:56:21 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:56:21 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:56:21 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:56:21 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:56:21 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:56:21 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:56:21 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:56:21 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:56:21 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:56:21 INFO  Utils: Successfully started service 'sparkDriver' on port 54153.
2025-02-24 15:56:21 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:56:21 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:56:21 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:56:21 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:56:21 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:56:21 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-888c2367-b005-4253-a027-7b16f9b03e8c
2025-02-24 15:56:21 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:56:21 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:56:22 INFO  log: Logging initialized @1185ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:56:22 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:56:22 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:56:22 INFO  Server: Started @1278ms
2025-02-24 15:56:22 INFO  AbstractConnector: Started ServerConnector@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:56:22 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68d651f2{/,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:56:22 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:56:22 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54162.
2025-02-24 15:56:22 INFO  NettyBlockTransferService: Server created on 172.20.10.2:54162
2025-02-24 15:56:22 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:56:22 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 54162, None)
2025-02-24 15:56:22 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:54162 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 54162, None)
2025-02-24 15:56:22 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 54162, None)
2025-02-24 15:56:22 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 54162, None)
2025-02-24 15:56:22 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@68d651f2{/,null,STOPPED,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/static,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@443faa85{/,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41da3aee{/api,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c8a7e38{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41184371{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:56:22 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cedee22{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5b47731f{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e13f304{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d24420b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16ac5d35{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:56:22 INFO  InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
2025-02-24 15:56:22 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-02-24 15:56:23 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:23 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:56:24 INFO  CodeGenerator: Code generated in 104.091833 ms
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:54162 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-02-24 15:56:24 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:24 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:56:24 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-02-24 15:56:24 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-02-24 15:56:24 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:24 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:24 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:54162 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:24 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:56:24 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:24 INFO  CodeGenerator: Code generated in 8.242834 ms
2025-02-24 15:56:24 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-02-24 15:56:24 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:56:24 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:56:24 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,150 s
2025-02-24 15:56:24 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:56:24 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:56:24 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,183876 s
2025-02-24 15:56:24 INFO  CodeGenerator: Code generated in 4.053833 ms
2025-02-24 15:56:24 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:24 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:54162 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-02-24 15:56:24 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:24 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:54162 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:54162 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:56:24 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-02-24 15:56:24 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-02-24 15:56:24 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:24 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:24 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:56:24 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:54162 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:24 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:24 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:56:24 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:24 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:56:24 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:56:24 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:56:24 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:56:24 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:56:24 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:56:24 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:56:24 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:56:25 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 917 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1069 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1075 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1077 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1079 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1082 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1090 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:56:25 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:56:25 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1090 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:56:25 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:56:25 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 1,103 s
2025-02-24 15:56:25 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:56:25 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:56:25 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,105304 s
2025-02-24 15:56:27 INFO  CodeGenerator: Code generated in 8.403042 ms
2025-02-24 15:56:27 INFO  SparkContext: Starting job: jdbc at main.scala:150
2025-02-24 15:56:27 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:150, took 0,000105 s
2025-02-24 15:56:29 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:29 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:56:29 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:29 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:29 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:54162 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:29 INFO  SparkContext: Created broadcast 4 from jdbc at main.scala:156
2025-02-24 15:56:29 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:29 INFO  SparkContext: Starting job: jdbc at main.scala:156
2025-02-24 15:56:29 INFO  DAGScheduler: Got job 3 (jdbc at main.scala:156) with 8 output partitions
2025-02-24 15:56:29 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:156)
2025-02-24 15:56:29 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:29 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:29 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:156), which has no missing parents
2025-02-24 15:56:29 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.2 KiB, free 2.2 GiB)
2025-02-24 15:56:29 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.4 KiB, free 2.2 GiB)
2025-02-24 15:56:29 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:54162 (size: 10.4 KiB, free: 2.2 GiB)
2025-02-24 15:56:29 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:29 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at jdbc at main.scala:156) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:56:29 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:29 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:56:29 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 15:56:29 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 15:56:29 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 15:56:29 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 15:56:29 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 15:56:29 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 15:56:29 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 15:56:29 INFO  CodeGenerator: Code generated in 24.604084 ms
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:56:29 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:56:29 INFO  CodeGenerator: Code generated in 10.410833 ms
2025-02-24 15:56:30 ERROR Executor: Exception in task 4.0 in stage 2.0 (TID 13)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 ERROR Executor: Exception in task 5.0 in stage 2.0 (TID 14)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 ERROR Executor: Exception in task 7.0 in stage 2.0 (TID 16)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 9)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 WARN  TaskSetManager: Lost task 7.0 in stage 2.0 (TID 16) (172.20.10.2 executor driver): java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795)
	... 17 more

2025-02-24 15:56:30 ERROR TaskSetManager: Task 7 in stage 2.0 failed 1 times; aborting job
2025-02-24 15:56:30 ERROR Executor: Exception in task 2.0 in stage 2.0 (TID 11)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 INFO  TaskSetManager: Lost task 0.0 in stage 2.0 (TID 9) on 172.20.10.2, executor driver: java.sql.BatchUpdateException (Field 'id' doesn't have a default value) [duplicate 1]
2025-02-24 15:56:30 INFO  TaskSetManager: Lost task 5.0 in stage 2.0 (TID 14) on 172.20.10.2, executor driver: java.sql.BatchUpdateException (Field 'id' doesn't have a default value) [duplicate 2]
2025-02-24 15:56:30 INFO  TaskSetManager: Lost task 4.0 in stage 2.0 (TID 13) on 172.20.10.2, executor driver: java.sql.BatchUpdateException (Field 'id' doesn't have a default value) [duplicate 3]
2025-02-24 15:56:30 INFO  TaskSetManager: Lost task 2.0 in stage 2.0 (TID 11) on 172.20.10.2, executor driver: java.sql.BatchUpdateException (Field 'id' doesn't have a default value) [duplicate 4]
2025-02-24 15:56:30 INFO  TaskSchedulerImpl: Cancelling stage 2
2025-02-24 15:56:30 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2025-02-24 15:56:30 ERROR Executor: Exception in task 6.0 in stage 2.0 (TID 15)
java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890) ~[spark-sql_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.scheduler.Task.run(Task.scala:139) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) ~[spark-core_2.13-3.4.0.jar:3.4.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795) ~[mysql-connector-j-8.0.33.jar:8.0.33]
	... 17 more
2025-02-24 15:56:30 INFO  TaskSchedulerImpl: Stage 2 was cancelled
2025-02-24 15:56:30 INFO  Executor: Executor is trying to kill task 1.0 in stage 2.0 (TID 10), reason: Stage cancelled
2025-02-24 15:56:30 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:156) failed in 0,685 s due to Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 16) (172.20.10.2 executor driver): java.sql.BatchUpdateException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:816)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:418)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:795)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:735)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:891)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:890)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1009)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1009)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: Field 'id' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:130)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:916)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1061)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:795)
	... 17 more

Driver stacktrace:
2025-02-24 15:56:30 INFO  Executor: Executor is trying to kill task 3.0 in stage 2.0 (TID 12), reason: Stage cancelled
2025-02-24 15:56:30 INFO  TaskSetManager: Lost task 6.0 in stage 2.0 (TID 15) on 172.20.10.2, executor driver: java.sql.BatchUpdateException (Field 'id' doesn't have a default value) [duplicate 5]
2025-02-24 15:56:30 INFO  DAGScheduler: Job 3 failed: jdbc at main.scala:156, took 0,687494 s
2025-02-24 15:56:30 INFO  Executor: Executor interrupted and killed task 1.0 in stage 2.0 (TID 10), reason: Stage cancelled
2025-02-24 15:56:30 WARN  TaskSetManager: Lost task 1.0 in stage 2.0 (TID 10) (172.20.10.2 executor driver): TaskKilled (Stage cancelled)
2025-02-24 15:56:30 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:56:30 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:56:30 INFO  AbstractConnector: Stopped Spark@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:56:30 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:56:30 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:56:30 INFO  Executor: Executor interrupted and killed task 3.0 in stage 2.0 (TID 12), reason: Stage cancelled
2025-02-24 15:56:30 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:56:30 INFO  BlockManager: BlockManager stopped
2025-02-24 15:56:30 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:56:30 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:56:30 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:56:30 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:56:30 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-de8d300c-3b97-4b49-a4f2-b76ad70dd4b7
2025-02-24 15:56:45 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)
2025-02-24 15:56:45 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-02-24 15:56:45 INFO  SparkContext: Running Spark version 3.4.0
2025-02-24 15:56:46 INFO  ResourceUtils: ==============================================================
2025-02-24 15:56:46 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-02-24 15:56:46 INFO  ResourceUtils: ==============================================================
2025-02-24 15:56:46 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-02-24 15:56:46 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-02-24 15:56:46 INFO  ResourceProfile: Limiting resource is cpu
2025-02-24 15:56:46 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-02-24 15:56:46 INFO  SecurityManager: Changing view acls to: fabob
2025-02-24 15:56:46 INFO  SecurityManager: Changing modify acls to: fabob
2025-02-24 15:56:46 INFO  SecurityManager: Changing view acls groups to: 
2025-02-24 15:56:46 INFO  SecurityManager: Changing modify acls groups to: 
2025-02-24 15:56:46 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-02-24 15:56:46 INFO  Utils: Successfully started service 'sparkDriver' on port 54310.
2025-02-24 15:56:46 INFO  SparkEnv: Registering MapOutputTracker
2025-02-24 15:56:46 INFO  SparkEnv: Registering BlockManagerMaster
2025-02-24 15:56:46 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-02-24 15:56:46 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-02-24 15:56:46 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-02-24 15:56:46 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-301bb0b3-507d-4619-bd85-18b555897a9e
2025-02-24 15:56:46 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-02-24 15:56:46 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-02-24 15:56:46 INFO  log: Logging initialized @1028ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-02-24 15:56:46 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-02-24 15:56:46 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+0
2025-02-24 15:56:46 INFO  Server: Started @1082ms
2025-02-24 15:56:46 INFO  AbstractConnector: Started ServerConnector@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:56:46 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@68d651f2{/,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  Executor: Starting executor ID driver on host 172.20.10.2
2025-02-24 15:56:46 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-02-24 15:56:46 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54314.
2025-02-24 15:56:46 INFO  NettyBlockTransferService: Server created on 172.20.10.2:54314
2025-02-24 15:56:46 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-02-24 15:56:46 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.2, 54314, None)
2025-02-24 15:56:46 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.2:54314 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.2, 54314, None)
2025-02-24 15:56:46 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.2, 54314, None)
2025-02-24 15:56:46 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.2, 54314, None)
2025-02-24 15:56:46 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@68d651f2{/,null,STOPPED,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44d64d4e{/jobs,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@526a9908{/jobs/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@66f28a1f{/jobs/job,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@44a085e5{/jobs/job/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/stages,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/stages/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/stages/stage,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/pool,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/pool/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c52fc81{/storage,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/storage/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/storage/rdd,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/environment,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/environment/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/executors,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/executors/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/executors/threadDump,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/static,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@443faa85{/,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41da3aee{/api,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3c8a7e38{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@10a98392{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@41184371{/metrics/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-02-24 15:56:46 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@cedee22{/SQL,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5b47731f{/SQL/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e13f304{/SQL/execution,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3d24420b{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@16ac5d35{/static/sql,null,AVAILABLE,@Spark}
2025-02-24 15:56:46 INFO  InMemoryFileIndex: It took 29 ms to list leaf files for 1 paths.
2025-02-24 15:56:47 INFO  InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
2025-02-24 15:56:48 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:48 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-02-24 15:56:48 INFO  CodeGenerator: Code generated in 93.400084 ms
2025-02-24 15:56:48 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.2:54314 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:49 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-02-24 15:56:49 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:49 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:56:49 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-02-24 15:56:49 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-02-24 15:56:49 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:49 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:49 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.2:54314 (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:49 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:49 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-02-24 15:56:49 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:49 INFO  CodeGenerator: Code generated in 10.863417 ms
2025-02-24 15:56:49 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-02-24 15:56:49 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 248 ms on 172.20.10.2 (executor driver) (1/1)
2025-02-24 15:56:49 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-02-24 15:56:49 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,310 s
2025-02-24 15:56:49 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:56:49 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-02-24 15:56:49 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,344950 s
2025-02-24 15:56:49 INFO  CodeGenerator: Code generated in 4.305708 ms
2025-02-24 15:56:49 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:49 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.2:54314 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:49 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-02-24 15:56:49 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:49 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.2:54314 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:49 INFO  SparkContext: Starting job: csv at main.scala:17
2025-02-24 15:56:49 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-02-24 15:56:49 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-02-24 15:56:49 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:49 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:49 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-02-24 15:56:49 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.2:54314 (size: 9.1 KiB, free: 2.2 GiB)
2025-02-24 15:56:49 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:49 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:56:49 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:49 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-02-24 15:56:49 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-02-24 15:56:49 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-02-24 15:56:49 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-02-24 15:56:49 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-02-24 15:56:49 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-02-24 15:56:49 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-02-24 15:56:49 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:49 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:56:50 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.2:54314 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:50 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-02-24 15:56:50 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1098 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:56:51 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1236 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:56:51 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1240 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1240 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:56:51 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1248 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1248 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1248 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:56:51 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-02-24 15:56:51 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1253 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:56:51 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-02-24 15:56:51 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 1,266 s
2025-02-24 15:56:51 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:56:51 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-02-24 15:56:51 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,267810 s
2025-02-24 15:56:57 INFO  FileSourceStrategy: Pushed Filters: 
2025-02-24 15:56:57 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-02-24 15:56:57 INFO  MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-02-24 15:56:57 INFO  MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-02-24 15:56:57 INFO  BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.10.2:54314 (size: 34.2 KiB, free: 2.2 GiB)
2025-02-24 15:56:57 INFO  SparkContext: Created broadcast 4 from jdbc at main.scala:156
2025-02-24 15:56:57 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-02-24 15:56:57 INFO  SparkContext: Starting job: jdbc at main.scala:156
2025-02-24 15:56:57 INFO  DAGScheduler: Got job 2 (jdbc at main.scala:156) with 8 output partitions
2025-02-24 15:56:57 INFO  DAGScheduler: Final stage: ResultStage 2 (jdbc at main.scala:156)
2025-02-24 15:56:57 INFO  DAGScheduler: Parents of final stage: List()
2025-02-24 15:56:57 INFO  DAGScheduler: Missing parents: List()
2025-02-24 15:56:57 INFO  DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at jdbc at main.scala:156), which has no missing parents
2025-02-24 15:56:57 INFO  MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.2 KiB, free 2.2 GiB)
2025-02-24 15:56:57 INFO  MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.5 KiB, free 2.2 GiB)
2025-02-24 15:56:57 INFO  BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.10.2:54314 (size: 10.5 KiB, free: 2.2 GiB)
2025-02-24 15:56:57 INFO  SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-02-24 15:56:57 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at jdbc at main.scala:156) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-02-24 15:56:57 INFO  TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9) (172.20.10.2, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10) (172.20.10.2, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11) (172.20.10.2, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12) (172.20.10.2, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13) (172.20.10.2, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 5.0 in stage 2.0 (TID 14) (172.20.10.2, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 6.0 in stage 2.0 (TID 15) (172.20.10.2, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  TaskSetManager: Starting task 7.0 in stage 2.0 (TID 16) (172.20.10.2, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-02-24 15:56:57 INFO  Executor: Running task 1.0 in stage 2.0 (TID 10)
2025-02-24 15:56:57 INFO  Executor: Running task 4.0 in stage 2.0 (TID 13)
2025-02-24 15:56:57 INFO  Executor: Running task 0.0 in stage 2.0 (TID 9)
2025-02-24 15:56:57 INFO  Executor: Running task 6.0 in stage 2.0 (TID 15)
2025-02-24 15:56:57 INFO  Executor: Running task 5.0 in stage 2.0 (TID 14)
2025-02-24 15:56:57 INFO  Executor: Running task 7.0 in stage 2.0 (TID 16)
2025-02-24 15:56:57 INFO  Executor: Running task 2.0 in stage 2.0 (TID 11)
2025-02-24 15:56:57 INFO  Executor: Running task 3.0 in stage 2.0 (TID 12)
2025-02-24 15:56:57 INFO  CodeGenerator: Code generated in 15.952083 ms
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-02-24 15:56:57 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-02-24 15:56:57 INFO  CodeGenerator: Code generated in 6.239833 ms
2025-02-24 15:57:33 INFO  Executor: Finished task 7.0 in stage 2.0 (TID 16). 1656 bytes result sent to driver
2025-02-24 15:57:33 INFO  TaskSetManager: Finished task 7.0 in stage 2.0 (TID 16) in 36093 ms on 172.20.10.2 (executor driver) (1/8)
2025-02-24 15:57:56 INFO  Executor: Finished task 5.0 in stage 2.0 (TID 14). 1613 bytes result sent to driver
2025-02-24 15:57:56 INFO  TaskSetManager: Finished task 5.0 in stage 2.0 (TID 14) in 58979 ms on 172.20.10.2 (executor driver) (2/8)
2025-02-24 15:57:56 INFO  Executor: Finished task 1.0 in stage 2.0 (TID 10). 1613 bytes result sent to driver
2025-02-24 15:57:56 INFO  TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 59109 ms on 172.20.10.2 (executor driver) (3/8)
2025-02-24 15:57:57 INFO  Executor: Finished task 2.0 in stage 2.0 (TID 11). 1613 bytes result sent to driver
2025-02-24 15:57:57 INFO  Executor: Finished task 6.0 in stage 2.0 (TID 15). 1613 bytes result sent to driver
2025-02-24 15:57:57 INFO  TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 59336 ms on 172.20.10.2 (executor driver) (4/8)
2025-02-24 15:57:57 INFO  TaskSetManager: Finished task 6.0 in stage 2.0 (TID 15) in 59335 ms on 172.20.10.2 (executor driver) (5/8)
2025-02-24 15:57:57 INFO  Executor: Finished task 3.0 in stage 2.0 (TID 12). 1613 bytes result sent to driver
2025-02-24 15:57:57 INFO  Executor: Finished task 4.0 in stage 2.0 (TID 13). 1613 bytes result sent to driver
2025-02-24 15:57:57 INFO  TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 59412 ms on 172.20.10.2 (executor driver) (6/8)
2025-02-24 15:57:57 INFO  TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 59412 ms on 172.20.10.2 (executor driver) (7/8)
2025-02-24 15:57:57 INFO  Executor: Finished task 0.0 in stage 2.0 (TID 9). 1613 bytes result sent to driver
2025-02-24 15:57:57 INFO  TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 59698 ms on 172.20.10.2 (executor driver) (8/8)
2025-02-24 15:57:57 INFO  TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-02-24 15:57:57 INFO  DAGScheduler: ResultStage 2 (jdbc at main.scala:156) finished in 59,705 s
2025-02-24 15:57:57 INFO  DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-02-24 15:57:57 INFO  TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
2025-02-24 15:57:57 INFO  DAGScheduler: Job 2 finished: jdbc at main.scala:156, took 59,708011 s
2025-02-24 15:59:24 INFO  SparkContext: Invoking stop() from shutdown hook
2025-02-24 15:59:24 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-02-24 15:59:24 INFO  AbstractConnector: Stopped Spark@65d57e4e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-02-24 15:59:24 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.2:4040
2025-02-24 15:59:24 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-02-24 15:59:24 INFO  MemoryStore: MemoryStore cleared
2025-02-24 15:59:24 INFO  BlockManager: BlockManager stopped
2025-02-24 15:59:24 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-02-24 15:59:24 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-02-24 15:59:24 INFO  SparkContext: Successfully stopped SparkContext
2025-02-24 15:59:24 INFO  ShutdownHookManager: Shutdown hook called
2025-02-24 15:59:24 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-ddd0acdb-cddc-4611-ade6-c4cecb10dd27
2025-05-19 10:33:17 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1, but we couldn't find any external IP address!
2025-05-19 10:33:17 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-05-19 10:33:17 INFO  SparkContext: Running Spark version 3.4.0
2025-05-19 10:33:18 INFO  ResourceUtils: ==============================================================
2025-05-19 10:33:18 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-05-19 10:33:18 INFO  ResourceUtils: ==============================================================
2025-05-19 10:33:18 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-05-19 10:33:18 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-05-19 10:33:18 INFO  ResourceProfile: Limiting resource is cpu
2025-05-19 10:33:18 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-05-19 10:33:18 INFO  SecurityManager: Changing view acls to: fabob
2025-05-19 10:33:18 INFO  SecurityManager: Changing modify acls to: fabob
2025-05-19 10:33:18 INFO  SecurityManager: Changing view acls groups to: 
2025-05-19 10:33:18 INFO  SecurityManager: Changing modify acls groups to: 
2025-05-19 10:33:18 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-05-19 10:33:18 INFO  Utils: Successfully started service 'sparkDriver' on port 50801.
2025-05-19 10:33:18 INFO  SparkEnv: Registering MapOutputTracker
2025-05-19 10:33:18 INFO  SparkEnv: Registering BlockManagerMaster
2025-05-19 10:33:18 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-05-19 10:33:18 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-05-19 10:33:18 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-05-19 10:33:18 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-c0834220-58d5-4c5c-bf61-29d3d3464aaf
2025-05-19 10:33:18 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-05-19 10:33:18 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-05-19 10:33:18 INFO  log: Logging initialized @1945ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-05-19 10:33:18 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-05-19 10:33:18 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17+35-LTS-2724
2025-05-19 10:33:18 INFO  Server: Started @2162ms
2025-05-19 10:33:18 INFO  AbstractConnector: Started ServerConnector@2a2ef072{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:33:18 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-05-19 10:33:18 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@14823f76{/,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  Executor: Starting executor ID driver on host localhost
2025-05-19 10:33:19 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-05-19 10:33:19 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50806.
2025-05-19 10:33:19 INFO  NettyBlockTransferService: Server created on localhost:50806
2025-05-19 10:33:19 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-05-19 10:33:19 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 50806, None)
2025-05-19 10:33:19 INFO  BlockManagerMasterEndpoint: Registering block manager localhost:50806 with 2.2 GiB RAM, BlockManagerId(driver, localhost, 50806, None)
2025-05-19 10:33:19 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 50806, None)
2025-05-19 10:33:19 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 50806, None)
2025-05-19 10:33:19 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@14823f76{/,null,STOPPED,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@619f2afc{/jobs,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/jobs/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@eb6ec6{/jobs/job,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/jobs/job/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/stages,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2806d6da{/stages/stage,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/stages/stage/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/stages/pool,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/stages/pool/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/storage,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/storage/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/storage/rdd,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/environment,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/environment/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@76a14c8d{/executors,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ee99964{/executors/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59c70ceb{/executors/threadDump,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@64f981e2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575b5f7d{/static,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d50a7ca{/,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e766822{/api,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db87583{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d6d1d42{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7c51782d{/metrics/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-05-19 10:33:19 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6274670b{/SQL,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@32d5279{/SQL/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3965bdf9{/SQL/execution,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1860f3be{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-05-19 10:33:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3b4825f0{/static/sql,null,AVAILABLE,@Spark}
2025-05-19 10:33:20 INFO  InMemoryFileIndex: It took 68 ms to list leaf files for 1 paths.
2025-05-19 10:33:20 INFO  InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
2025-05-19 10:33:22 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:33:22 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-05-19 10:33:23 INFO  CodeGenerator: Code generated in 305.609125 ms
2025-05-19 10:33:23 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:33:23 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:33:23 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50806 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:33:23 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-05-19 10:33:23 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:33:23 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:33:23 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-05-19 10:33:23 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-05-19 10:33:23 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:33:23 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:33:23 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-05-19 10:33:23 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-05-19 10:33:23 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-05-19 10:33:23 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50806 (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:33:23 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:33:23 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-05-19 10:33:23 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-05-19 10:33:23 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:23 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-05-19 10:33:23 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:33:23 INFO  CodeGenerator: Code generated in 7.755125 ms
2025-05-19 10:33:23 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-05-19 10:33:23 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 154 ms on localhost (executor driver) (1/1)
2025-05-19 10:33:23 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-05-19 10:33:23 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,230 s
2025-05-19 10:33:23 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:33:23 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-05-19 10:33:23 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,264346 s
2025-05-19 10:33:23 INFO  CodeGenerator: Code generated in 19.992208 ms
2025-05-19 10:33:24 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on localhost:50806 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:33:24 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:33:24 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-05-19 10:33:24 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:33:24 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:33:24 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:50806 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:33:24 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-05-19 10:33:24 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:33:24 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on localhost:50806 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:33:24 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:33:24 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-05-19 10:33:24 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-05-19 10:33:24 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:33:24 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:33:24 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-05-19 10:33:24 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-05-19 10:33:24 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-05-19 10:33:24 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:50806 (size: 9.1 KiB, free: 2.2 GiB)
2025-05-19 10:33:24 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:33:24 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-05-19 10:33:24 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (localhost, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (localhost, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (localhost, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (localhost, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (localhost, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (localhost, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (localhost, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:33:24 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-05-19 10:33:24 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-05-19 10:33:24 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-05-19 10:33:24 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-05-19 10:33:24 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-05-19 10:33:24 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-05-19 10:33:24 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-05-19 10:33:24 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:33:24 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-05-19 10:33:25 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1357 ms on localhost (executor driver) (1/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1496 ms on localhost (executor driver) (2/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1500 ms on localhost (executor driver) (3/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1501 ms on localhost (executor driver) (4/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1505 ms on localhost (executor driver) (5/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1509 ms on localhost (executor driver) (6/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1518 ms on localhost (executor driver) (7/8)
2025-05-19 10:33:25 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-05-19 10:33:25 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1519 ms on localhost (executor driver) (8/8)
2025-05-19 10:33:25 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-05-19 10:33:25 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 1,535 s
2025-05-19 10:33:25 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:33:25 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-05-19 10:33:25 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,537733 s
2025-05-19 10:33:25 INFO  SparkContext: Invoking stop() from shutdown hook
2025-05-19 10:33:25 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-05-19 10:33:25 INFO  AbstractConnector: Stopped Spark@2a2ef072{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:33:25 INFO  SparkUI: Stopped Spark web UI at http://localhost:4040
2025-05-19 10:33:25 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-05-19 10:33:25 INFO  MemoryStore: MemoryStore cleared
2025-05-19 10:33:25 INFO  BlockManager: BlockManager stopped
2025-05-19 10:33:25 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-05-19 10:33:25 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-05-19 10:33:25 INFO  SparkContext: Successfully stopped SparkContext
2025-05-19 10:33:25 INFO  ShutdownHookManager: Shutdown hook called
2025-05-19 10:33:25 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-f6900716-aba2-4375-9d6f-6c710feb04f2
2025-05-19 10:34:18 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.3 instead (on interface en0)
2025-05-19 10:34:18 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-05-19 10:34:18 INFO  SparkContext: Running Spark version 3.4.0
2025-05-19 10:34:18 INFO  ResourceUtils: ==============================================================
2025-05-19 10:34:18 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-05-19 10:34:18 INFO  ResourceUtils: ==============================================================
2025-05-19 10:34:18 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-05-19 10:34:18 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-05-19 10:34:18 INFO  ResourceProfile: Limiting resource is cpu
2025-05-19 10:34:18 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-05-19 10:34:18 INFO  SecurityManager: Changing view acls to: fabob
2025-05-19 10:34:18 INFO  SecurityManager: Changing modify acls to: fabob
2025-05-19 10:34:18 INFO  SecurityManager: Changing view acls groups to: 
2025-05-19 10:34:18 INFO  SecurityManager: Changing modify acls groups to: 
2025-05-19 10:34:18 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-05-19 10:34:19 INFO  Utils: Successfully started service 'sparkDriver' on port 51168.
2025-05-19 10:34:19 INFO  SparkEnv: Registering MapOutputTracker
2025-05-19 10:34:19 INFO  SparkEnv: Registering BlockManagerMaster
2025-05-19 10:34:19 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-05-19 10:34:19 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-05-19 10:34:19 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-05-19 10:34:19 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-990a8327-5f59-4a6d-8eea-652eacb210ce
2025-05-19 10:34:19 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-05-19 10:34:19 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-05-19 10:34:19 INFO  log: Logging initialized @1127ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-05-19 10:34:19 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-05-19 10:34:19 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17+35-LTS-2724
2025-05-19 10:34:19 INFO  Server: Started @1198ms
2025-05-19 10:34:19 INFO  AbstractConnector: Started ServerConnector@2f00f851{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:34:19 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ed16657{/,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  Executor: Starting executor ID driver on host 172.20.10.3
2025-05-19 10:34:19 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-05-19 10:34:19 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51173.
2025-05-19 10:34:19 INFO  NettyBlockTransferService: Server created on 172.20.10.3:51173
2025-05-19 10:34:19 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-05-19 10:34:19 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.3, 51173, None)
2025-05-19 10:34:19 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.3:51173 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.3, 51173, None)
2025-05-19 10:34:19 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.3, 51173, None)
2025-05-19 10:34:19 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.3, 51173, None)
2025-05-19 10:34:19 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@6ed16657{/,null,STOPPED,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/jobs,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3902bd2c{/jobs/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/jobs/job,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/stages/stage,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/stages/stage/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/stages/pool,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/stages/pool/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/storage,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/storage/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/storage/rdd,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/environment,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@76a14c8d{/environment/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ee99964{/executors,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59c70ceb{/executors/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@64f981e2{/executors/threadDump,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575b5f7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7165d530{/static,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e766822{/,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28757abd{/api,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d6d1d42{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7978e022{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@48e8c32a{/metrics/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-05-19 10:34:19 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@32d5279{/SQL,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d0b0cb9{/SQL/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1860f3be{/SQL/execution,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@78cfa264{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-05-19 10:34:19 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7980cf2c{/static/sql,null,AVAILABLE,@Spark}
2025-05-19 10:34:20 INFO  InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
2025-05-19 10:34:20 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-05-19 10:34:21 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:34:21 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-05-19 10:34:21 INFO  CodeGenerator: Code generated in 127.206334 ms
2025-05-19 10:34:21 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.3:51173 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:34:22 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-05-19 10:34:22 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:34:22 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:34:22 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-05-19 10:34:22 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-05-19 10:34:22 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:34:22 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:34:22 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.3:51173 (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:34:22 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:34:22 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-05-19 10:34:22 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.3, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:34:22 INFO  CodeGenerator: Code generated in 11.674375 ms
2025-05-19 10:34:22 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1773 bytes result sent to driver
2025-05-19 10:34:22 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 125 ms on 172.20.10.3 (executor driver) (1/1)
2025-05-19 10:34:22 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-05-19 10:34:22 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,208 s
2025-05-19 10:34:22 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:34:22 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-05-19 10:34:22 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,231272 s
2025-05-19 10:34:22 INFO  CodeGenerator: Code generated in 4.803792 ms
2025-05-19 10:34:22 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.3:51173 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:34:22 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:34:22 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.3:51173 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:34:22 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-05-19 10:34:22 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:34:22 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:34:22 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-05-19 10:34:22 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-05-19 10:34:22 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:34:22 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:34:22 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-05-19 10:34:22 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.3:51173 (size: 9.1 KiB, free: 2.2 GiB)
2025-05-19 10:34:22 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:34:22 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-05-19 10:34:22 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.3, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.3, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.3, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.3, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.3, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.3, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.3, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.3, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:34:22 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-05-19 10:34:22 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-05-19 10:34:22 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-05-19 10:34:22 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-05-19 10:34:22 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-05-19 10:34:22 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-05-19 10:34:22 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-05-19 10:34:22 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-05-19 10:34:22 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-05-19 10:34:23 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.3:51173 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:34:23 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 836 ms on 172.20.10.3 (executor driver) (1/8)
2025-05-19 10:34:23 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 973 ms on 172.20.10.3 (executor driver) (2/8)
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 976 ms on 172.20.10.3 (executor driver) (3/8)
2025-05-19 10:34:23 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 979 ms on 172.20.10.3 (executor driver) (4/8)
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 980 ms on 172.20.10.3 (executor driver) (5/8)
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 980 ms on 172.20.10.3 (executor driver) (6/8)
2025-05-19 10:34:23 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 982 ms on 172.20.10.3 (executor driver) (7/8)
2025-05-19 10:34:23 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-05-19 10:34:23 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 984 ms on 172.20.10.3 (executor driver) (8/8)
2025-05-19 10:34:23 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-05-19 10:34:23 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 0,999 s
2025-05-19 10:34:23 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:34:23 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-05-19 10:34:23 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 1,001902 s
2025-05-19 10:35:08 INFO  SparkContext: Invoking stop() from shutdown hook
2025-05-19 10:35:08 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-05-19 10:35:08 INFO  AbstractConnector: Stopped Spark@2f00f851{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:35:08 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.3:4040
2025-05-19 10:35:08 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-05-19 10:35:08 INFO  MemoryStore: MemoryStore cleared
2025-05-19 10:35:08 INFO  BlockManager: BlockManager stopped
2025-05-19 10:35:08 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-05-19 10:35:08 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-05-19 10:35:08 INFO  SparkContext: Successfully stopped SparkContext
2025-05-19 10:35:08 INFO  ShutdownHookManager: Shutdown hook called
2025-05-19 10:35:08 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-0b35b9ba-22b4-4b43-92dc-a9dd79d5748c
2025-05-19 10:35:12 WARN  Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.20.10.3 instead (on interface en0)
2025-05-19 10:35:12 WARN  Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2025-05-19 10:35:12 INFO  SparkContext: Running Spark version 3.4.0
2025-05-19 10:35:12 INFO  ResourceUtils: ==============================================================
2025-05-19 10:35:12 INFO  ResourceUtils: No custom resources configured for spark.driver.
2025-05-19 10:35:12 INFO  ResourceUtils: ==============================================================
2025-05-19 10:35:12 INFO  SparkContext: Submitted application: Analyse de stock massive
2025-05-19 10:35:12 INFO  ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-05-19 10:35:12 INFO  ResourceProfile: Limiting resource is cpu
2025-05-19 10:35:12 INFO  ResourceProfileManager: Added ResourceProfile id: 0
2025-05-19 10:35:12 INFO  SecurityManager: Changing view acls to: fabob
2025-05-19 10:35:12 INFO  SecurityManager: Changing modify acls to: fabob
2025-05-19 10:35:12 INFO  SecurityManager: Changing view acls groups to: 
2025-05-19 10:35:12 INFO  SecurityManager: Changing modify acls groups to: 
2025-05-19 10:35:12 INFO  SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: fabob; groups with view permissions: EMPTY; users with modify permissions: fabob; groups with modify permissions: EMPTY
2025-05-19 10:35:12 INFO  Utils: Successfully started service 'sparkDriver' on port 51473.
2025-05-19 10:35:12 INFO  SparkEnv: Registering MapOutputTracker
2025-05-19 10:35:12 INFO  SparkEnv: Registering BlockManagerMaster
2025-05-19 10:35:12 INFO  BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-05-19 10:35:12 INFO  BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2025-05-19 10:35:12 INFO  SparkEnv: Registering BlockManagerMasterHeartbeat
2025-05-19 10:35:12 INFO  DiskBlockManager: Created local directory at /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/blockmgr-dfbaed4c-f320-4ca4-8650-76a351d260b8
2025-05-19 10:35:12 INFO  MemoryStore: MemoryStore started with capacity 2.2 GiB
2025-05-19 10:35:12 INFO  SparkEnv: Registering OutputCommitCoordinator
2025-05-19 10:35:12 INFO  log: Logging initialized @971ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-05-19 10:35:12 INFO  JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2025-05-19 10:35:12 INFO  Server: jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17+35-LTS-2724
2025-05-19 10:35:12 INFO  Server: Started @1024ms
2025-05-19 10:35:12 INFO  AbstractConnector: Started ServerConnector@1fb48736{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:35:12 INFO  Utils: Successfully started service 'SparkUI' on port 4040.
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ed16657{/,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  Executor: Starting executor ID driver on host 172.20.10.3
2025-05-19 10:35:12 INFO  Executor: Starting executor with user classpath (userClassPathFirst = false): ''
2025-05-19 10:35:12 INFO  Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51474.
2025-05-19 10:35:12 INFO  NettyBlockTransferService: Server created on 172.20.10.3:51474
2025-05-19 10:35:12 INFO  BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-05-19 10:35:12 INFO  BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.20.10.3, 51474, None)
2025-05-19 10:35:12 INFO  BlockManagerMasterEndpoint: Registering block manager 172.20.10.3:51474 with 2.2 GiB RAM, BlockManagerId(driver, 172.20.10.3, 51474, None)
2025-05-19 10:35:12 INFO  BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.20.10.3, 51474, None)
2025-05-19 10:35:12 INFO  BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.20.10.3, 51474, None)
2025-05-19 10:35:12 INFO  ContextHandler: Stopped o.s.j.s.ServletContextHandler@6ed16657{/,null,STOPPED,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@4db60246{/jobs,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3902bd2c{/jobs/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@18137eab{/jobs/job,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2935fd2c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@3ce443f9{/stages,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@51a18b21{/stages/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1db7157f{/stages/stage,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6bccd036{/stages/stage/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6a756082{/stages/pool,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1f3b992{/stages/pool/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6b63e6ad{/storage,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6749fe50{/storage/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@261db982{/storage/rdd,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@22f4f8f2{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@40a72ecd{/environment,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@76a14c8d{/environment/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@6ee99964{/executors,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@59c70ceb{/executors/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@64f981e2{/executors/threadDump,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@575b5f7d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7165d530{/static,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@2e766822{/,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@28757abd{/api,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1d6d1d42{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7978e022{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@48e8c32a{/metrics/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-05-19 10:35:12 INFO  SharedState: Warehouse path is 'file:/Users/fabob/IdeaProjects/transactions_massives_scala/spark-warehouse'.
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@32d5279{/SQL,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@5d0b0cb9{/SQL/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@1860f3be{/SQL/execution,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@78cfa264{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-05-19 10:35:12 INFO  ContextHandler: Started o.s.j.s.ServletContextHandler@7980cf2c{/static/sql,null,AVAILABLE,@Spark}
2025-05-19 10:35:13 INFO  InMemoryFileIndex: It took 17 ms to list leaf files for 1 paths.
2025-05-19 10:35:13 INFO  InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2025-05-19 10:35:13 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:35:13 INFO  FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-05-19 10:35:14 INFO  CodeGenerator: Code generated in 79.391625 ms
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_0 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.10.3:51474 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  SparkContext: Created broadcast 0 from csv at main.scala:17
2025-05-19 10:35:14 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:35:14 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:35:14 INFO  DAGScheduler: Got job 0 (csv at main.scala:17) with 1 output partitions
2025-05-19 10:35:14 INFO  DAGScheduler: Final stage: ResultStage 0 (csv at main.scala:17)
2025-05-19 10:35:14 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:35:14 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:35:14 INFO  DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17), which has no missing parents
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.10.3:51474 (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:35:14 INFO  DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0))
2025-05-19 10:35:14 INFO  TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.10.3, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  Executor: Running task 0.0 in stage 0.0 (TID 0)
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:35:14 INFO  CodeGenerator: Code generated in 6.880125 ms
2025-05-19 10:35:14 INFO  Executor: Finished task 0.0 in stage 0.0 (TID 0). 1816 bytes result sent to driver
2025-05-19 10:35:14 INFO  TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 104 ms on 172.20.10.3 (executor driver) (1/1)
2025-05-19 10:35:14 INFO  TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-05-19 10:35:14 INFO  DAGScheduler: ResultStage 0 (csv at main.scala:17) finished in 0,162 s
2025-05-19 10:35:14 INFO  DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:35:14 INFO  TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2025-05-19 10:35:14 INFO  DAGScheduler: Job 0 finished: csv at main.scala:17, took 0,179346 s
2025-05-19 10:35:14 INFO  CodeGenerator: Code generated in 3.745916 ms
2025-05-19 10:35:14 INFO  BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.10.3:51474 in memory (size: 6.1 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  FileSourceStrategy: Pushed Filters: 
2025-05-19 10:35:14 INFO  FileSourceStrategy: Post-Scan Filters: 
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_2 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.10.3:51474 (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  SparkContext: Created broadcast 2 from csv at main.scala:17
2025-05-19 10:35:14 INFO  FileSourceScanExec: Planning scan with bin packing, max size: 9849868 bytes, open cost is considered as scanning 4194304 bytes.
2025-05-19 10:35:14 INFO  SparkContext: Starting job: csv at main.scala:17
2025-05-19 10:35:14 INFO  DAGScheduler: Got job 1 (csv at main.scala:17) with 8 output partitions
2025-05-19 10:35:14 INFO  DAGScheduler: Final stage: ResultStage 1 (csv at main.scala:17)
2025-05-19 10:35:14 INFO  DAGScheduler: Parents of final stage: List()
2025-05-19 10:35:14 INFO  DAGScheduler: Missing parents: List()
2025-05-19 10:35:14 INFO  DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17), which has no missing parents
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.8 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 2.2 GiB)
2025-05-19 10:35:14 INFO  BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.10.3:51474 (size: 9.1 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
2025-05-19 10:35:14 INFO  DAGScheduler: Submitting 8 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at main.scala:17) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2025-05-19 10:35:14 INFO  TaskSchedulerImpl: Adding task set 1.0 with 8 tasks resource profile 0
2025-05-19 10:35:14 INFO  BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.10.3:51474 in memory (size: 34.2 KiB, free: 2.2 GiB)
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.20.10.3, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.20.10.3, executor driver, partition 1, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.20.10.3, executor driver, partition 2, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.20.10.3, executor driver, partition 3, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.20.10.3, executor driver, partition 4, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.20.10.3, executor driver, partition 5, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.20.10.3, executor driver, partition 6, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.20.10.3, executor driver, partition 7, PROCESS_LOCAL, 8052 bytes) 
2025-05-19 10:35:14 INFO  Executor: Running task 0.0 in stage 1.0 (TID 1)
2025-05-19 10:35:14 INFO  Executor: Running task 1.0 in stage 1.0 (TID 2)
2025-05-19 10:35:14 INFO  Executor: Running task 3.0 in stage 1.0 (TID 4)
2025-05-19 10:35:14 INFO  Executor: Running task 2.0 in stage 1.0 (TID 3)
2025-05-19 10:35:14 INFO  Executor: Running task 4.0 in stage 1.0 (TID 5)
2025-05-19 10:35:14 INFO  Executor: Running task 5.0 in stage 1.0 (TID 6)
2025-05-19 10:35:14 INFO  Executor: Running task 6.0 in stage 1.0 (TID 7)
2025-05-19 10:35:14 INFO  Executor: Running task 7.0 in stage 1.0 (TID 8)
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 59099208-68949076, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 19699736-29549604, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 49249340-59099208, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 0-9849868, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 68949076-74604645, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 39399472-49249340, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 9849868-19699736, partition values: [empty row]
2025-05-19 10:35:14 INFO  FileScanRDD: Reading File path: file:///Users/fabob/IdeaProjects/transactions_massives_scala/transactions_massives_scala_spark.csv, range: 29549604-39399472, partition values: [empty row]
2025-05-19 10:35:15 INFO  Executor: Finished task 7.0 in stage 1.0 (TID 8). 1981 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 734 ms on 172.20.10.3 (executor driver) (1/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 6.0 in stage 1.0 (TID 7). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 817 ms on 172.20.10.3 (executor driver) (2/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 5.0 in stage 1.0 (TID 6). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 829 ms on 172.20.10.3 (executor driver) (3/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 0.0 in stage 1.0 (TID 1). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 832 ms on 172.20.10.3 (executor driver) (4/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 2.0 in stage 1.0 (TID 3). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 835 ms on 172.20.10.3 (executor driver) (5/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 4.0 in stage 1.0 (TID 5). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 836 ms on 172.20.10.3 (executor driver) (6/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 3.0 in stage 1.0 (TID 4). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 845 ms on 172.20.10.3 (executor driver) (7/8)
2025-05-19 10:35:15 INFO  Executor: Finished task 1.0 in stage 1.0 (TID 2). 1938 bytes result sent to driver
2025-05-19 10:35:15 INFO  TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 847 ms on 172.20.10.3 (executor driver) (8/8)
2025-05-19 10:35:15 INFO  TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-05-19 10:35:15 INFO  DAGScheduler: ResultStage 1 (csv at main.scala:17) finished in 0,866 s
2025-05-19 10:35:15 INFO  DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-05-19 10:35:15 INFO  TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2025-05-19 10:35:15 INFO  DAGScheduler: Job 1 finished: csv at main.scala:17, took 0,867584 s
2025-05-19 10:36:19 INFO  SparkContext: Invoking stop() from shutdown hook
2025-05-19 10:36:19 INFO  SparkContext: SparkContext is stopping with exitCode 0.
2025-05-19 10:36:19 INFO  AbstractConnector: Stopped Spark@1fb48736{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-05-19 10:36:19 INFO  SparkUI: Stopped Spark web UI at http://172.20.10.3:4040
2025-05-19 10:36:19 INFO  MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2025-05-19 10:36:19 INFO  MemoryStore: MemoryStore cleared
2025-05-19 10:36:19 INFO  BlockManager: BlockManager stopped
2025-05-19 10:36:19 INFO  BlockManagerMaster: BlockManagerMaster stopped
2025-05-19 10:36:19 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2025-05-19 10:36:19 INFO  SparkContext: Successfully stopped SparkContext
2025-05-19 10:36:19 INFO  ShutdownHookManager: Shutdown hook called
2025-05-19 10:36:19 INFO  ShutdownHookManager: Deleting directory /private/var/folders/zr/9zs30z0x7zqg2qtlblgpd45r0000gn/T/spark-1c8a6547-b1bd-4b4c-b088-6f5a6fedddb0
